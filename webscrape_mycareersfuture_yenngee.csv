,job_title,company,salary,job_description
0,Senior Data Engineer,THOUGHTWORKS PTE. LTD.,"$5,700to$11,200Monthly","Roles & ResponsibilitiesSingapore, SingaporeThoughtWorks Singapore is looking for talented engineers passionate about building large scale data processing systems to help
manage the ever-growing information needs of our clients.  
You will be responsible for -   Creating complex data processing pipelines, as part of diverse, high energy teams Designing scalable implementations of the models
 Hands-on programming based on TDD, usually in a pair programming environment Deploying data pipelines in production based on Continuous Delivery practices Advising clients on the usage of different distributed storage and computing
technologies from the plethora of options available in the ecosystem  RequirementsIdeally, you should have -
  5+ years of experience building and deploying large scale
data processing pipelines in a production environment Production-level hands-on experience working on
HDFS, Java MapReduce, Hive, Apache Spark, Oozie etc. Solid understanding of YARN, Mesos, MPP Databases, SQL-on-Hadoop solutions like Impala etc. Experience working with, or an interest in Agile Methodologies, such as Extreme Programming (XP) and Scrum Knowledge of software best practices, like Test-Driven Development (TDD) and Continuous Integration (CI) Strong communication and client-facing skills with the ability to work in a consulting environment is essential Senior developers (7+ years) are expected to be the Architect for small
and large
enterprise projects. On larger projects, you are expected to work closely with the fellow architects to come up with the architecture and take it further. Desire to contribute to the wider technical community through collaboration, coaching, and mentoring of other technologists  If you relish the idea of being part of a community that extends beyond the work we do for our customers, you may find ThoughtWorks is the right place for you. If you share our passion for technology and want to help change the world with software, we want to hear from you! To apply, please submit your CV and tell us why you want to join ThoughtWorks. We will ask you to write code as part of your interview process, so be prepared! Our recruiters will be in touch."
1,Data Scientist,Company Undisclosed,Salary undisclosed,"Roles & ResponsibilitiesOur Client is an established company in Singapore, who is seeking to recruit a Data Scientist.   
   Data Scientist  
   Job Responsibilities  
   You will advocate, evangelize and build data-fuelled products, dig in and become an expert on our datasets. You will provide insight into leading analytic practices, design and lead iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become part of our core deliverables.   
   You will work with cross-functional team members to identify and prioritize actionable, high-impact insights across a variety of core business areas. You will lead applied analytics initiatives that are leveraged across the breadth of our solutions. You will research, design, implement and validate cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes.   As our data scientist, you will provide expertise on mathematical concepts for the broader applied analytics team and inspire the adoption of advanced analytics and data science across the entire breadth of our organization. Requirements Ph.D. or Masters Degree in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline. Have a deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, and recommendation and optimization algorithms. More than 3 years of experience delivering world-class data science outcomes, proven ability to solve complex analytical problems using quantitative approaches with unique blend of analytical, mathematical and technical skills. Passionate about asking and answering questions in large datasets, and able to communicate that passion to product managers and engineers. Keen desire to solve business problems, and live to find patterns and insights within structured and unstructured data. You propose analytics strategies and solutions that challenge and expand the thinking of everyone around you. Expert in analyzing large, complex, multi-dimensional datasets with a variety of tools. You are accomplished in the use of statistical analysis environments such as R, MATLAB, SPSS or SAS. You have experience with BI tools such as Tableau and Microstrategy. Youre as comfortable with relational databases as you are with Hadoop-based data mining frameworks. You are familiar with SQL, Python, Java and C/C++. Able to work in a fast paced, test-driven, collaborative and iterative engineering environment. You love learning, data, scale and agility. You excel at making complex concepts simple and easy to understand by those around you. Youre driven to show the world the power of applied analytics.  
   
   JJ Consulting Services   EA Licence No.: 12C6207   
   Applicants are invited to send in a MS Word resume to
  jobs@jjconsulting.com.sg
stating position applying for/present/expected salaries and earliest available date.    We thank all applicants in advance and regret that only short listed candidates will be notified."
2,Data Engineer,ADDSTONES SAS,"$5,000to$10,000Monthly","Roles & ResponsibilitiesGFI is an international IT services company, currently employing about 18,000 people Worldwide. GFI provides its clients with innovative, long-lasting industrial solutions to leverage performance from their information systems.  Management Consulting | Digital Transformation | Innovation  Operating over 20 countries,  2017 revenue of over 1,2 billion USD,  48 years of existence. In order to support our forthcoming business and technological challenges, we seek innovative and agile people sharing our mind set. We are now looking for a Data Engineer to join our team in Singapore. General presentation of the position: Part of CIB IT Architecture, Digital and Transformation, the IT Digital Accelerator & Platform Accelerator team is in charge of:  Accelerating the delivery of products from Lab to Prod. Coordinating the correct usage of our platform. Expanding and managing the Digital Expert Community.  One of the Platform we are working on is the APAC Data Solution. This solution will be used for data management, data quality, analytics and reporting services providing the capability to be a data driven organization. Within the team, the Data Engineer ensures that any data is properly received, transformed, stored, and made accessible to other users. Role and Responsibilities:  Constructing data pipelines. Building APIs for data consumption Supporting the Data Platform Continuously monitoring and testing the system to ensure optimized performance  
 RequirementsDeep analytical skills : 
  Business intelligence understanding. Data Visualization tools (tableau). Enjoying discovering and solving problems  Excellent communication skills :  Strong interpersonal, oral and written communication and presentation skills. Ability to communicate complex findings and ideas in plain language. Written and verbal communication, preferably with technical writing skills. Being able to work in teams towards a shared goal;  Project and resource management skills:  Resilient project juggler Strong experience in user testing and project management  Specific Qualifications Required :  Experience on with visualization tools (tableau) Experience with data management tools (Ab initio) is required 5+ years of associated work experience in a relevant role Excellent interpersonal communication skills to explain complex technical topics in an easily digestible manner Advanced SQL database management is a plus. Understanding of file transfer solution (CFT, sfTP, MQ, kafka) Technical expertise regarding data models, database design development, data mining and segmentation techniques. Strong knowledge and experience with reporting packages/tools (tableau etc.), databases (SQL etc.), programming (Python, R, JavaScript or ETL frameworks). Knowledge of statistics or experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.). Adept at queries, report writing and presenting findings. Working knowledge in any analytical tools like Alteryx, Dataiku. Working knowledge of Hadoop, MapR and Machine Learning techniques are desired. "
3,Senior Building Services Engineer (Data Centre),PM ASIA PROJECT SERVICES PTE. LTD.,"$5,500to$8,000Monthly","Roles & ResponsibilitiesOverall Job Objectives:  Responsible for the design of HVAC systems and related utilities, including conceptual, front end and detailed design activities on a variety of data centre projects. Core Responsibilities:   Lead the Building Services design of large scale, high end industrial facilities
 Experience in designing HVAC, Fire Protection Sprinkler and Black Utilities Carry out site visits / site surveys Interact and communicate with own department, other departments, project team members, clients and other external parties to ensure co-ordination of activities Prepare technical documents in accordance with agreed schedules  
 Requirements Minimum Degree in Engineering or Science related discipline Minimum 6
years of building services design experience Good knowledge of designing HVAC, Sprinkler and Black Utilities Experience of working with a design house or engineering company Proficient in the use of relevant engineering software such as AutoCAD and Revit Strong work ethic and act with integrity Good organizational skills "
4,Datastage Consultant,INFINITE COMPUTER SOLUTIONS PTE LTD,"$3,000to$5,000Monthly","Roles & ResponsibilitiesJob Description Responsible for the analysis, data profiling, development, and integration of disparate systems throughout all phases of the project life cycle. Work as part of a team delivering high quality and efficient integration solutions. Assist in ongoing development of technical best practices for data movement, data quality, data cleansing and other ETL related activities. Takes a logical, analytical approach to problem solving and pays close attention to detail  
 RequirementsKey Qualification: *Degree in Computer Science or Computer Engineering *4+ years experience in IBM DataStage or similar ETL tool *Experience with other components of ETL such as Information Analysis, data quality,data lineage and data governance *Knowledge/hands on experience with SQL, relational databases such as MSSQL, 
DB2 or Oracle, *IBM Infosphere Tool Suite.  EA License No. - 14C6941 
"
5,O&T - Data Analyst Lead - 18035524,CITIBANK N.A.,"$10,000to$17,500Monthly","Roles & Responsibilities You will interface with our business partners in decision management functions to mature use cases, identify solutions and help implement solutions iteratively using agile methodologies You will engage within the technology organization to integrate and embed analytic capabilities to enhance products and customer experience You will partner with
 architects and the Business Intelligence organization to assemble capabilities into platforms that can address a variety of analytical needs You will represent yourself as an expert, but equally rely on others to support you as a team
 Serve as mentor and coach to junior resources and other teams Apply deep analytical skills to explore complex datasets to aid in knowledge discovery and predictive modeling activities Assist our business data science teams in developing tools, metrics, and systems to analyze large-scale internal and external data to identify opportunities to improve product offering and marketing Maintain knowledge of emerging trends related to analytics, data management, statistical computing/machine learning, business intelligence, data visualization, etc Manage the development and execution of predictive analytics and machine learning models for a variety of applications, from predicting customer behavior to creating recommendation engines for the marketplace Design, coordinate, and implement analytical business and technology solutions to support business strategy Drive the day-to-day implementation of the analytical strategy Determine data needed to be collected and the appropriate data resources for specific projects  To apply online via the careers section of Citi E career website, please click via the link below: https://citi.taleo.net/careersection/2/jobdetail.ftl?lang-en&job=18035524 Requirements BA/BS degree required, advanced degree is preferred in Computer Science/Statistics or related field with 10+ years of data analytics experience Experience in quantifying and monetizing data platforms Ability to influence others to adopt new ways of thinking, change habits and improve processes Ability to translate complex technical topics into easy to understand concepts Experience developing processes to govern analytics development life cycle Demonstrated track record of success in delivering advanced analytics capabilities Direct experience in implementing data management processes, procedures, data quality management, and decision support Experience leveraging next generation tools and techniques such as Hadoop, Machine Learning, MapReduce, Spark, Python, R to build deployable analytical solutions Working knowledge of data mining, statistical analysis and machine learning concepts, with the ability to apply them to make better decisions, find hidden patterns, and predict outcomes Experience managing and working in an agile environment using agile tools and practices Experience building out and managing an organization's data capabilities, including staff, tools, and processes is a plus Strong written and verbal communication and presentation skills Experience working in a banking / financial services / fintech / retail environment is a plus "
6,Research & Development - Data Scientist - Hair Care - Singapore,PROCTER & GAMBLE INTERNATIONAL OPERATIONS SA SINGAPORE BRANCH,"$6,000to$10,000Monthly","Roles & ResponsibilitiesAt P&G we leverage advanced machine learning methods to solve R&D problems  ranging from developing smart products and personalizing consumer experiences generating consumer insights from complex data sources. The Data Scientist could effectively leverage various data sources, machine learning and deep learning algorithms and beyond, partnering with multiple functional teams to generate insight and actionable recommendation from data for R&D innovation. Key Responsibilities:  Work closely with Scientists and Engineers to translate business challenges into clear problem statements. Leverage existing or develop new algorithms to model the data and solve the technical problem. Partner with IT/data engineering to realize rich media (text/image/video) solutions at global scale. Communicate effectively with working team to turn data into insight, develop actionable recommendation and business solutions.  RequirementsWe are seeking leaders who has a PhD in Computer Science, Engineering, Mathematics, Statistics, Data Sciences or other related fields. Outstanding Masters degree graduates in related field are also welcome to apply. Key Requirements:  Proficient with R and Python including Pandas, NumPy and Scikit-learn etc. Extensive experience and in depth understanding with wide range of advanced machine learning methods Practical experience of Natiural Launguage Processing (NLP)
with Chinese is a plus Practical experience with Text mining
and large data sets is a plus  Behavioral Skills:   Demonstrated leadership in applying and scaling Analytic techniques to deliver actionable insights from data Strong written and verbal communication skills Demonstrated ability to handle multiple priorities Strong enthusiasm and curiosity about the intersection of business and technology  Interested candidates to apply directly at www.pgcareers.com to Job Number: RND00003649 or apply via link below: https://jobs.pgcareers.com/job/singapore/research-and-development-data-scientist-hair-care-singapore/936/6327782 
"
7,Data Scientist,COMTEL SOLUTIONS PTE LTD,"$7,000to$10,500Monthly","Roles & Responsibilities Define hypotheses and identify the analysis trail for given business problems. Help create new solution approaches for innovative analytics scenarios. Develop proofs of concept and validate results. Implement small and large-scale projects in Advanced Analytics to help derive business insights for measurable success. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing 'big data' pipelines, data architectures and data sets. Knowledge of machine learning techniques and algorithms, such as K-NN, Naive Bayes, SVM, Decision Forests, etc. Expertise in design & development of API's, Web Services (REST, SOAP, etc ..) is needed Good to have exposure to data visualisation tools, such as D3.js, QlikView, Tableau etc. Exposure in configuring components (Celery, Redis..) on Linux platform  Requirements A Bachelors degree in Computer Science (or equivalent experience) 8  10 years of development and delivery experience Experience with big data tools: Hadoop, Spark. Experience with object-oriented function scripting languages: Python, C++ Experience with statistical computer languages (Python, SQL, R) to manipulate data and draw insights from large data sets. Experience with common data science toolkits, such as NumPy, Pandas. R, etc. "
8,DWH Consultant,ECNET LIMITED,"$6,000to$7,000Monthly","Roles & ResponsibilitiesDesign a BI Solution Manage full SDLC of BI solution
 Perform full product review and selection for multiple BI vendors Control cross department data access matrix Govern best practice of data warehouse and BI design RequirementsSSAS, SSIS, Microsoft SQL Server,
Tableau"
9,"Data Analyst, Group Customer Analytics & Decisioning",OVERSEA-CHINESE BANKING CORPORATION LIMITED,"$5,000to$9,000Monthly","Roles & Responsibilities
 What youll do Work with specific client groups in the Consumer Bank to understand their business challenges & identify areas where Customer analytics techniques could help them overcome these challenges and realise new opportunities Design and deploy data pipelines & solutions to increase productivity of the Consumer Banking business Support planning, development, execution and tracking of Data Driven Marketing activity across all channels Develop data-driven actionable customer insights to support marketing, sales and service communications. 
  Generate actionable customer insight to improve key business outcomes  
 Support the deployment of world-class marketing analytics capabilities and practices to improve marketing effectiveness and efficiency of the OCBC Consumer Financial Services division. This includes: 
  Development and execution of marketing campaigns & event triggers to support customer acquisition, cross & upselling and account activation goals within the Consumer Banking business. Conducting data discovery and other data exploration activities to identify emerging trends and business opportunities. Development and ongoing management of campaign reporting, analysis and derivation of key customer metrics. Design of management reporting & visualization using Qlikview. Provision of ongoing support to segment and product management in the profiling and segmentation of customers as well as conduct of tactical mining to support their business initiatives. Regular interaction with product and segment managers to understand their business objectives. Proactive recommendation on how you think analytics could help them achieve their goals.  
   Deploy solutions to increase productivity of Consumer Banking division  
 Design, build and deploy data driven solutions to increase productivity of the Consumer Banking Division including:  Design of processes to streamline marketing & promotional fulfillment activities Support for operational reporting & customer communications  RequirementsGeneral Knowledge & Experience: o










 Exposure to data management, programming and analysis functions o










 Understanding of the role of analytical marketers 
 Programming & Data: o










 Exposure to database, analytical marketing or campaign management functions. o










 Ability to analyse, identify, visualize and describe key trends within large datasets o










 Strong SQL coding and database knowledge o










 Some prior exposure to analytical software tools of leading analytical software tools (such as SAS / Python / Spark / R); leading database environments (Oracle / Teradata / Hadoop / SQL); reporting tools (Qlikview / Tableau) and/or contact management platforms (Siebel / Pega). 
 Communication & Soft Skills: o










 Curiosity & a real passion for understanding why? o










 Creativity to see possibilities within the data & translate into decisions and actions for non-technical business users. o










 Ability to visualise patterns arising out of data analysis and turn these into compelling stories."
10,Data Analyst,CAPGEMINI SINGAPORE PTE. LTD.,"$5,500to$10,000Monthly","Roles & ResponsibilitiesExplore and analyse complex data sets to formulate models Implement complex KPIs for various business domains Work with super users to implement complex reports and advanced data visualisations Define or adapt suitable predictive models Requirements Engineer or University degree 5+ years of experience with data visualization and predictive tools Good knowledge of predictive models (R or else) Experience with MS Power BI, Tableau, Qlik or Domo is a real plus Knowledge of data wrangling tools (Trifacta, alteryx, ) "
11,Data Warehouse and Reporting Specialist,Company Undisclosed,"$9,000to$12,000Monthly","Roles & ResponsibilitiesAPPLICANTS HAVE TO APPLY VIA OUR WEBSITE: ""http://careers.pageuppeople.com/395/ci/en/listing"" PURPOSE: To provide outstanding systems support to the Marketing department. Ensure all contracts and SLAs are managed to target performance and provide technical support SME for trading and reporting systems. TYPICAL TASK:
 - Deliver Datawarehouse and reporting enhancements in support of the Marketing business.
 - Provide day-to-day support to Marketing organisation users including (but not limited to): reporting, trading, finance and integration systems. - Manage the change management process to any trading application ensuring that each change is approved, well documented, tested and released in a controlled manner to the production environment. - Provide analysis support for any issues (hardware or application) arising and resolve these whilst liaising with third party service providers as appropriate. - Drive improved performance from support partners ensuring they are well briefed and trained to provide a strong service. - Ensure that there is adequate licensing in place to cover the Marketing user base. - Provide support coverage to Singapore counterparts, as part of a global team i.e. cover any Singapore absences and also cover the London hours end-of-day system processing. - Improve unit cost performance and service level achievement continuously. RequirementsCAPABILITY REQUIRED TO DO THE ROLE: Knowledge: Formal qualifications:  An undergraduate qualification (Bachelors degree or equivalent) in the relevant IM Discipline. Desirable: It would be advantageous to have a postgraduate qualification in the relevant IM discipline OR a proven track record of extensive practical experience in a role and context of similar complexity. Role-specific knowledge:  - the specific IM field, controls and risk mitigation - relevant business process improvement plans, risks and opportunities - the Marketing systems landscape Safety Knowledge: Provides a consistent outstanding role model in relation to safety practices with a deep understanding of the importance of safety. Technical Skills: Ability to: - make recommendation to process stakeholders on process improvement. - analyse and identify risk root causes and quantify potential business impact. - implement solutions to better enable the process and reduce level of exposure and risk. - interpret policy and explain why work needs to be completed in a particular manner. - explain how a particular process task needs to be fulfilled. - engage with key stakeholders and understand their process requirements. - assign and re-assign work to ensure outputs and the elimination of waste. - participate in IM initiatives and the different processes involved. - perform continuous monitoring reviews to make sure that the process aligns to the overall system. - complete project lifecycles with responsibility for a small team. Take an idea from concept to proof of concept and then to pilot. Any other requirements to perform the work effectively: - Global travel and collaboration across time zones may be required."
12,Data Scientist,OAK CONSULTING PTE. LTD.,"$6,000to$10,000Monthly","Roles & ResponsibilitiesData Scientist - with experience in Airport Hub Operations The Candidate serves as internal consultants to the operational leaders by providing analytical and project support across all major areas of the operation. The Data Scientist
will  Provides direction for the Airport Online Operations
and co-ops/interns in locating, extracting and aggregating data Manages process improvement and project management engagements for both individual business units and cross-divisional initiatives Interface with business unit leaders to develop and maintain internal customer relationships Presents findings to Hub and business unit leaders Locates and develops new data sources and/or complex analytical models and projects Develops highly complex reports, models and analyses with minimal supervision Practices safety-conscious behaviors in all operational processes and procedures Bachelor's degree in Engineering, Computer Science, Information Science, Business/Management, Mathematics/Statistics, Economics or other relevant quantitative field required and 3+ years of experience in analysis, information science, data visualization, or other relevant quantitative field required or a Master's degree and 2+ relevant experience. Previous airline experience preferred. Track record of seeking leadership roles including student and community organizations preferred. Must be comfortable working in group and individual settings and presenting to leaders.  RequirementsSuccessful candidates will have an intermediate level of understanding or experience with most, if not all, of the following:  SQL, Python, R or other database interface tools and languages Statistical Modeling and Six Sigma DMAIC process highly preferred MS Office Suite, Microstrategy and Tableau experience Must be performing satisfactory in current position. Some travel might be required to domestic hubs. "
13,Senior Data Analyst (JD#4216),Company Undisclosed,"$5,000to$7,000Monthly","Roles & ResponsibilitiesJob Summary Great opportunity to gain experience as a Senior Data Analyst within the tourism / entertainment industry working on the latest data analytics cloud platform with machine learning and Artificial Intelligence capabilities. 
 RequirementsMandatory Skill-set  Bachelor's Degree in Mathematics, Statistics or Computer Science; At least 3 years of relevant experience in data science and analysis; Technical expertise regarding data model, database design development, data mining, clustering and segmentation techniques; Proficiency in analytical tools such as R, Python and data visualization tools like Tableau as well as knowledgeable in ETL concepts; Strong knowledge of and experience with reporting packages, databases, data marts , data warehousing; Possess strong reasoning skill and analytical skills; Meticulous
and organised with good interpersonal and communication skills.  Desired Skill-set  Preferably with experience in Hadoop, Spark, Hive and Apache Pig.
  Responsibilities  Collect and interpret data and analyze results using statistical techniques; Develop and implement data collection and strategies that optimise
statistical efficiency and quality of data; Identify, analyze and interpret trends or patterns in complex data sets; Work with business stakeholders and present the findings to stakeholders
effectively communicating the key findings and recommendations; Act as a point of contact for data team.  Should you be interested in this opportunity, please send your updated resume to apply@sciente.com at the earliest. Confidentiality is assured, and only shortlisted candidates will be notified.
 Sciente International Pte Ltd (EA License: 07C5639)"
14,Research Fellow,Company Undisclosed,"$4,000to$5,000Monthly","Roles & ResponsibilitiesData Scientist / Programmer for Regional ATM Modernisation Programme Under the Air Traffic Management Research Institute (ATMRI) (http://atmri.ntu.edu.sg/), Nanyang Technological University, you will be part of Regional ATM Modernisation Programme team to perform programming and data analytics for the ASEAN air routes and ATM operations in the region. Primary Duties or Responsibilities Specifically, you will  Undertake research and development related to Air-space management & Data Analytics. Perform programming support for fast time and real-time simulation tools, doing analytics, and building high quality strategic planning system for future for Air Traffic Management (ATM) eco-system for the region. You will provide expertise on mathematical concepts for the broader applied analytics of flow management and inspire the adoption of advanced analytics and data science across the entire breadth of regional ATM system. Conduct stakeholder meetings to solicit input for development of systems. Interact with senior personnel such as project lead and ATC operations specialist on significant technical matters and coordinate with other specialist teams within programme. Represent the Institute at regional/global ATM platforms, international forum/conferences. Occasional overseas travel may be required.  Requirements Doctorate degree in a relevant field. At least 3 years experience in any aviation-related fast-time simulation environment. Knowledge of tools like SAAM and AirTop will be an added advantage. Strong programming skills. Experience in
Data Science (knowledge in Aviation / Air Traffic Management Good English writing and communication skills Independent and team player "
15,Data Scientist,BIGO TECHNOLOGY PTE. LTD.,Salary undisclosed,"Roles & Responsibilities R & D of NLP technology to solve text classification and clustering, sentiment analysis, name entity extraction, sementic models, question and answer system, natural language generation.   Apply NLP to ranking, user profiling and comment analysis. 
 
 
 
 

  Requirements Master's or doctorate degree in computer science, mathematics or related field.

 








 Expertise on some NLP topics. Expertise on machine learning and statistics. Excellent communication skills and teamwork skills. Hadoop/Spark/MPI programming skill is preferred.










 Familiar with deep learning in NLP is preferred. "
16,Master Data Analyst,APPLE SOUTH ASIA PTE. LTD.,"$6,000to$10,000Monthly","Roles & ResponsibilitiesJob Summary Team up with Apple, one of the most influential technology leaders in the industry. Join the Apple Finance organization and make a positive impact on a company that is known for its impressive lineup of products, including Mac, iPod, iPhone and iPad. At Apple, youll share in a commitment to excellence by partnering with world-class professionals, all with one unified vision  creating innovative products that delight customers. We do this by hiring quality individuals with integrity, personal accountability, teamwork, excellence, and dedicated thinking. If you exemplify our values and want to be part of something big, contact us today. Apples Global Business Solutions (GBS) is a centrally managed organization that supports Apples four shared service centers around the world, including Austin, TX, Cork, Ireland, Shanghai, China and Singapore. GBS is responsible for vendor and customer master data management, finance helpline support and technical production support for SAP and other finance systems. This position may be located in either Shanghai or Singapore and is responsible for Japan vendor and customer master data management. Description - Creation, maintenance and management of customer and vendor master data in SAP and peripheral systems - Communication with external vendors in Japanese is required - Ensure compliance with SOX controls, finance policies and documented procedures Support documentation and enforcement of data governance policies, standards and processes - Handle urgent work deadlines and high profile deliverables in an efficient manner - Communicate and co-ordinate effectively with subject matter expert and the business teams on processes, projects and change management - Find opportunities for process improvement and automation to drive scale and efficiency, while maintaining a strong control environment - Participate in SAP projects and user acceptance testing when master data participation is required - Provide problem resolution and business-case diagnostics on complex system and data issues - Audit and update database to ensure that master data is consistent, free of duplicates, accurate, up-to-date and correctly classified - Build data quality metrics and reporting to validate and carry out operating and key control activities RequirementsKey Qualifications  You will have a strong knowledge of master data functions You are self-motivated and natural curiosity to learn
 Possess excellent written and verbal social skills
 Strong business partnering skills and ability to establish relationships with multi-functional and global partners You have strong analytical, problem-solving and negotiating skills
 Ability to handle various tasks simultaneously, while working independently in a fast paced, ambiguous environment Validated ability to perform under tight deadlines with flexibility with working hours to support global issues required  Education Bachelor degree in a technical or business discipline Experience with customer and vendor master data preferred"
17,"AVP / Senior Associate, Lead Development Engineer, Grp Consumer Banking & Big Data Analytics (180002YV",DBS BANK LTD.,"$5,500to$11,000Monthly","Roles & Responsibilities Manage the Avaloq Configuration / Release Management tasks and work on the BAU tasks in non-production environments Env Planning (DB, application), Avaloq ICE Streaming, Release calendars preparation and communicate with all stakeholders Definition of Connect Direct (NDM), IBM MQ, Avaloq Tools Upgrade, TWS Definition and Batch support, and FIX Platform interface setup Projects and Enhancement requests. Plan and manage the end-to-end deployment and delivery of IT infrastructure for Banks project from deployment planning, setup & testing, pre-production readiness to production cutover. Collaborate with Architecture and Engineering team, Application teams, Infrastructure teams, and service providers in delivering quality IT solutions and services to meet business objectives. Ensure the project meet schedule and within the allocated budget and resources. Adhere to the bank's Project Management, Deployment and Change management process.
 Prepare and submit the necessary change requests and requisition forms for the deployment of infrastructure for the project, such as facility request, IP/DNS/Hostname request, SAN requisition, etc. Conduct proper transition from Project to Operations before project closure. Prepare all project documentation such as SOM and status reports, assure report accuracy and timeliness. e.g. Weekly Project Status report, etc. Work collaboratively with technology team and vendors, provide single point of contact and drive resolution of issues that arise in projects. Maintain business partnership with Line of Business (LOBs) and constantly collect and manage users demands and applications infra requirements. Coordinate with DBA, Solaris, Linux, Windows, Network, ID Mgmt and other Infra admin teams on the system issue related tasks Co-ordinate with various Infra teams to apply the OS / DB / MQ patches
 Apply the innovative thinking to automate the manual tasks, provide infrastructure services effortlessly, improve performance and resilience of the systems.  Requirements The candidate need to have minimum of 5 years IT experience with Avaloq Release Management and infrastructure project delivery. The candidate should have strong infrastructure technical background with hands on Open Systems platform such as Solaris, Linux, virtualization, network, and storage. Moderate information security knowledge Have a good understanding of ITIL processes and project management processes. Development experience in SQL & PL/SQL, preferably in Oracle 11g / 12c environment Must have hands-on experience in IBM MQ series, Connect Direct and SSH such as file transfer tools Good to have knowledge on the Micro services and cloud services A Bachelors degree in Computer Science (or equivalent experience) 5 -8 years of development and delivery experience Able to perform Unix / Linux scripting. Monitor and address issues relating to capacity constraints and performance related items. Analyze and perform database performance tuning. Develop and maintain high-performance, scalable utilities to support technology research and data transformation. Contribute to the establishment and maintenance of distributed computing platform / Messaging services Good leadership skills in working with Application teams and service providers in defining and executing infrastructure deployment plan, coordination of all infrastructure required activities, cutover/migration strategy and test plan. Good in documentation, tracking, form submission, raising change request and project status reports.
 Should be an effective communicator with good people management skills to handle diverse groups/teams in the project. Should be a proactive self-starter with strong analytical skill, team-player, independent, pro-active, resourceful.
 "
18,"AVP / Senior Assoc, Data Scientist - Data Analytics & Robotics Team, Group Audit (180001M7)",DBS BANK LTD.,"$6,000to$10,000Monthly","Roles & ResponsibilitiesBusiness Function
 Group Audit helps the Board and Executive Management meet the strategic and operational objectives of the DBS Group. We conduct independent checks to ensure that the Groups risk and control processes are adequate and effective. All our team members are highly sought-after professionals who work as trusted advisors to our clients, in all matters related to a companys internal controls.
 Responsibilities  Partner with audit specialists across various banking functions to assess business needs and identify opportunities to apply data analytics Define analytical strategy to address identified opportunities, including analytical approaches, data and technology requirements Develop models and perform statistical analysis to identify key areas of risk and predict risk events, across a range of banking functions Present key findings to senior management and/or other stakeholders with actionable recommendations. Work with other data scientists in the team to drive projects  Requirements Post graduate degree in Computer Science, Machine Learning, Statistics, Applied Mathematics, or equivalent At least 3 years of experience in data mining and machine learning on large amount of data, building and implementing various statistical models Good mathematical and statistics background, including the ability to translate business problems and requirements into mathematical formulations Proficient in data manipulation and analysis Proficiency in R, Python, or other statistical software required. Experience in Big Data technology stack is a plus Ability to present analysis in a manner accessible by non-statisticians through data visualisation techniques Independent self-starter with ability to multitask Excellent verbal and written communication skills and the ability to interact professionally with a diverse group of executives, managers and subject matter experts Has a can-do attitude "
19,"Application Support Analyst, Reference Data Team","JPMORGAN CHASE BANK, N.A.","$6,000to$12,000Monthly","Roles & ResponsibilitiesWe are seeking an Application Support Analyst who can ensure
a smooth and effective operation of applications and 24/7 availability of the systems through careful monitoring of infrastructure, production processes, automating procedures where possible via scripting, and performing Permit to Operate on each application release. Analysis of existing system and user needs and support of newly developed systems. L2 Support is responsible for day to day support of CT environments infrastructure including the production and DR environments. Works with the development and other support teams to provide design guidelines and imparts knowledge on technical trends and solutions. The candidate will Instrument end to end monitoring of the CT infrastructure, ensuring high availability of the environment and timely alerting of any potential issues.
 Ensures infrastructures have adequate capacity and are refreshed on a periodic basis. Develops and maintains system documentation, run-books and production metrics reporting.
 Work effectively within the CT team to identify and resolve issues. Communicate effectively with both technical and non-technical individuals at all levels. . 
 Key responsibilities  Provide Level
 2 support to internal business users Prioritize workload, provide timely and accurate resolutions Perform in-depth research and identify sources of production issues Effectively perform and document root cause analysis of issues Identify efficiencies and ways to improve processes Juggle an array of tasks while demonstrating strong organization Perform daily health checks of the application, job schedules and infrastructure supporting the application Develop scripts to automate repeatable manual tasks Participate in Disaster Recovery events and Major Event Changes Partake in audit support activities, as they pertain to Information Security, for both internal and external audits.
 Perform audit support tasks as assigned Manage the application risk to ensure the security and resiliency of the application are in compliance with firm and regulatory requirements Ensure infrastructure has adequate capacity and are refreshed on a periodic basis Maintain system documentation and provide production metrics reporting. Act as first point of contact to diagnose and resolve issues raised by the business as part of the global operate team. Liaise with colleagues and other teams within the technology group to drive enhancements to technology requested by the business. Understand the batch flow and application flow end to end and be able to support the batches, drive improvements and automate manual procedures.  RequirementsQualifications  7-10 years Production support experience in Unix, Oracle and PL/SQLwith ability to manage/drive high priority Production incidents. Experience with escalated ticket management.
 Able to work under pressure to resolve issues affecting production services. Excellent analytical, problem-solving and multi-tasking skills. Experience with creating process, procedures, and documentation relating to incident management or systems operations. Able to work weekend on call rotations as required. Ability to coordinate tasks with multiple teams in multiple locations and time zones. Able to adapt to new technologies. Experience of communicating problems and issues concisely to senior business and technology leads.  Soft Skills (Essential):  Excellent verbal and written communication skills. Excellent interpersonal skills and be able to quickly understand and retain knowledge of business processes and the technology systems. Ability to handle high pressure, complex environments. Energetic and highly self-motivated. Build positive working relationships with external teams and managing their expectations. Strong analytical skills to solve complex issues.Good in stakeholder management and able to multi-task  Technical Skills:  Experience with supporting OS (Windows, Linux), web servers (IIS, Apache), application servers (WebSphere, Tomcat). Strong Oracle, PL/SQL support experience Strong UNIX experience. Need to have ability to read and understand UNIX Shell scripts. Strong knowledge in scheduling tools like Control-M and Autosys Knowledge of monitoring tools like Geneos , App Dynamics, Splunk Hands-on experience in troubleshoot performance issue including analyzing heap/thread dumps. Experience creating automation tools via scripting in both Linux as well as Windows environment  
 Experience (Desirable)  Previous experience of Reference Data support will be preferable  
 Key skills  Individual should be a self-starter who is confident and highly motivated to succeed. A genuine desire to learn about the business process and products across a number of asset classes. Ability to comfortably use a number of different technologies to analytically resolve complex issues Ability to take ownership of a myriad of issues and see them through to resolution. Excellent interpersonal skills, team player, with an ability to remain calm under pressure. Ability to take ownership of an issue and see it through to resolution. Ability to prioritize work load, multi task and react quickly to meet business expectations.  
Additional information  A flexible approach to working hours is required in order to cover the trading day.
 There is a rota system in place to provide on-site support normally between 7:30am and 7:00pm. Out of hours support is a part of this role and as such this role extends to support
production and batch monitoring, releases or maintenance of server processes where necessary on weekends on a rota basis.  Our Corporate Technology team relies on smart, driven people like you to develop applications and provide tech support for all our corporate functions across our network. Your efforts will touch lives all over the financial spectrum and across all our divisions: Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and within the Corporate Administrative Office. Youll be part of a team specifically built to meet and exceed our evolving technology needs, as well as our technology controls agenda. 
 When you work at JPMorgan Chase & Co., youre not just working at a global financial institution. Youre an integral part of one of the worlds biggest tech companies. In 14 technology hubs worldwide, our team of 40,000+ technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $9.5B+ annual investment in technology enables us to hire people to create innovative solutions that will not only transform the financial services industry, but also change the world.
 At JPMorgan Chase & Co. we value the unique skills of every employee, and were building a technology organization that thrives on diversity.
 We encourage professional growth and career development, and offer competitive benefits and compensation.
 If youre looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world, we want to meet you.
 
 We strongly encourage all applicants to apply via our careers website where you are able join our Talent Network to receive customized vacancy notifications and ensure that your details are accessible by our global recruiting team - www.jpmorganchase.com/careers. 
 A quick link to this particular job posting can be found in this URL: http://jobs.jpmorganchase.com/ListJobs/ByKeyword/180066358/  Please note that only short-listed candidates will be notified. We thank you for your interest and wish you all the best in your career.  Yours Sincerely, Human Resources JPMorgan 
"
20,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$2,500to$5,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Possess minimum 1 year of relevant work experience Ability to work independently to translate research ideas into programs with efficient coding Basic knowledge on data analytics, machine learning, data mining Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
21,"Senior Associate / Associate, Avaloq Support Analyst, Group Consumer Banking & Big Data, T&O(1800033I)",DBS BANK LTD.,"$4,000to$8,000Monthly","Roles & ResponsibilitiesJob Purpose
 To provide Day to Day support of all applications supporting DBS Wealth Management business.   Key Accountabilities
  Day to Day support of all applications supporting Wealth Management business Monitor critical components of the system and troubleshoot problem areas.
 Analyze and respond to queries and issues raised by end users in an effective and timely manner. Work closely with development team to provide fixes for critical application issues. Perform duties relating to system maintenance to ensure smooth usage of application and adherence to compliance   Responsibilities
  Ability to perform Avaloq Parameterization, Integration with External System. Ability to perform business analysis, impact analysis in a structured manner. Manages support phone to ensure that end-of-day batch jobs and files are processed and monitored. Coordinates with Vendor for solution delivery and release upgrade. Participate in Business Continuity Planning and Exercises.
 Participate in Release Management activities for Wealth Management systems.
 Participate in preparing ad-hoc reports for users.
  Requirements 5+ years of experience with Degree in Business Information Science, Computer Science or Engineering disciplines
 Avaloq-certified Professional preferred. Strong knowledge and experience in Oracle PL/SQL is a must. Good knowledge on Unix commands and scripting
 Minimum 3 years of experience in IT application support in banking industry. Excellent interpersonal and Communication skills. Experience in IBM websphere MQ, Connect Direct, SSH, Tivoli workload scheduler, Linux/Unix environments.
 Able to articulate well on solution(s) Team player
 "
22,BI Developer,TECHCOM SOLUTIONS & CONSULTANCY PTE. LTD.,"$6,000to$7,500Monthly","Roles & Responsibilities Support day- to- day operations for DWH/BI (as a first contact point) with ETL and Cognos changes at the highest level of quality, ensuring that business users have a Tier-1 IT support experience. Ensures production application systems are stable, highly available and performs consistently. Ensures rapid restoration of service follows up on the permanent removal of defects and ensures quality service is provided in an efficient, effective, and proactive manner. Works with DBAs and other IT teams to align with ETL and Cognos development quality. Collaborates with IT business analysts to overcome issues impacting service delivery. Participates in both systems and software upgrades for the region. Acts as a team role model and change-agent. Engage with offshore ETL and Cognos developers and partner together to achieve delivery. Promotes and follows the guidelines of the Corporations Code of Business Ethics and Values. Performs all other related duties as assigned. Executes ETL and Cognos enhancements. Travels up to 5%.  Requirements Bachelors degree preferably in Computer Science, Engineering or related discipline.
 6-8 years relevant experience in IT or equivalent with preferably in a manufacturing environment. This role requires strong technical skills specific to ETL ((Informatica or Oracle ODI),Cognos BI and production support. Hands-on experience with reporting and BI tools, especially the Cognos Suite v10 & 11 ( with Reporting MDX) Strong technical and functional knowledge of Data Warehouse and related software including design, development. Expert level proficiency in developing Data Integration and EDW solutions based on:-Data Integration: Informatica PowerCenter and ODI (good to have),
Database: Oracle, Progress or equivalent with hands-on experience of PL/SQL Strong communication and interpersonal skills required. Experience working with matrixed and geographically distributed teams, and an offshore/onshore collaborative environment. "
23,SENIOR AI DATA SCIENTIST (GENERALIST),AMARIS.AI PTE. LTD.,"$10,000to$15,000Monthly","Roles & ResponsibilitiesThe Data Scientist should have a Master or PhD degree in Computer Science, Statistics, Deep Learning or Machine Learning and a strong background in statistical methods such as Bayesian statistics, time series forecasting, and feature engineering. Candidates with an undergraduate degree and a demonstrable track record in these domains are encouraged to apply.
  If you have a passion for building state-of-the-art deep learning and machine learning models, this is your opportunity. RESPONSIBILITIES   Implement state-of-the-art deep learning and machine learning models
   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions   TECHNICAL SKILLS   Comfortable with core machine learning algorithms implementation and theory   Advanced in scripting languages (Python, R and UNIX Shell), Git project management, deep learning frameworks (PyTorch /Keras / TensorFlow..), and programming skills (Java or C++)   Can communicate clearly and cogently on concepts, processes and algorithms used   Ability to work in time-sensitive environments and to approach problems from different angles   Deep learning experience   DIFFERENTIATING FACTORS   A vibrant Github account with open-source repositories useful to the community   Experience at a corporate data science team, financial/investment analytics entity, or hedge fund
   Work with alternative data (e.g. news, social feeds, etc.)   A top ranking in online AI competition platforms such as Kaggle   Requirements  Implement state-of-the-art deep learning and machine learning models
   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions  "
24,"Network Engineer, Security & Data Entreprise",HTZ RESOURCES,"$5,000to$7,000Monthly","Roles & ResponsibilitiesYour New Role We are looking for a Network Engineer to design, implement, maintain, and support our growing network infrastructure.
 You will be part of a systems engineering team that is responsible for designing and developing scalable, maintainable, highly available network architectures that meet business objectives. 
 What Will You Do  This position is responsible to work with all technology team member to insure
proper design of the LAN, Wireless, MAN and WAN voice and data networks. Responsible for planning and implementing enterprise data network & security based projects. Responsible for leadership and training to lower level network engineers and technicians. Provide Level-2/3 support and troubleshooting to resolve issues. The Engineer is responsible to assist in the development of company policiesa nd procedures to support operations, security, and integrity. Select and implement security tools, policies, and procedures conjunction with the companys security team. Responsible for insuring the day-to-day operation, reliability, and integrity of the enterprise voice communications network. This includes the installation, maintenance, and management of all data network equipment such as router, LAN switch, firewall, wireless, servers, backup systems, network management and diagnostic tools, etc. Perform network maintenance and system upgrades including service packs, patches, hot fixes and security configurations  RequirementsWhat You Will Need to Succeed  4+ years implementation experience in Data Networking &amp; Network Security
architecture and deployment. Deep understanding of networking protocols (e.g., IPSEC, HSRP, BGP, OSPF, 802.11, QoS ) Technical or College Degree in Information Technology, Management or related field, and/or advanced networking certifications. Hands-on experience with monitoring, network diagnostic and network analytics tools Solid understanding of network &amp; security technologies: Hands-on network design and/or configuration experience with Cisco, HPE, Checkpoint, Palo Alto, Aruba, Juniper product, etc. Ability to quickly learn new or unfamiliar technology and products using documentation and internet resources. "
25,Smarthub Big Data Engineer,STARHUB LTD.,"$3,500to$6,500Monthly","Roles & ResponsibilitiesMaintain and support the SmartHub Big Data Platform and Infrastructure Support and maintain with other SmartHub systems and infrastructure specialists to perform the following:  Support and maintain offline systems for Big Data storage and analysis  Support and maintain near-line systems for serving data for production & project use  Develop extraction, transformation, and loading (ETL) processes  Work with Big Data Solutions and Application Product teams to identify and fix data quality issues  Responsible for day-to-day operation, administration, and maintaining of the assigned systems.
  Manage the Hadoop HDFS systems that include system administration, OS patching, troubleshooting, and maintenance  Maintain the high-performance and data integration of critical subscribers database  Render support to Network Operation Center on a 24/7 stand-by duty for fault investigation, escalation and resolution to system faults.  Outline, draft and implement operational procedure for efficient handling of System Fault.  Perform system tuning, system health check, alarm check & verification check to ensure optimal performance and continuous uptime.  Track incidents and perform management reporting.  Support new projects/integrations working with Operations.  Responsible for changes, releases, capacity planning and operation.  Other responsibilities include
 
 - Provide technical consultancy work like gathering user requirements and formulate the requirement specifications 
 - Support and maintain work-plan and implement application platforms for new services. 
 - Participate in proof of concept 
 - Participate in RFI, and RFP for vendor selections for new services or solution replacement of existing services Requirements Diploma/Degree holder in Telecommunications/Computer/Electrical Engineering from a recognized institution.
  At least 5-7 years working experience in a telecom or IT related environment.  Preferably experience in leading migration of Hadoop clusters to Cloudera Hadoop  Experience in leading and managing operation and maintenance of server systems and network equipment.  Experience in planning, formulating users requirement specification and system test and implementation of telecommunication services.  Good working knowledge with Big Data processing tools (e.g. Hadoop Cloudera//Pivotal/GreenPlum, ecosystems Hive /YARN/, Spark etc )  Good working knowledge in Operating Systems like Linux, Windows  Good working knowledge in virtualization technologies like VMWARE and etc.  Good working knowledge in Basic Programming  Linux Shell Scripting, Java etc.  Good working knowledge in Dell/EMC and Isilon storage servers, telco switches and routers  Good working knowledge in TCP/IP Networking and troubleshooting skill.  Strong technical and working knowledge in one or more of the following areas:
 
 - Dell/EMC/Pivotal Hadoop Technologies 
 - BI Applications
 
 - Cloud solutions & VM solutions 
 - Backup & Storage Solutions  Good management and communication skill is important, able to communicate with people of different level within in-house users and external partners/vendors/customers  Work independently with minimum supervision.  Supportive of team objectives and be a team player  Self motivated with strong drive and willingness to take on challenges"
26,DATA ENGINEER,RINGS.TV PTE. LTD.,"$4,000to$6,000Monthly","Roles & Responsibilities1. Participate in R&D and performance optimization of big data platforms; 2. Responsible for the construction and maintenance of big data platforms, including but not limited to BI systems, scheduling systems, metadata systems, development platforms, data analysis/mining platforms, etc.; Requirements1. Bachelor degree or above, computer related major 2. Familiar with data warehouse theory, with ability to comb with complex business requirements 3. Proficient in SQL development, proficient in one or more of relational databases such as Mysql 4. Proficient in Hadoop and MapReduce application development, proficient in one or more of big data development tools such as HBase, Hive, Storm, Impala, Kylin, spark, etc. 5. Be familiar with Linux system, have shell, python and other script development capabilities are preferred 6. Strong in learning ability, likes to study open source new technologies, has a team concept, and has the ability to solve problems independently."
27,Senior Data Scientist - F&R,THOMSON REUTERS ASIA PTE. LTD.,"$10,000to$15,000Monthly","Roles & ResponsibilitiesDo you like big data / Artificial Intelligence / emerging technologies? How do you feel about skunk works? 
 Thomson Reuters Labs, Singapore is located in the heart of Singapores Central Business District and leverages the vibrant innovation and FinTech ecosystem in Singapore to drive experimentation and fuel collaborative projects across Asia. (More info at labs.tr.com) This role sits within our Financial & Risk (F&R) business. 
On January 30, 2018, Thomson Reuters announced that it signed a definitive agreement to enter into a strategic partnership with private equity funds managed by Blackstone related to the company's F&R business. As part of the transaction, Thomson Reuters has agreed to sell a 55% majority stake in Financial & Risk and will retain a 45% interest in the business. Thomson Reuters will maintain full ownership of its Legal, Tax & Accounting and the Reuters News businesses. The transaction is expected to close in the second half of the year and is subject to specified regulatory approvals and customary closing conditions. When the transaction closes, this role will be included in the new F&R entity. 
Further information on this can be found at https://www.thomsonreuters.com/en/press-releases/2018/january/thomson-reuters-and-blackstone-announce-strategic-partnership-for-thomson-reuters-financial-and-risk-business.html What do we do? We experiment. We play with big data sets to discover what new products, services, or analysis we can create for our customers. You might be familiar with Reuters News, but you might not know that Thomson Reuters is also one of the leading sources of information for the worlds top companies in finance, risk, legal, tax and accounting. 
 The best part? We have data. Lots and lots of data. Over 60,000 TBs worth of data. Thats about 20,000 times more data than exists in Wikipedia. Come tinker along with us. Learn from Data Scientists in our global labs in Waterloo, Boston, London, Zurich, San Francisco and Cape Town. Pick the brains of PhDs and Masters grads with experience in big data, statistics, machine learning, natural language processing, artificial intelligence, and data visualization. 
 Thomson Reuters Labs  Singapore operates like a start-up within a large corporate. We partner with internal teams, external customers, and third parties, such as start-ups and academics, creating rapid prototypes and data-driven innovations that land in the hands of real users in just a few short weeks. 
 Key Responsibilities:  Scope and build proof-of-concepts / prototypes using data science techniques directly for TR customers Conceive, develop, and test algorithms with tools like R, Python, etc. Build external and internal relationships with technology and business leaders, working closely with colleagues to identify and shape ideas into compelling proposals that engage stakeholders Present proof-of-concepts to customers and grow and maintain relationships with key academic groups and start-ups, acting as an ambassador for TR Labs Work with external and internal partners to identify and deliver Thomson Reuters data and tools needed to build prototypes and proof-of-concepts Locate, clean and wrangle data. Integrate internal and external data sources using APIs  RequirementsCandidate must have:  Masters Degree or PhD in relevant technical field, such as computer science, statistics, finance, applied mathematics, or a related discipline. 5+ years industry experience in text mining, big data, or machine learning Experience producing and rapidly delivering minimum viable products. Building APIs or web-based prototypes. Experience in one or more of: - Text mining, NLP or data mining - Information extraction - Machine learning - Data visualization - Graph analysis - Use of APIs Experience working with programming and scripting languages such as: - Python - R - Scala - Java - C# - Experience with relational, NoSQL, or Graph databases. Engineering Experience: - Back-end infrastructure, Back-end engineering experience such as: - RabbitMQ, Kafka, Celery - Flask, Django - AWS - System design Ability to track down complex data integration issues, evaluate different algorithmic approaches, and analyze data to solve problems Demonstrated ability to effectively engage with business and technology stakeholders. Bonus: - 	 Big data analytics or visualization such as: - Spark - Hadoop ecosystem - NoSQL DB such as ElasticSearch, Solr - Web Technologies (e.g. HTML, JS, D3, etc) Understanding of Buy side, Sell Side  front office, middle office and back office operations.   "
28,ODC QA Software Engineer,ORACLE CORPORATION SINGAPORE PTE LTD,"$8,000to$15,000Monthly","Roles & ResponsibilitiesOracle Data Cloud was created in 2014 through the acquisition of BlueKai and was expanded through the acquisitions of Datalogix, AddThis, Crosswise and Moat. ODC helps advertisers connect with the right customer, personalize every interaction, and measure the effectiveness of each engagement. Powered by Oracle ID Graph, Oracle Data Cloud creates true cross-channel consumer understanding, so you know more about who your customers are, what they do, where they go, and what they buy.  The team, ODC QA Engineering is responsible for the design, implementation and maintenance of ODC QA platform and tools. The custom QA framework is used to run our functional and integration tests across all the ODC products. As a QA engineer, you will be using Java and scripting(shell/python) to help maintain and extend our platform. This means, testers will be using a common language for developing test scripts and we empower testers to write end-to-end tests with very minimal investment of time.  QA engineer will work in an environment where we take ownership and responsibility to test and certify ODC products. One should come up with testing strategies/approach and build utilities that facilitate, efficient and optimized test execution and automation. The engineer should be experienced in testing distributed applications and pipelines written using big data technologies. Due to the complexity of the business and volume, we expect the person to have skills of a Data scientist and use their formidable skills in math, statistics and programming.  Were looking for personable, adaptable, skilled and experienced engineers to join our team. You like a lot of variety in your job, love tackling the hard technology problems and are not fazed by change, and can both think strategically about the future as well as dig deep into problems affecting our users and business today.  Responsibilities.  Creating detailed, comprehensive and well-structured test plan and test cases  Estimating, prioritizing, planning and coordinating quality testing activities  Define testing scope and responsible for QA sign off and release to production.  Develop solid test automation suite, achieving complete test coverage.  Adapt to changing software and highly scalable micro services  Monitor & Analyze test execution reports to Identify, record, document thoroughly and track bugs  Interpret and implement quality assurance standards.  Analyze data to identify areas for improvement in the quality system. RequirementsRequirements.  BS Degree in Computer Science or related technical field  Programming experience in Java & J2EE Technologies  Experience developing cross browser automation using Selenium WebDriver  Strong understanding and working knowledge on any of the test frameworks.  Good fundamentals on REST architecture and testing experience of RESTful APIs  Strong fundamentals including an understanding of algorithms, data structures, and software design.  Proven work experience in software development and quality assurance  Strong knowledge of software QA methodologies, tools and processes  Experience in writing clear, concise and comprehensive test plans and test cases  Experience working in an Agile/Scrum development process  Experience with Performance and/or security testing is a plus.  Experience using TestNG, Mocha, Nightwatch.js etc, would be huge plus  Experience with RestAssured and superTest libraries would be desirable  Solid understand of Selenium Grid would be desirable  Experience with continuous Integration and continuous deployment tools (Jenkins, Hudson)  Expertise in distributed systems."
29,Senior Data Engineer,RAZER (ASIA-PACIFIC) PTE. LTD.,"$6,000to$7,000Monthly","Roles & Responsibilities Design, develop, test and deploy analysis, hypothesis, and machine learning models that uncovers insights to enhance business performances Design, implement, and manage data pipelines from end-to-end Collect, cleanse and transform data from multiple data sources for report generation and visualization Ability and desire to learn and pick up new tools and technologies for problem solving, enhancing analysis results/accuracy, and optimizing workflow efficiency Identify big data science technology, latest developments, training modules, etc. and be a custodian of personal training and development  Requirements Experience in programming languages such as Python, Scala or Spark is preferred Demonstrated experience applying and showing an understanding of machine learning algorithms used for classification, regression, clustering, recommendation system, etc. Developed and deployed applications running on public cloud systems such as AWS, Azure or Google Cloud Platform. Extensive SQL experience (MySQL, PostgreSQL, Hive, etc.) Experience working in Neural Network and other Deep Learning techniques is a plus Be independent and creative in problem solving
 "
30,"Vice President, Business Analyst - Data Services",Company Undisclosed,"$7,500to$11,250Monthly","Roles & ResponsibilitiesProven working experience as a data analyst, with experience in large data warehousing and Hadoop implementation projects in financial services industry Good functional knowledge of Retail bank, Wholesale & Private Bank products & business processes  Hands on experience of executing projects in Finance domain - expertise in financial reconciliation, GL unification, profitability, fund transfer pricing, budgeting, forecasting Experience with Credit Risk domain - computation of risk weighed assets, economic capital, S29, MAS, BASEL reporting, economic capital, cross border exposure Knowledge & experience with products such as SAP GL, OFSA (profitability, FTP), FITAS, ARF (Trade Finance & Accounts Receivables), Moodys RaY, Murex, Cash Management & Remittance would be of additional advantage  Good expertise in designing financial services data models & data modeling tools  Knowledge & experience of having used industry standards data models such as FSDM Knowledge & experience in designing normalized & dimensional models to support different analytical users  Hands on experience of doing data mapping across different layers in data architecture  from source to target state Good experience in implementing data governance processes  Experience in doing data profiling & implementing data quality rules using ETL tools like Informatica Data Quality Knowledge & experience with reference data management, data standards, expertise with Teradata MDM Experience of building business glossary & providing end to end data lineage using tools like Informatica Metadata Manager  Proven problem solving skills & analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy Exposure to Data Warehouse & Big data tools for Information Management  ETL & Data governance tools - Informatica PC, DQ, MM, Teradata GCFR, MDM RBMS - Teradata, Oracle, NoSQL Reporting - Qlik, OBIEE, Tableau, BO Cloudera administration suite Hadoop languages & tools  Spark, Python, R, Pig, Hue, Impala, Hive, Hbase, Informatica IDL, BDM, Kafka, Flume, Machine Learning Algorithms  Requirements Experience & knowledge of building security framework involving data classification & access controls in Hadoop and Teradata Good experience of implementing large scale, multitrack projects involving mix of waterfall and agile approaches Knowledge of defect management  leading defect triage, resolution & reporting Good attitude, team player, result driven, self motivated and keenness to learn Experience in handling large teams, demonstrated ability to learn fast and apply to project execution Good communication & interpersonal skills, ability to engage different stakeholders in business, operations & technology "
31,Data Center Engineer,PEOPLEBANK SINGAPORE PTE. LTD.,"$2,500to$4,000Monthly","Roles & Responsibilities Server mounting/installation Inventory Management Tracking
 Shipping/Receiving and Loading Dock
 Equipment Destruction
 Installation and Removal of IT equipment
 Device Validation
 Basic troubleshooting and repair (report) of IT equipment failures
 Cable Installation and Planning
 Device/Cable Validation
 Cable troubleshooting and repair
 Cable Installation and Planning
 Validation of cable material / patching sheet
 Maintain companys stock
 Hardware Planning
  Requirements 2-3 years of relevant experience in data center Smart hands support Work location: supporting few sites  Tai Seng, Serangoon, Jurong "
32,Engineer  /  Senior Engineer Factory Automation,GLOBALFOUNDRIES SINGAPORE PTE. LTD.,"$3,300to$5,500Monthly","Roles & ResponsibilitiesWe are looking for a skilled Data Engineer to join our analytics team. The ideal candidate has an eye for building and optimizing data systems and will work closely with our systems architects, data scientists, and analysts to help direct the flow of data within the pipeline and ensure consistency of data delivery and utilization across multiple projects. 
 Responsibilities: Work closely with other data and analytics team members to optimize the companys data systems and pipeline architecture Design and build the infrastructure for data extraction, preparation, and loading of data from a variety of sources using technology such as SQL and Scripting Will be required to Design, Implement, test and Support Reports and Dashboards within the agreed SLA. Build data and analytics tools that will offer deeper insight into the pipeline, allowing for critical discoveries surrounding key performance indicators and customer activity Always angle for greater efficiency across all of our company data systems. RequirementsGraduate degree in Computer Science, Information Systems or equivalent quantitative field and 5+ years of experience in a similar Data Engineer role. Preferably with 1-3 years of working experience with and extracting value from large, disconnected and/or unstructured datasets Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management Strong interpersonal skills and ability to project manage and work with cross-functional teams Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing big data data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Familiar with roles of a Big Data Engineer/Data Scientist Experience with the following tools and technologies: Hadoop, Spark, Kafka, Intermediate or better SQL and NoSQL databases skill sets Data pipeline/workflow management tools such as Azkaban and Airflow AWS cloud services such as EC2, EMR, RDS and Redshift Stream-processing systems such as Storm and Spark-Streaming Object-oriented/object function scripting languages such as Python, Java, C++, etc. Knowledge of data manipulation through ETL and modelling tools and coding language Web development skills"
33,Data Analyst,APBA PTE. LTD.,"$4,000to$5,000Monthly","Roles & Responsibilities Handle data extractions from multiple data sources and analyze large volume of data to address key business questions, create/ refine customer segmentation and identify new areas of growth. Create reports and dashboards of Leading Indicators that help Business Leaders look for growth opportunities and nip problem areas in the bud quickly.  Requirements At least 3 years experience in IT and Data Analysis Experience in Statistical Tools: R, Base SAS, Amazon ML, Portrait Miner (Or any Statistical tools)     Experience Data Analysis: SQL Query for Data Cleaning and Analysis (MySQL) Joining multiple datasets and unions (MySQL) Data Aggression if necessary   Data Modelling Tasks:     Must know Market Basket Analysis (Apriori Algorithm) Support Confidence Metrics (NBO Model Outputs) Knowledge if Regression and Decision Trees (Single category Upsell/Cross Sell) Automate code through scheduling after monthly Aggregated Data Dump Analysis of outputs for Business consumption Presentation skills (PPT)   "
34,Data Analyst,RINGS.TV PTE. LTD.,"$3,000to$5,000Monthly","Roles & Responsibilities1 Initiate high impact data science projects and make actionable plan 2 Research and design the core algorithm 3 Develop prototype and some production API 4 Liaise with product owner and engineers to deliver 5 Analyse the performance of data science projects and continuously improve Requirements1 PhD in Machine Learning related field, or Master with rich relevant experience 2 Familiar with general ML methods and expert in one of the following field: Deep learning Recommender Supervised learning and feature engineering Personalization Time series analysis 3 Proven success in applying data science methodologies to business 4 Proficient in a data science language like Python, R, or Scala 5 Familiar with machine learning packages like scikit-learn, TensorFlow etc. 6 Ability to develop stable production API is a plus 7 Logical & systematic, team player, fast learner"
35,IT - SENIOR BIG DATA ENGINEER,Company Undisclosed,"$5,000to$8,000Monthly","Roles & ResponsibilitiesResponsibilities: Be part of a DevOps team that design, build and maintain innovative Smart Manufacturing solutions and Big Data platform. Lead and participate in Agile development lifecycle for software & solution related to Smart Manufacturing and Big Data platform. Manage projects scope, goal and deliverables and track timelines of implementation to meet expectation. Work with Data Science within company to architect solution and drives innovation. Manage system health to ensure high system availability and perform review for capacity expansion. Communicate, collaborate and coordinate on Smart Manufacturing and Big Data related activities to various level of stakeholders and senior management. RequirementsRequirements: Bachelors or Masters degree Computer Science, Electrical & Electronics/Computer/Software Engineering, Information Systems or related fields. The candidate should have at least 2-5 years of technical experience in Information Technology with at least 1 years in Big Data, Data Warehousing or Business Intelligent technology. Candidates with over 4 years of relevant experience will be considered for a senior position. Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in two or more of the following areas: Hadoop based technologies such as HDFS, MapReduce, Hive, MongoDB, HBase, Spark etc. Data warehousing solutions and latest (NoSQL) database technologies. Good knowledge in some following programming or scripting languages like Java, Linux, Matlab, C#/C++, Python, Perl and/or R on Linux/Windows platforms. Experience in Big Data visualization and reporting software like Tableau. Experience in operational support in delivering Big Data solutions. Experience in designing ETL/BI solutions using Microsoft SSIS, Informatica or having DB programming experience (TSQL, PLSQL) will be advantageous. Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job. Applicant who demonstrated good software project management skill and had exposure to agile development methodology will be advantageous."
36,DATA SCIENTIST,Company Undisclosed,"$5,000to$11,000Monthly","Roles & Responsibilities Implement new statistical or other mathematical methodologies and devise possible solutions from data analytics as needed for specific projects. Collaborate with third parties to research and develop statistical learning models for data analysis. To deploy an in-house data platform and operationalize analytic models on it. To take ownership and lead development role on the current end-to-end technology stack (back-end) and scale to enterprise level. Communicate results and ideas to key decision makers (CTO and business sector). To guide and collaborate with data engineer and oversee the project progress.  Requirements Min. Masters Degree in Computer Science, Statistics, Applied Math or related fields 5+ years of practical experience with ETL, data processing and data analytics Proficiency and hands-on experience in machine learning, including data mining, statistical analysis, pattern recognition and predictive modeling. Extensive experience in software development cycles and excellent programming skill with scripting languages e.g. Python, Java, Scala, R. Familiar with state-of-the-art big data technologies, e.g. Apache Hadoop, Spark, Kafka, MongoDB, lambda architecture. Prior experience with AWS framework is preferred. Background in medical sciences an asset. Prior startup or entrepreneurial experience would be a bonus. "
37,Data Scientist,MEDIACORP PTE. LTD.,"$5,500to$8,000Monthly","Roles & Responsibilities Serve as primary source of data insights supporting internal and external constituencies Analyse and translate data findings into meaningful, actionable insights  including synthesizing relevant insights from different customer touch points and data sources Lead, design and implement quantitative analytical frameworks, including scalable predictive models, customer segmentation and marketing mix optimization that improve business performance and customer engagement Institute and adopt best practices in data science, platforms and approaches. Establish internal organisational standards and benchmarks Work with other teams in Mediacorp to understand business needs, document data and data integration requirements, and resolve conflicting business/data architecture rules. Ensure compliance with internal customer contact governance policies and drive closed-loop measurement through smart data capture. Become an internal authority on Mediacorps data tools and resources. Function as a power user of data analytics to guide other business users. Support ad-hoc business intelligence and other strategic initiatives  Requirements PhD or MS degree in Statistics, Mathematics, Machine Learning, Operations Research, CS, Econometrics or related field. Minimum 5 years hands-on experience in data science. Demonstrated expertise in developing and implementing a full range of analytical techniques to address commercial challenges. Proficiency in at least one statistical analysis tool such as R or Weka. Demonstrated experience with distributed databases and query languages. Proficiency in at least one programming language (preferably Java, C++, Python, or Perl). Must possess exceptional business judgment to identify core business objectives; synthesize and interpret disparate quantitative information, develop meaningful insights and clearly disseminate to key stakeholders Strong project management and time management skills. Able to lead data initiative independently with minimal supervision. Relevant experience in web, video, mobile or adtech domain is a plus. "
38,Data Engineer,TOTAL E&P ASIA PACIFIC PTE. LTD.,"$6,000to$12,000Monthly","Roles & Responsibilities Supervise data loading and guarantee the data availability and quality in the interpretation software, in line with the GeoInformation rules and best practices. Guarantee the quality and the preservation of the data, in line with the GeoInformation rules and best practices. Evaluate the requests from internal or external customers (from a technical and cost perspective) Monitor the software evolution and suggest some improvements Edit and prepare data for preservation and manage the publication Suggest data bases, describe, select or request the creation of tools useful for the activity. Follow the implementation of new products Organize study and reference data bases Guarantee the application of the rules, the deadlines and the procedures Guarantee the data bases organization, in line with the GeoInformation and HSE rules Suggest and write procedures for managing data flows. Write activity follow-up reports for the entity Lead and coordinate projects and complex activities Train 
on the job
 users and new employees  Requirements Guarantee the organization and the publication of the Geosciences data in order to contribute to the success of the interpretation studies Provide HQ and affiliates with solutions adapted to the users needs for data preservation Develop the usage of GIS in HQ and affiliates, and follow up the technical evolutions Convey the GeoInformation know-how within the Group Diploma
: BSc of Msc Professional experience
: 6 to 15 years 1 year contract "
39,"Senior Manager - Big Data, Advisory",ERNST & YOUNG ADVISORY PTE. LTD.,"$8,000to$16,000Monthly","Roles & ResponsibilitiesEY Data and Analytics is the data and advanced analytics capability within EY Asia-Pacific.
 We have vibrant practices in Australia, New Zealand, Singapore, Hong Kong, Korea, The Philippines and Malaysia. EY Data and Analytics creates intelligent client organizations using data & advanced analytics.
 We go beyond strategy and provide end to end implementation of real life data environments and have some of the best architects, project managers, business analysts, data scientist, big data engineers, developers and consultants in the region.

 
 Due to our continued growth we are looking for a talented, inquisitive and proactive Big Data IM join our team. 
 
 ABOUT YOU 
 As a Senior Manager in EY Data and Analytics team, you will deliver value-added services to our clients and you are required to be specialized in some or all of the following areas:  Lead and
manage all Analytics related
solutions to Ernst & Young clients in the APAC region. Develop, build and manage business pipeline and client relationships. Contributing your expertise to strategy and roadmaps Communicate effectively with the EY Partners, the team and the client regarding the progress of the project and be a role model to the team members in exhibiting the Ernst & Young best practices.  At Ernst & Young, we know it's your point of view, energy and enthusiasm that make the difference.
 RequirementsCLIENT RESPONSIBILITIES:  Lead clients engagements. Work effectively as a team and project director, sharing responsibility, providing support, maintaining communication, and updating senior team members on progress. Help prepare reports and schedules that will be delivered to clients and other parties. Develop and maintain productive working relationships with client personnel. Build strong internal relationships within Ernst & Young Advisory Services and with other services lines across the organization. Generate new client leads by leveraging on existing relationships and building new ones Lead business development initiatives from leads to qualification to proposal development and client presentations.  
 PEOPLE RESPONSIBILITIES:  Conduct performance reviews and contribute to performance feedback for staff. Contribute to people-related initiatives including recruiting and retaining staff. Contribute, guide and develop technical and functional skills of staff. Understand and follow workplace policies and procedures.  
 REQUIREMENTS:   Bachelor degree and above in Analytics, Information Systems Management, Computer Science or related fields. Hands on experience in implementing data integration processes, designing and developing data models(ER/Dimensional/Vault), designing, developing and building in detail ETL/ELT processes or programs. Contributed in at least 2 phases of SDLC lifecycle and experience in Big Data, data warehouse, data analytics projects, data migration, change management process, and/or any IM (Information Management) related works. Experience with Hadoop Technologies such as HDFS/MapRFS, Map Reduce(II), Advanced HDFS ACLS, Hive, HBase, Cassandra, Impala, Spark, Drill, Sentry, Sqoop, Flume, Kafka, Storm, Zookeeper and zkClient tool Good understanding on Cloudera or Horton Works or MapR Hadoop Distribution with deep understanding of administration concepts Experience in working with RDBMS technologies such as, Oracle, Microsoft SQL Server, PostgreSQL, DB2, MySQL etc. Experience in MPP database technologies such as Teradata Hands-on experience on Spark, SparkSQL, Hive QL, Drill QL, Impala, Spark Data Frames and Flink CEP, Flink TableAPI&SQL as ETL framework Hands-on programming skill on Scala/Python using Spark/Flink Framework Strong knowledge of
Big Data stream ingestion and IoT streaming using Flume, or Kafka, Storm, MQTT, RabbitMQ Good understanding Spark Memory management with and without Yarn memory management Should have basic understanding on Cloudera Manager or HortonWorks Ambari and MapR Control System Should have experience developing and designing in one or more NoSQL database components and objects using Cassandra, Mongo, HBase, CouchDB/Couchbase, Elasticsearch Should have experience developing and designing in one or more NoSQL database technologies such as Cassandra, Mongo, HBase, CouchDB/Couchbase, Elasticsearch etc. Should good working knowledge of HCatalog and Hive Metadata. Should have working knowledge of Kerberos authentication tool Experience in commercial ETL tools like Talend, Informatica or Alteryx will be added advantage Greenplum, IBM Pure Data etc. will be an added advantage Experience in working with RDBMS technologies such as, Oracle, Microsoft SQL Server, PostgreSQL, DB2, MySQL etc. Experience in MPP database technologies such as Teradata, Greenplum, IBM Pure Data etc. will be an added advantage Good knowledge of data warehouse and data management implementation methodology. Good knowledge of the Information Management framework, including operating model, data governance, data management, data security, data quality and data architecture. Knowledge and experience in
 data visualisation concepts using tools such as SAS Visual Analytics or WRS, Tableau, Microsoft PowerBI or Reporting Services, IBM Cognos, SAP Business Objects, etc. will be an advantage. Ability to pick up new tools and able to be independent with minimal guidance from the project leads/managers. Strong analytical and creative problem solving capabilities. Ability to establish personal credibility quickly and demonstrate expertise. Ability to create a positive learning culture, coach and develop team members.  
 ADDITIONAL REQUIREMENTS:   4 to 10 years of experience in data warehouse, data analytics projects, change management process, and/or any IM (Information Management) related works. Delivered at least two (2) full SDLC lifecycle projects. At least one of the industry or domain experiences in Banking/ Telecommunications/ Consulting Preferably with experience in implementation best practices involving data management, data reconciliation, data duping, scheduling, etc. Able to assess design considerations in the aspect of data management and integration Experience with Agile/SCRUM/Kanban software implementation methodology Should have good knowledge in DevOps engineering using Continuous Integration/Delivery tools such as Docker, Jenkins, Puppet, Chef, GitHub Atlassian Jira etc. Certification in any of Hadoop Big Data tool/technology, data integration, data management, or visualisation tools is an added advantage. Knowledge about the infrastructure paradigms such as OS, network etc. is an added advantage.  
 ABOUT US The EY Data and Analytics team are specialists in information management, advanced analytics and business intelligence. We implement the information-driven strategies and systems that offer the highest return on investment, profitability, and service or policy outcomes for our clients. Our consultants work to create a lasting organisational culture that encourages people to use information and technology more creatively and more intelligently to get better business results.
 

 
 WHY US We work with some of the worlds most influential businesses on many of their most exciting Bigdata and IoT projects. Our sheer scale, scope and reach will provide you with the experiences, challenges and contacts that can inspire you for life Our culture means you can succeed whatever your background, work to your natural strengths, and learn from a remarkably diverse and talented group of people in a dynamic and collaborative global business environment 
 
 
 WHAT WORKING AT EY OFFERS EY offers a competitive remuneration package commensurate with your work experience where youll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements, where this may be needed, guided by our FWA Policy. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way thats right for you 
 
 ABOUT EY  As a global leader in assurance, tax, transaction and advisory services, were using the finance products, expertise and systems weve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, well make our ambition to be the best employer by 2020 a reality. 
 If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now"
40,Data Scientist,CERTIS CISCO SECURITY PTE. LTD.,"$6,000to$10,000Monthly","Roles & ResponsibilitiesOverview As a Data Scientist in the Technology Planning & Development Office, you will lead advanced data analytics and AI projects across the organization. You will support our business units to analyze large-scale structured and unstructured data and develop Machine Learning (ML) applications across various fields of computer vision, natural language processing and operations research. You will be part of a team of high-performing data science professionals, ranging the competency gamut from data engineers, data analysts, business analysts, application developers and fellow data scientists. You will lead cross-functional teams to identify business opportunities, optimize operational and internal business processes and deliver cutting-edge AI applications.  Responsibilities  Provide relevant subject matter expertise across AI/ML/Deep Learning domains in the form of algorithm analysis, model building, training and evaluation, and systems best practices for data products Create AI applications that support our security operations, such as Facial Recognition, Video/Image Analytics, Natural Language Processing (chatbot), Graph Analysis Keep abreast of the latest trends and developments in the fields of AI, Data Analytics and Big Data; to evaluate potential technology solutions and incorporate those into our Data Platform whenever feasible Craft compelling data stories to get buy-in from stakeholders so that analytics results can be translated into actionable decisions Conduct ML and Data Analytics workshops for non-technical staff within the organization as part of the teams effort to inculcate a data-driven culture Mentor and guide junior data science teammates to elevate their competencies All other duties assigned by your reporting officer  RequirementsQualifications  Postgraduate degree (Masters, Ph.D.) with a specialization in Computer Science,
  Engineering, Mathematics or Statistics Setting or research fieldAt least 2 years of experience in an advanced analytics / AI role in a corporate  Strong mathematical and statistical foundations  Skills and Experiences  Proficient with at least two of the usual suspects of data analytics  Java, Scala, Python, R, MATLAB, Octave, Julia Comfortable operating in the Unix/Linux environment for automating processes
with shell scripting Understanding of relational (SQL) and NoSQL databases Familiar with data visualization techniques and tools, e.g. D3.js, Tableau Experience with Big Data technologies such as Hadoop (MapReduce and YARN), Pig, Hive, Spark, Storm, Presto "
41,Data Engineer  /   Scientist,MATCHMOVE PAY PTE. LTD.,"$3,500to$7,000Monthly","Roles & ResponsibilitiesAre you the One?  MatchMove Pay, one of the fastest, award-winning Fin-Tech company, is looking for a couple of experienced Data Engineers to work on in-house data warehouse projects and data modelling.  Job Responsibilities :  - Build the data warehouse infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources on AWS technologies. - Maintain compliance of the data warehouse with MatchMove data architecture policy. - Responsible for data modelling and validation of master data with original data sources. - Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability - Work with stakeholders including the Executive,
 Finance, Product and Engineering teams to assist with data-related technical issues and support their data infrastructure needs. 
 Requirements- Good programming experience in Python - Knowledge of information retrieval using SQL, java or C++ - Experience with AWS data technologies such as Redshift, Glue, Spectrum, Quicksight. - Well versed with data modelling and data warehousing. - Working knowledge of message queuing, stream processing, and highly scalable data stores. - Knowledge about Apache Spark or Hadoop would be an advantage. - Self-starter
and committed to working in fast paced environment 
 Culture in MatchMove :
  - To work in a fast-moving startup, fun and yet professional environment that recognizes and rewards individual contributions and also team success.
 - To work with highly motivated people who are totally focused on winning by combining great teamwork, rapid execution and an uncompromising approach to quality and customer satisfaction.
 - We strongly encourage Innovation, Collaboration, Creativity, and Initiative.
 - We work in a collaborative environment where you can talk to the CEO anytime!
 - Be A Part of the MatchMove Family! Check us out our Facebook page 
 Personal Data Protection Act : By submitting your application for this job, you are authorizing MatchMove to: a) Collect and use your personal data, and to disclose such data to any third party with whom MatchMove or any of its related corporation has service arrangements, in each case for all purposes in connection with your job application, and employment with MatchMove; and b) Retain your personal data for 1 year for consideration of future job opportunities (where applicable for relevant unsuccessful job applicants)."
42,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a capable and responsible scientist to work on and make contributions in the area of big data management and analytics, spatial-temporal data analytics, predictive analytics in time series data etc. These research areas has wide applications, such as smart city, IIoT, manufacturing, healthcare. Successful candidate will be given opportunities to participate in projects bringing innovation to various domain, such as advanced manufacturing and engineering (AME) domains and urban solutions and sustainability (USS) domain, and economic sectors including that of the financial service industry entities. In particular, successful candidate will be involved in the execution of both industry projects and research projects. In addition, the candidate is also required to participate in the drafting of grant proposals and project scoping with industrial partners and/or public sector entities. Overall, as a member of the Data analytics department in I2R, the successful candidate will have ample opportunities doing cutting-edge research, and solve real-world problems in collaboration with universities, industry and/or public sector entities. Requirements PhD in Computer Science, Computer engineering, Mathematics and statistics, data science intensive programs with expertise in one or more of the following areas: Data mining, data management, machine learning etc Entry level candidate with relevant experience may apply Ability to work independently to innovate and develop prototypes to demonstrate the feasibility of research ideas Good knowledge on data analytics/machine learning/ data mining and experiences in solving real-world data science problems Proficient in Python, R, Matlab, C++ or Java Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills Prior experience with trajectory data or time-series data is a big plus Good knowledge of big data technology, such as Hadoop, Spark, Storm, is a big plus Prior experience with AME industry is a plus  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
43,"AVP, BigData Engineer, Group Consumer Banking and Big Data Analytics Technology (180000J9)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & ResponsibilitiesAs a Senior Data Engineer you'll be a Machine Learning and Data Engineering Specialist and help us discover the information hidden in vast amounts of data. You'll help us make smarter decisions to deliver even better products and apply data mining techniques and statistical analysis to build high quality prediction systems integrated with our products.   Responsibilities
  Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud.
 Move architecture and implementation through the development pipeline, from research to deployment Work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics.
 Analyze source data and data flows, working with structured and unstructured data. Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends Analyze and visualize diverse sources of data, interpret results in the business context and report results clearly and concisely. Apply data mining, NLP, and machine learning (both supervised and unsupervised) to improve relevance and personalization algorithms. Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products. Build and optimize classifiers using machine learning techniques and enhance data collection procedures that is relevant for building analytic systems. Discover data sources, get access to them, import them, clean them up, and make them model-ready. You need to be willing and able to do your own ETL. Create and refine features from the underlying data. Youll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then youll lather, rinse and repeat. Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders.  Requirements 10+ years of Experience in one or more areas of big data and machine learning The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles. Development experience in Java/Scala and pride in producing clean, maintainable code Practical experience in clustering high dimensionality data using a variety of approaches Real world experience in solving business problems by deploying one or more machine learning techniques Experience creating pipelines to analyze data, extracted features and updated models in production. Independence and self-reliance while being a pro-active team player with excellent communication skills. Hands-on development with key technologies including Scala, Spark, and other relevant distributed computing languages, frameworks, and libraries.
 Experience with distributed databases, such as Cassandra, and the key issues affecting their performance and reliability.
 Experience using high-throughput, distributed message queueing systems such as Kafka. Familiarity with operational technologies, including Docker (required), Chef, Puppet, ZooKeeper, Terraform, and Ansible (preferred).
 An ability to periodically deploy systems to on-prem environments.
 Mastery of key development tools such as GIT, and familiarity with collaboration tools such as Jira and Confluence or similar tools.
 Experience with Teradata SQL, Exadata SQL, T-SQL Strong experience in graph and stream processing Experience in migrating SQL from traditional RDBMS to Spark and BigData technologies Experience in building language parsers using ANTLR, query optimizers and automatic code generation In-depth knowledge of database internals and Spark SQL Catalyst engine "
44,Data Engineer,CARGILL ASIA PACIFIC HOLDINGS PTE. LTD.,"$5,000to$8,000Monthly","Roles & ResponsibilitiesThe Data Engineer within the regional delivery portfolio will work closely with business partners, Global IT, CBS and 3rd party partners to enable the delivery of process, data, and technology solutions.
 You will work with the entire Global IT delivery eco-system to understand data, business requirements, create designs, and test solutions to ensure they meet business needs. As a skilled professional in data and reporting, systems & process design, you will provide solid data and reporting design, system designs, and quality solutions to solve various business requirements.
 You will expertly manage low to medium rigor projects or work streams thoughout the entire project lifecycle and 
use strong communication skills to deliver effective presentations of the solution detailing data, process, and system design to audiences of all sizes. To be successful you will leverage common solutions and processes by following Global IT design to deliver solutions and gain knowledge of the solution(s) and business processes for an assigned Regional Delivery Portfolio of either:  Trading ERP Operations Supply Chain (OSC) Functions / Customer Facing  You will have the ability to design solutions by mapping customer business problems and data to reusable end-to-end business application solutions, engage in business decision discussions related to agility, business value, data, and business processes. You are an individual who is resourceful, confident under pressure, 
has demonstrated competence in expectation management, and a passion for the business through professionalism and striving for excellence in all aspects of the business experience. This position is expected follow
 the Cargill Project Delivery Process and Requirements Analysis and Solution Design process framework.
 50%






 Analysis & Requirements Gathering
  Elicit requirements using interviews, document analysis, requirements workshops, surveys, site visits, business process descriptions, use cases, scenarios, business analysis, task and workflow analysis. Elicit functional and non-functional (performance, availability, security, accessibility, cross-browser compliance, data) requirements using a methodology most appropriate for the context of each project, such as Joint Requirements Planning (JRP), Joint Application Development (JAD). Proactively communicate and collaborate with external and internal stakeholders to analyze information needs and functional requirements and deliver the following artifacts as needed: Business Requirements Document, Use Cases, data requirements, Screen, and Interface Designs. Facilitate requirements discussions with key stakeholders Communicate and clarify the requirements to the design and development resources. Assist in translating business requirements into functional design specifications Clarify and improve the business processes and data impacted by the technology changes that are part of assigned 
projects. Particiate in the evaluation of system changes for downstream system and/or organizational impacts Plan for acceptance of solution (change management, communication, training needs) Provide subject matter expertise in assigned business process areas  20%






 Solution Design  Create solution designs across process, data, and technology that meet business requirements and adhere to relevant standards and principles, leverage common tools and processes, and meet cost/delivery objectives. Consider in the design, the business implications of the application of technology to the current and future business environment. Perform reviews with key stakeholders throughout the design lifecycle to ensure alignment on solution designs and requirements. This may include but is not limited to the following activities: design reviews, testing execution, data validation, deployment verifications, customer satisfaction reviews, etc. Create supporting solution design documentation to ensure sustainment of the solution and business capability, support solution implementation as necessary. Develop requirements specifications according to standard templates, using natural language. Participate with developers and subject matter experts to establish the technical vision and analyze trade-offs between usability and performance needs. Be the liaison between the business, technology teams and support teams. Actively participate in discussions on solution options and business partner decision making to minimize the amount of project investment divergence from target architecture  15%

 



Business Partnership  Work with businesses to identify and confirm connections between business goals, 
strategies,process, 
data, and technology investments required to achieve them. Engage with and influence business units on their assumptions of how they will successfully execute their plans Create and maintain strong working relationships with technology teams, functional counterparts, vendors and business partners. Effectively engage stakeholders in change management activities  
 15%




 Project Delivery Responsibilities  Manage workload and priorities to deliver agreed upon project milestones Provides input to staffing plans at the project-level to identify key / required skills Ensure traceability from business requirements through application testing and work with offshore development and QA teams clarifying requirements. Deliver presentations and training of solutions to stakeholders and end users Holds project team resources accountable to their deliverables and ensures project execution. Prepare high and detailed level estimations of effort in order to achieve a preferred solution. Provide guidance and oversight during requirements, design, build, and test phases.  RequirementsMinimum Required Qualifications  Bachelors degree in Business Administration, Computer Science or Management Information Systems; OR equivalent experience 3 years experience in diverse operational, development and/or business roles 3 years experience collaborating with project
 teams to define business requirements and deliver solutions that meet business goals 3 years experience in developing integrated solutions involving process, data, and technology 1  3 years expereince using Visualization tools such as Tableau and Power BI 1  3 years background in User Experience and User Interface. Ability to travel up to 20%  Preferred Qualifications  3 years experience across various businesses and project types (including custom software development, COTS and SAAS implementation, O&M support). 2 years experience in Use Case diagramming, Business Process Modeling (BPM) and User Stories development Experience working in a business role including mergers and acquisitions Experience with in-house developed and package implementations. Knowledge of and experience with Change Management, industry certification (e.g ITIL, six sigma etc) Knowledge of data access framework, data processing pipeline tools , and or other ETL knowledge. Experience with numerical algorithms, data structures and statistics Experience dashboard creation experience from scratch.  Success Attributes  Strong analytical skills required, including a thorough understanding of how to interpret customer business needs and translate them into application and operational requirements. Ability to influence peers and leadership stakeholders Strong written and verbal communication skills, ability to communicate technical and business information effectively to both technical and non-technical people. Strong project management, planning and organizational skills Ability to quickly comprehend the functions and capabilities of new technologies Demonstrated ability in identifying and developing strategies to address change management issues Business fluency in English "
45,Data Scientist,IBM SINGAPORE PTE LTD,"$7,000to$10,000Monthly","Roles & ResponsibilitiesJob Description We are in a data science renaissance. Companies that embrace data science will lead and those who do not will fall behind. To help IBM's clients lead, we are building an elite team of data science practitioners to help them learn how to succeed with data science. The team will include data engineers, machine learning engineers, operations research / optimization engineers and data journalists. You will engage directly in solving real-world data science problems in a wide array of industries around the globe with IBM clients and internally to IBM. The elite team of data scientist will work with other IBMers and client data science teams to solve problems in banking, insurance, health care, manufacturing, oil & gas and automotive industries, to name a few. 
 Youll spend time on the following:  You will design and develop processes and systems to consolidate and analyze unstructured, diverse data sources to generate actionable insights You will work with the IBM Client and IBM cross industry teams to identify questions and issues for data analysis and experimentation You will use machine learning to build models that can address a few areas such as user segmentation, churn, affinity, and conversion rates among others You will develop and code software programs, algorithms, and automated processes to cleanse, integrate, and evaluate large datasets from multiple disparate sources Identify meaningful insights from large data and metadata sources; interpret and communicate insights and findings from analysis and experiments to clients/IBM teams  RequirementsRequired  A Degree in a quantitative field (Statistics, Mathematics, Operations Research, Economics) or a degree in Computer Science 3-5 years of experience in working with data sets to build statistical models Excellent understanding of machine learning techniques and algorithms such as (Logistic Regression, Decision Trees, Random Forrest, Support Vector Machines, Clustering) Experience with common data science languages and libraries such as R, Python (NumPy, Pandas, Scikit), Weka, MatLab, etc. Skills in applied statistics skills, such as distributions, statistical testing etc. Expertise on machine learning methodology (data preparation, feature engineering, error metrics, model selection and validation) Proficiency in using query languages such as SQL and/or HiveQL Great communication skills  Good to have  Experience with NoSQL databases such as MongoDB, Cassandra, HBase Experience with distributed computing tools like the Hadoop stack, Spark, Pig, Hive etc. Software development skills in one or more high level languages (C#/C/C++/Java/.Net), one or more scripting languages (Perl/Shell) Experience with AWS or Azure Deep Learning frameworks (TensorFlow, Caffe, CNTK, Torch etc.)  
"
46,APAC Data Scientist,UPS ASIA GROUP PTE. LTD.,"$5,256to$7,008Monthly","Roles & ResponsibilitiesSummary The Data Scientist implements advanced analytics models and solutions to yield predictive and prescriptive insights from large volumes of structured and unstructured data. He/ She works with a team that is responsible for researching and implementing advanced analytics models utilizing a diverse set of techniques. He/ She leverages data and Artificial Intelligence (AI)/ Machine Learning (ML) techniques and algorithms to predict an outcome based on a learned set of historical events. The Data Scientist has experience applying models to moderate to large scale problems. Responsibilities  Develops data design based on exploratory data analysis to meet stated business need. Defines key data sources from UPS and external sources to deliver models. Writes code to collect and manipulate data from multiple data sources. Works with team to select and implement model development process from statistics and machine learning to answer business problems. Defines model KPI expectations and validation, testing, and re-training of existing models to meet business objectives. Reviews and creates repeatable solutions through written project documentation, process flowcharts, logs, and commented clean code to produce datasets that can be used in analytics and/or predictive modeling. Synthesizes insights and documents findings through clear and concise presentations and reports to inform stakeholders. Works with team to present operationalized analytic findings and provide recommendations. Develops data features that will serve as inputs to Artificial Intelligence (AI)/Machine Learning techniques to meet stated business requirements. Explores data to determine correlation of data to domain classification or regression problem. Develops procedures to monitor model and production system performance/integrity. Supports analysis and integration of tools and methods to provide desired results from models and requirements. Provides consultation to functional partners to support the design of planning systems. Creates technical documentation in compliance with internal Software Development Lifecycle to communicate and update project teams and stakeholders. Leverages analytics and visualization tools to design and present information to drive fact-based decision making.  RequirementsSkills and Qualifications  Demonstrates extensive knowledge of statistical sampling, tests, and analyses and chooses the most appropriate method Demonstrates extensive knowledge of multivariate and generalized linear models and time series models Demonstrates an ability to interpret results and draw conclusions from analyses; troubleshoots errors in data, models, and interpretation; creates processes for improving the integrity of existing data. Strong communication skills both oral and written. Strong project management skills, Project Management Office (PMO) or similar training or certification. Education or experience in disciplines associated with computer science, data science including advanced analytical techniques, data architecture, machine learning and associated mathematics and statistical capabilities. "
47,Data Engineer,MOZAT PTE. LTD.,"$3,500to$5,500Monthly","Roles & Responsibilities1. Participate in R&D and performance optimization of big data platforms; 2. Responsible for the construction and maintenance of big data platforms, including but not limited to BI systems, scheduling systems, metadata systems, development platforms, data analysis/mining platforms, etc.; Requirements1. Bachelor degree or above, computer related major 2. Familiar with data warehouse theory, with ability to comb with complex business requirements 3. Proficient in SQL development, proficient in one or more of relational databases such as Mysql 4. Proficient in Hadoop and MapReduce application development, proficient in one or more of big data development tools such as HBase, Hive, Storm, Impala, Kylin, spark, etc. 5. Be familiar with Linux system, have shell, python and other script development capabilities are preferred 6. Strong in learning ability, likes to study open source new technologies, has a team concept, and has the ability to solve problems independently."
48,Data Platform Engineer,SILOT PTE. LTD.,"$4,000to$8,000Monthly","Roles & ResponsibilitiesRole 
 As data engineer at Silot, you design and implement
distributed backend services that processes data in real-time, with focus on scalability, data quality and integration of machine learning. 
 You feel natural at extracting information out of heterogeneous data from many sources. You can
plan, build and maintain distributed, service-oriented and event-driven data platform for real-time processing. You like delivering accurate data components that people rely on. You optimize architecture and processes for performance and stability. 
 To visualize what this position is like, think ""building systems,"" not ""processing data"" (even though your day will involve aspects of both). RequirementsSkills & Qualifications 
 Requirements:  Excellent computer science knowledge Working experience in designing and building big data platforms (distributed filesystems, distributed databases, batch processing frameworks, stream processing frameworks, message queues, job scheduling) Expert knowledge of
scalable architecture for real-time processing Experience ensuring data quality and compliance Experience with DevOps and continuous integration Experience in agile practices, test-driven development Fluent written and spoken English  Good to have:  Good documentation skills Experience in Fintech Experience with machine learning "
49,Big Data Engineer,RAZER (ASIA-PACIFIC) PTE. LTD.,"$4,500to$6,500Monthly","Roles & Responsibilities Design, develop, test and deploy analysis, hypothesis, and machine learning models that uncovers insights to enhance business performances Design, implement, and manage data pipelines from end-to-end. Collect, cleanse and transform data from multiple data sources for report generation and visualization. Ability and desire to learn and pick up new tools and technologies for problem solving, enhancing analysis results/accuracy, and optimizing workflow efficiency Identify big data science technology, latest developments, training modules, etc and be custodian of personal training and development.  Requirements Experience in programming languages such as Python, Scala or Spark is preferred. Demonstrated experience applying and showing an understanding of machine learning algorithms used for classification, regression, clustering, recommendation system, etc. Developed and deployed applications running on public cloud systems such as AWS, Azure or Google Cloud Platform. Extensive SQL experience (MySQL, PostgreSQL, Hive, etc.) Experience working in Neural Network and other Deep Learning techniques is a plus. Be independent and creative in problem solving "
50,Senior Data Engineer,TITANSOFT PTE. LTD.,"$4,000to$8,000Monthly","Roles & ResponsibilitiesWe are looking for data engineers who are passionate about all things data! Our research team at Titansoft focuses on Human Behaviour Imitation, Artificial Intelligence, and Probability Theory, including, and definitely not limited to, feedback control algorithms, automatic processing, and machine learning models with the overall goal of building an automation system. Being part of our data research team will give your opportunities to not only build data pipelines that will efficiently and reliably move data across systems, but also to build an internal service to the whole company. If you love optimizing data and you feel strongly about improving data architecture, then we are definitely keen to speak with you to journey with us on this rewarding experience. Requirements BA / BS in Computer Science, Electronics or Electrical Engineering, Information Technology or other technical fields.  Able to implement and maintain custom or structured ETL design. Have knowledge and experience with SQL databases. Experience with Unix / Linux operating systems internal and administration (e.g. file systems, inodes, system calls) or networking (e.g. TCP/IP, routing, network topologies and hardware, SDN)  To succeed in this role, it will be good to have:  Expertise in designing and analyzing large-scale distributed systems (e.g. Hadoop, Kafka, Hive) Systematic problem-solving approach and strong communication skills. Ability to debug and optimize code and automate routine tasks. "
51,"Senior Engineer, DCIM ( Data Center Infrastructure Management )",KEPPEL DATA CENTRES HOLDING PTE. LTD.,"$4,500to$6,500Monthly","Roles & Responsibilities Ensure 
DCIM systems are operating as designed to protect the data center, capture power usage, calculate available capacity, and provide meaningful, timely alarms, notifications and reports to end users Interface with design consultants and BMS vendors to ensure BMS reliability objectives are met for new data center deployments and data center retrofit projects. Coordinate application deployments and IT infrastructure between the vendor and Corporate IT departments. Provide tactical support to implement enterprise alarming standards at the site level. Ensure site alarms are delivered to the Keppel Control Center teams Provide Technical support to Develop validation program for system alarms to ensure the right alarm is received by the right person at the right time. The configuration of EPMS applications in support of new data center deployments, new data requirements and data center retrofits. Provide technical support to Create standards and follow implementation by regional engineers on system administration of DCIM systems which include: application/database backups, redundant platform readiness, licenses management, infrastructure coordination for application support, etc. Prepare and maintain DCIM systems support documentation, test plans, and change management records. Coordinate DCIM systems Ethernet and IT requirements with internal IT operations. Engage, lead, and direct vendors via Scope of Work and Requests for Proposals/information documents. Implement corporate policies procedures and standards to maximize the performance of systems, applications and networks. Work closely with co-workers, maintenance personnel, project managers, building managers, engineers, and contractors on site-specific projects. Perform inspections, and assist in the testing and commissioning of the facility system (as required).  Requirements Degree in Electrical Engineering, Engineering Technology, or other related Engineering degrees or equivalent professional experience. 6 or more years of experience with critical monitoring/control systems and support for critical facilities. Working knowledge and experience with a BMS and building EPMS systems. Familiarity with power distribution systems in a data center environment or similar critical systems environment. Expertise in systems Programming using Java/C++, data modelling and event processing techniques. Demonstrated experience with SQL and No-SQL technologies (Cassandra, Storm, MongoDB etc.) Highly desired to have hands-on experience with Datacenter infrastructure monitoring platforms and frameworks. Experience performing commissioning, qualification & change control activities related to BMS including but not limited to HVAC, chiller plants, domestic and process water systems, building automation systems, etc. Ability to read, interpret, and produce engineering documents that may include: Control Drawings, Sequence of Operations, Bill of Materials, Graphical User, Interface requirements, and Functional Specifications. Experience with BAC-net, Modbus, TCP/IP configuration, SNMP communication protocols, Active Directory security and Microsoft Office tools. Understanding of basic power calculations on single and 3-phase circuits, electrical diagrams, control diagrams Demonstrated experience with cloud computing and IoT models/architecture is preferred "
52,Data Analyst,SPARKLINE PTE. LTD.,"$5,000to$7,000Monthly","Roles & ResponsibilitiesAt Sparkline, we are in the people business! 
Our Analytics Consultants are passionate about helping our Clients use data to develop a multi-view of their customer and deliver improvements across the customer journey to achieve competitive advantage and amazing customer experiences. 
 As a Senior Consultant youll use your consultancy toolkit to build a strategic partnership with the Client. 
Youll build a working knowledge of the Clients business, leverage industry knowledge and analytics techniques to provide creative solutions to solve real business problems. 
This, paired with an inquisitive style and proven ability to get to the root of a problem, will ensure you deliver cohesive and scaleable ideas for our Clients. 
 In this role you will leverage your advanced analytics capabilities to develop creative measurement strategies that maximise visibility and activate opportunity for our Clients. 
As a passionate storyteller you present your insights in the form of a narrative, using all communication channels to convey your message and help cross functional stakeholders connect with the bigger picture. 
 You are comfortable with a degree of ambiguity and not having all pieces of the puzzle in front of you. 
Your natural ability with numbers and statistics, combined with your experience using agile data sets and external resources, will allow you to identify opportunities and provide rich recommendations for your Client. You keep connected with the ever evolving digital technology landscape to help identify new solutions and skills that could create greater opportunities. 
 
 In this client facing role, youll take an independent approach to work planning and use your experience to preempt and mitigate issues to deliver on time, every time. You will keep the Client up to date, not only on progress but on the impact and value being generated every step of the way. 
 
 RequirementsAt Sparkline social capital is king! 

Your success will be based on your ability to collaborate, cooperate and ideate with Sparks from across the business. 
Demonstrating your natural bias for action, youll chase every opportunity to flex your entrepreneurial muscles and contribute to delivering impactful solutions for our clients. 
Youll enjoy working with a degree of ambiguity and see the challenge in not having all the pieces of the puzzle in front of you. You will be a passionate learner with the ability to pick up new tools and languages with ease. 
 Youll bring   A Bachelors Degree in Statistics (preferred) or related field   3 years in a digital marketing/data analytics role in eCommerce, Publisher or Consulting Firms   2 years leading a small team and/or project team with client facing responsibilities   2 years working with analytics and tag management solutions; specifically the Adobe and Google Analytics Suites.   Broad knowledge of the MarTech landscape and expertise in the main channels of online acquisition, related technologies and analytics tools; Advertising (Search Engines, SEO, SEM, Bid-management Tools, AdExchange etc), Marketing (Display, Content, Email etc), 
Social Media (Facebook, Twitter, YouTube etc), eCommerce.   Understanding of the statistical algorithms typically used in Marketing Analytics   Practical experience using Advanced Excel VBA, R and/or SQL  "
53,BIG DATA ENGINEER,Company Undisclosed,"$3,000to$6,000Monthly","Roles & ResponsibilitiesResponsibilities: Maintain and support Big Data platform.  Develop or identify, evaluate, recommend and maintain Big Data reporting and visualization applications.  Design, develop, and maintain data ingest solution for Big Data platform.  Work with Data Science to automate and maintain reliable data analytic and mining solutions for Big Data platform.  Ability to assess current IT environments and make recommendations to increase capacity needs.  Participate in 24x7 oncall rotation for operation support of Big Data platforms and solutions.  Communicate, collaborate and coordinate on Big Data related activities to various level of stakeholders and senior management. RequirementsRequirements: Bachelors or Masters degree computer science, software engineering, information systems or related field.  The candidate should have at least 2-5 years of technical experience in Information Technology with at least 1 years in Big Data, Data Warehousing or Business Intelligent technology.  Candidates with over 4 years of relevant experience will be considered for a senior position.  Broad knowledge of various aspects of Big Data with good understanding and hands-on experience in two or more of the following areas: Hadoop based technologies such as HDFS, MapReduce, Hive, MongoDB, HBase, Spark etc.  Data warehousing solutions and latest (NoSQL) database technologies.  Good knowledge in some following programming or scripting languages like Java, Linux, Matlab, C++/C#, Python, Perl and/or R on Linux/Windows platforms.  Experience in Big Data visualization and reporting software.  Experience in operational support in delivering Big Data solutions.  Experience in designing ETL/BI solutions using Microsoft SSIS, Informatica or having DB programming experience (TSQL, PLSQL) will be advantageous. Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job."
54,Data Analyst,CERTIS CISCO SECURITY PTE. LTD.,"$3,500to$6,000Monthly","Roles & ResponsibilitiesOverview As a Data Analyst in the Technology Development Office, you will support and provide consultancy to our business units as they embark on and implement their data analytics projects. You will assist their them on collecting, parsing, transforming,
analyzing and visualizing large sets of operational data so as to turn information into insights. We will provide you with training on modern data visualization / business intelligence tools (e.g. Tableau) and machine learning. As part of the data science team, you will be working with like-minded colleagues who are equally inquisitive about data and passionate about deriving business value from data analytics. Responsibilities  Assist business units in identifying feasible data analytics solutions to improve efficiency, reduce costs and augment operational planning  and then prototype or implement those solutions Validate business decisions with data analysis as required to determine their viability and practicality in the operations of business units Monitor progress of data applications and goals and provide status reports to management Document relevant information for our business units and customers All other duties assigned by your reporting officer  RequirementsQualifications  Relevant Bachelors degree in Computer Science, Computer Engineering,
Electrical Engineering, Mathematics or related fields  Skills and Experiences  Proficient with one or more of the usual programming languages used in data analytics  Java, Scala, Python, R Good mathematical and statistical foundations "
55,data scientist,ST ENGINEERING ELECTRONICS LTD.,"$4,000to$7,000Monthly","Roles & ResponsibilitiesWork in Strategic Technology Centre to deliver data analytic solution to customers/users. These solutions range from Descriptive, Diagnostic, Predictive, Prescriptive to Machine Learning and AI in developing data models with algorithms for big data analytics. Requirements Masters Degree or PHD in Science/Engineering/Mathematics with at least 2-3 years of working experience in data analytics In-depth technical knowledge in either (1) operational research (2) computer network (3) computer vision (4) fluid dynamics (5) engineering mechanics (6) video or image processing (7) AI and neural network (8) geometry and topology (9) social and cognitive computing Good experience with end-to-end data profiling, mathematical modelling, testing, validation, algorithm, visualization, ideation and solutioning Experience in MySQL, Python, Matlab, Java or C Knowledge of Hadoop and Spark "
56,Data Center Facilities Engineer,PEOPLEBANK SINGAPORE PTE. LTD.,"$3,000to$4,000Monthly","Roles & ResponsibilitiesWe are looking for Data Centre Facilities Engineers to do the following functions: Inventory Management Tracking  Perform physical inspection and collection of information related to IT equipment within the data center. Affix company's provided RFID, barcode, and other tags to all IT devices located within the data center. Perform scheduled periodic/random scans and inventory of equipment per supplied lists from inventory tool.  Shipping/Receiving and Loading Dock  Coordinate shipping/receiving functions including, but not limited to: receipt and shipping at facility loading dock, packing/unpacking of materials, movement of materials and equipment to/from data floor or storage location  Equipment Destruction  Plan and Coordinate disposal/destruction of IT equipment following company's standard processes and procures.  Installation and Removal of IT equipment  Physical power down of equipment Install and remove cabinets and racks in the data center Act as the POC and approve/coordinate tickets to add or remove equipment from the data center Move equipment, racks, devices, and materials between physical locations in the same data center Install equipment in designated cabinet, rack, floor location Unrack and remove equipment from designated cabinet, rack, floor location  Device Validation  Visual inspection of devices as requested Serial number validation Device Inventory capabilities and physical comparison to inventory lists  Basic troubleshooting and repair of IT equipment failures  Power on/power off devices Relay LCD readouts Reset Remote Management connection IDs and Passwords Reset cables  Cable Installation and Planning  Physical installation and removal of patch cabling, and cabling components, and related material Removal of unused cable and cable components from racks, conduits and data center subfloor  Device/Cable Validation  Perform visual inspection of equipment as requested to provide company with information regarding cabling, port availability, and network connections Document cable connections and server backplane connections as requested Perform cable inventory as requested  Cable troubleshooting and repair
  Troubleshoot and repair system connections as needed Replace cables Check network connections Trace cables  Cable Installation and Planning  Participate in the design and engineering of cable infrastructure, and cabling component related material Assist with planning of data center layout, cable plant and tray systems  Validation of cable material / patching sheet  Review and validate all cable material/patching sheet to ensure complete  Maintain
company's
stock  Maintain and track stock levels for company owned and Vendor owned materials onsite, including but not limited to:   Maintaining stock levels and following all processes. Receive, sort, stock, and manage company and Vendor owned materials  Hardware Planning  Manage and approve all physical changes within each data hall Govern the process of customer installations/de-installations Perform tile and cabinet RU assignment Ensure installations or de-installations are performed by technically qualified parties  Requirements Diploma or Degree holder Has at least 2 years of relevant data centre experience doing smart hands support "
57,Data Analyst,Company Undisclosed,Salary undisclosed,"Roles & ResponsibilitiesLooking for a Data
Analyst for our immediate requirements Requirements Experience with Data Analysis in the Banking regulatory and compliance field. Macro and VBA Coding (in Excel and Outlook) "
58,AVP Data Analyst,GIC PRIVATE LIMITED,"$5,000to$10,000Monthly","Roles & ResponsibilitiesInvestment Services Public Markets Investment Services Public Markets, or ISPM, is an integrated team that provides investment service support for public market investment activities strategically and tactically.
 The team is responsible for business management functions for all public market investment strategy groups, as well as GICs global trade operations, custody control and asset servicing such as income entitlements, mergers and acquisitions and other corporate events of our underlying investments, futures and derivative operations, collateral management, pricing and rates, market data and rebalancing operations.

 The coverage extends across a spectrum of products such as equities, bonds, money market, foreign exchange, futures, collateralized securities and other derivatives.
 We are looking for an analytics professional to join our department as a Data Analyst. This is a unique opportunity for a commercially-minded data professional to harness analytics to add value, optimize decision making and influence initiatives with high business impact. RequirementsResponsibilities  Evaluate business and information needs, and formulate data solutions through the analysis and interpretation of large data sets, trends and results  Creation and customization of dashboards to generate actionable insights for stakeholders and senior management  Understand, leverage and integrate existing operations data sources, while bringing in new techniques and technologies to enable analysis and predictive analytics  Provide thought leadership and take ownership of building analytics capability within the department  Participate in thematic studies and projects both within and across departments 
 Requirements
  Good degree in a technically inclined field such as Engineering, Financial Engineering, Mathematics, Statistics, Computer Science etc  At least 5 years of relevant experience in data analytics, data science, business intelligence or a related field  Expertise in data analysis techniques, tools and models, database design development, data mining and segmentation techniques  Ability to write clean and effective code in one or more programming languages  Self starter, passion for using data to generate strategic insights that translate into value and application for stakeholders  Adept at presenting findings using strong visuals and in interesting and digestible ways  Forward thinking and a natural curiosity in keeping up to date with developments and best practices in the analytics industry"
59,Software Engineer,DELTA ELECTRONICS INT'L (SINGAPORE) PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesJob
Purpose

 The
Software Engineer would be a part of a high performance global team
at Delta Research
Center
responsible for the delivery of features in the research projects. The candidate would need to
analyse, design core modules of
application and work with a global team of developers, data scientist, knowledge expert
and architects.
 Delta Research
Center
is the Corp RD of Delta Electronics group. Our mission is to develop Deltas new capabilities by synergizing technology novelties with business innovation to achieve sustainable competitiveness in the ever changing climate.
 Job
Duties & Responsibilities
   Collaborate with Software Project Leader and Solution
Architects in
defining and designing
solution.
   Liaise with
solution
project team members for
solution delivery.  
  RequirementsJob Requirement (Qualification & Experience)
   At least a Bachelor
Degree in Computer Engineering/Science or equivalent
   Experience in Java/Javascript,
JEE5 and above/Angular JS,
SQL, XML and Web Services
technologies

   Experience
in at least 1 cycle of software development
   Working experience UML design and documentation
   Skills & Competencies
   Deep knowledge of operating systems (Linux,
Unix, etc.),
middleware systems (Tomcat,
ESB, etc.)
/Frontend technical framework
and database system (MongoDB,
MySQL,
etc.)
   Understanding of Object Oriented Programming and concepts
   Good communications and interpersonal skills, able to work well with people from diverse backgrounds and within distributed international teams
  "
60,Data Scientist Consultant,KANEX PTE. LTD.,"$5,000to$9,000Monthly","Roles & ResponsibilitiesWe are looking for highly motivated Individual who will work with various members of Data Intelligence & Science (DISc) team to address challenging data science problems by leveraging techniques in 
statistics, machine learning or/and data mining. Requirements1.



 Phd/Masters degree in Statistics/Applied Math/Operational Research/Computer Science or related field.   2.



 5+ experience of working experience in software or related industry   3.



 2+ experience as data scientist working on various data science projects.   
 
 
 
4. Experienced in developing machine learning models for real-world problems using R, 






python or other languages   









 


5.




Familiar with big data technologies like Hadoop, Hive, Pig and Spark   
 
 
 
 
 
 
 6.




Able to conceptualize prototypes and evolve them to full fledge solutions   
 
 
 
 
 
 
 7. Able to articulate the findings and work in a team environment"
61,Data Analyst,WILLIAMS-SONOMA SINGAPORE PTE. LTD.,"$3,300to$3,500Monthly","Roles & ResponsibilitiesJOB PURPOSE: We are looking for a Data Analyst
 ( 1 year contract ) who is passionate about collecting and making data useful for our business associates. The successful candidate will turn raw data into meaningful and insightful information and empower our business users to make good business decisions. 
 KEY RESPONSIBILITIES: 
  Learn and understand WSI Sourcing and operation business work flow and data requirements. Interpret data, analyze results using data collection techniques and provide ongoing reports Develop and implement data collection techniques where needed, data analytics and other strategies that optimize statistical efficiency and quality Acquire data from primary or secondary data sources and maintain good data in our database systems Identify, analyze, and interpret trends or patterns in complex data sets Filter and clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems Work with management to prioritize business and information needs Locate and define new process improvement opportunities  RequirementsJOB HOLDERS COMPETENCIES & EXPERIENCE:   Degree/Diploma Computer Science, Information Management or Statistics, Mathematics Proven 2-3 years working experience as a data analyst. Technical expertise regarding data models, database design development, data mining and segmentation techniques Proficient in writing and optimizing SQL statement, and understanding of Views, Functions, Triggers, Procedure in Mysql will be ideal ; Knowledge of Mysql client tools like Toad, Query browser; Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy Adept at queries, report writing and presenting findings This is a 1 year contract role.
 "
62,Data Sciences & Analytics Engineer,SINGAPORE AIRLINES LIMITED,"$3,000to$6,000Monthly","Roles & ResponsibilitiesSIA has implemented the Enterprise Information Management (EIM) platform which is the single, integrated and comprehensive repository of enterprise data. Our Data Engineering Team is looking for Data Engineers to help us continue to build out our data infrastructure, making available to the business users the right data at their fingertips and supporting the business in big data analytics.   
    Responsibilities of the Data Engineer include:   
   Administration and monitoring of the EIM systems to ensure EIM operations run efficiently with the desired SLA and security compliance. Monitoring performance and advising any necessary infrastructure changes to the EIM landscape. Work with the infrastructure teams to implement such changes. Design and develop architecture for data services ecosystem spanning Relational, Columnar, NoSQL, In-Memory, Data Warehouses and BI & Big Data technologies. This include designing and implementing data pipelines & ETL processes. Design data models for mission critical and high volume data management, real-time and distributed data process aligning with the business requirements. Promote and develop data architecture best practices, guidelines, procedures and repeatable and scalable frameworks. Work with business units on their analytics initiatives, providing the data science expertise and resources besides being responsible for extracting the data from EIM as required for the project. Work with analytics vendors, providing the data sets as required and support the business users in assessments & validation of the analytics/statistical & machine learning models. Work with and help business units with tools like Tableau to visualize and create dashboards with the relevant data in EIM. Work closely with our application teams to operationalise & integrate analytics/machine learning models into our production systems.  Requirements BS in Computer Science or other related discipline is required. Advanced degree related to Analytics, Machine Learning & AI preferred. At least
1 years of relevant industry experience in following areas:   Knowledge and working experience with Machine Learning, AI, statistical techniques, and information retrieval as well as on data management systems, practices and standards. Knowledge and working experience with at least one visualization tools like Tableau, PowerBI, Qlik, or similar open source tools. Working experience in architecting highly performant databases using RedShift, PostgreSQL and Cassandra or NoSQL. Knowledge & working experience in Big Data technologies like In-Memory, New SQL, NoSQL, Hadoop Hive/Spark, etc Knowledge & experience in shell scripting, R, Python, Perl, Ruby, or any other scripting language. Should be proficient in at least shell scripting and R or Python. Experience with commercial ETL platforms with in-depth knowledge and understanding of ETL methodology & design supporting data transformations layer. Working experience with Ab Initio would be a bonus.   Strong knowledge and experience with Agile/Scrum methodology and iterative practices in a service delivery lifecycle is a PLUS. Working experience in an AWS or similar public cloud environment is another PLUS Excellent interpersonal & communication skills and proven ability as a problem-solver. Candidate to indicate in the application his/her strengths in data engineering and data science, and his/her preference. "
63,Data Engineer,GUMI ASIA PTE. LTD.,"$5,000to$7,000Monthly","Roles & Responsibilities Design, develop, implement, and evolve data pipelines powering core data sets and key business and performance metrics Identify, troubleshoot, and resolve any performance, system or data related issues, and work to ensure data consistency and integrity Work with Product and Marketing teams on data requirements.
 Work with various game teams on data set and data flow to ensure that data requirements are met. Ensure the quality, accuracy, and timeliness of analytical data  Requirements Min. 5 years working in a large analytical data ecosystem Strong technical understanding of data modelling, design, architecture principles, and techniques to take business requirements from concept to implementation Strong knowledge of relational databases and SQL. Knowledge of Python, PHP, Java, Linux architecture and scripting Extensive background extracting and transforming complex data sets. i.e. ETL
 Experience with database design and star schema data warehouse theory "
64,"Data Governance Senior Analyst, APAC Data Governance",ITCAN PTE. LIMITED,"$6,000to$12,000Monthly","Roles & ResponsibilitiesResponsibilities: 
  Supports data governance needs for Business Line MI programs in the region. Run data governance projects to set up data governance for our accounts and clients in the region:   Run workshops, define data strategy based on client/account priorities, Define with the business data classes and
 Critical data elements Proposes regional data governance standards and processes based on Client/Account needs. Set up Data governance framework including
 data stewardship program, data governance processes, RACI, business glossary, standards and playbooks for regional Clients and Account teams, in compliance to Global Data Governance guidelines Participate to the implementation of Data Quality programs for regional Clients/Accounts and Business Lines. (represent data Governance voice in the definition of DQ rules) Facilitate meetings with data consumers, data stewards, data producers and other stakeholders to ensure data governance rules and standards are applied to data related changes/ projects and mentor the business on DG. Identify areas of improvement in data practices and suggest appropriate solutions based on Data Governance principles.    RequirementsExperience  Must have 5+ years of experience in data domain such as Data Analysis, Data Governance, Data Management, Enterprise Information Management, Data Modeling, and Data Quality Management. Must have intermediate expertise in MS Excel, Visio, Word and PowerPoint. Must have foundational exposure to DataConcepts, i.e. Data Visualization, Data Analytics, Data Mining, Business Intelligence, etc. Bachelor's degree in Information Management, MIS, Library Science, or Computer Science; advanced degree preferred.   Experience in any standard ETL (Informatica, SSIS etc.), BI (Tableau, Cognos, Power BI etc.) and data management tools preferred. 3 + years related experience in commercial real estate management (preferred) or related industry. Candidates must have experience working in large global organizations with geographically dispersed teams and complex technical environments.  Skills: Data Governance & Management:  A practitioner of Data Governance and Management with real world experience of implementing at least two of the below concepts:   Critical Data Elements Business Glossary/Data Definition Reference Data Management Data Migration Master Data Management   Should have demonstrated success in implementation of Data Quality Management methodology. Should possess business acumen and have demonstrated success as a Business Analyst/Consultant in data domain. Experience in business consulting for large scale data projects preferred. Experience of successful application of Data Governance concepts in business scenarios preferred.  Project Management:  Should have demonstrated success in managing end to end project lifecycle. Should have demonstrated success in requirement gathering, stake holder management and project co-ordination in a heterogeneous (a mix of Business, Operations and IT) environment. Ability to work well under deadlines and multitask between competing priorities preferred.  Soft Skills:  Must be a self-starter and work with minimal or no supervision during analysis of complex business problems and deliver under strict deadlines. Must have excellent relationship management skills that include: excellent listening and consultative capability, ability to influence and negotiate with business and technology partners to drive change, ability to see the big picture and make key connections. Should have excellent presentation, oral and written communication skills. Must be able to communicate with a variety of stakeholders across all levels of the organization. Should have demonstrated to be successful in a team based collaborative environment. Excellent collaborative and leadership mindset preferred.  Technology: 
  Should have sound understanding on technological concepts (Data Architecture, Data Modeling and Data Integration) in data domain. Should be able to analyze and manipulate data stored in spreadsheets.  Ability to query and analyze data stored in RDBMS systems such as MS SQL server, Oracle etc."
65,"VP  /  AVP, Data Scientist, IBG Digital, Institutional Banking Group (180000ZI)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & ResponsibilitiesJob Purpose
 The Data Scientist works within IBG Business Analytics to drive value for the business by leveraging machine learning. He will have opportunities to work on various projects that provide data-driven insights that enable enhanced capabilities in the areas of business growth, risk management, productivity etc. Responsibilities  Partner with business stakeholders to understand needs and identify opportunities to apply data science Frame this opportunity as a data science problem, formulating hypotheses and techniques for experimentation Work with data analysts and engineers for data exploration and preparation Conduct experiments, assess model performance, and present results to business stakeholders to obtain feedback Present key insights to management with actionable recommendations Facilitate deployment of finalised solution to production environment Monitor model performance over time and retrain model if necessary Work with other data scientists to drive projects and guide juniors as required Accountable for the delivery of data science projects that drive value for business  Requirements For PhD holders (in computer science, machine learning, statistics, decision science, mathematics or equivalent)  at least 3 years of industry experience developing data science solutions For non PhD holders  at least 6 years of data science industry experience Advanced degree holder in computer science, machine learning, statistics, decision science, mathematics or equivalentExcellent advanced analytics skills, with prior industry experience developing machine learning solutions for classification, prediction, forecasting and/or anomaly detection problems Highly proficient in data manipulation Highly proficient in R, Python, Spark Deep expertise in at least one of the following areas (or equivalent): deep learning, NLP, graph mining, anomaly detection, large-scale recommender engines, large-scale optimizations, large-scale multivariate time-series forecasting, causal and statistical reasoning Ability to present analysis in a manner accessible by non-practitioners Good verbal and written communication skills and the ability to interact professionally with business executives Has a can-do attitude "
66,Data Managament Analyst,MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD,"$3,000to$4,000Monthly","Roles & ResponsibilitiesResponsibilities:  Review and Approve or deny connections within a review tool based on client Policy. Review data provided by advertisers and validate it matches the corresponding internal CRM object (e.g. the contact for the advertisers company). Review subjective content (e.g. Ads run by the advertiser or the account billing address) and tag it to existing Client Relationship Management listings. Read, understand and make decisions based on policy documents Correspond with internal salespeople regarding any appeals filed. Review non-objectionable content, create tasks, follow-up on open tickets Provide feedback on trends identified in reviews. General data entry related tasks. Provide suggestions to improve the process and workflows Translate content in foreign language from local countries counterparts into English for the team  
 RequirementsRequired Experience  Familiar and uses social media accounts/products Excellent work pacing (time management) skills, able to work independently Attention to detail is essential to ensure the quality of work execution Able to work in multiple tools/web browser windows at one time Motivated, takes initiative, high energy Familiar with MS office (mainly excel) for updating progress Candidates should have good search and navigating skills Interpersonal Skills Self-starter, can easily adapt to change (new content, changing policies) Good problem solving Business language proficiency (written and oral) in Hindi/ Tamil/ Thai/ Vietnamese/ Bahasa Indonesia/ Bahasa Melayu/ Japanese/ Korean/ Mandarin to liaise with local countries' counterparts. Interested candidates must substantiate language proficiency with relevant certifications.  Must be keen to work in Social Media/Digital environment  We respect your privacy and all communication will be treated with confidentiality. 
If you wish to know more about this position or explore other roles, please prepare your updated profile and get in touch with our consultants at 6232 8811
(EA License:
02C3423) Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by Manpower for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012."
67,Data Engineer,RAKUTEN ASIA PTE. LTD.,"$4,500to$8,000Monthly","Roles & Responsibilities Implement cutting-edge data infrastructure platform which is vendor unlocked and multi-tenant. Implement and manage robust ETL pipeline based on streaming. Implement easy-to-use generalized data accessing layer by leveraging the details of storage engine. Implement distributed machine learning pipeline by coordinating with data science team. Develop data driven culture for integrated partners. Propose new technologies, tools to improve whole process of data system integration.  RequirementsMust have  Bachelor degree or higher in Computer Science or related field. Experience in at least one language for web backend application & data processing, such as Java, Python, etc. Experience in NoSQL database, such as Redis, Solr, MongoDB, etc. Experience in Linux system operation, ability to manage system level task such as monitoring and troubleshooting your deployed applications. Good communication skills, ability to work in fast pace R&D. High motivation for learning, skill up, system ownership and contribution to the team.  Must have for Senior position  3+ years of experience in developing large scale data processing platform of various unstructured data. 3+ years of experience in using various big data frameworks and NoSQL databases, such as Hadoop, Kafka, Redis, Solr, etc. Practical knowledge of web system performance tuning including OS, middleware, I/O and application.  Good to have  Experience on cloud computing service, such as AWS. Experience in handling multilingual data. Knowledge in data science domains, such as NLP, Data Mining, and Deep Learning will help your collaboration with the data scientists. "
68,Mid Senior Data Scientist,AXA DIL@ASIA PTE. LTD.,"$6,000to$9,500Monthly","Roles & ResponsibilitiesThe AXA Group, a worldwide leader in Insurance and Asset Management, supports and advises its customers, individuals and businesses at every stage of their lives by meeting their needs for products and insurance, pension, savings and wealth transmission. Our expertise is expressed through a range of products and services tailored to each client in three major areas: property & casualty insurance, life & health insurance and asset management. Present in 59 countries, 161,000 AXA employees are committed along with 103 million customers. Created in January 2014, the Data Innovation Lab (DIL) acts for the Group as a business-focused center of expertise on data analytics to foster R&D for AXAs offers and services. The DIL supports AXA entities big data projects by acting as an accelerator to carry out pilots and drives the creation of technological platforms to ease the operational roll-out. We have gathered both the latest data science tools and a team of experts in innovation, data and data science. The DILs key mission is to help AXA entities become data - driven companies by contributing to build technological platforms, acting as a technological hub towards external to explore the technological opportunities for insurance business. A glimpse of your daily mission: Contribute to the data strategy of the company: Link business needs to analytical solutions Build and promote data strategic assets for the business: marketing, products, services and tools Maintain and evolve the part of the innovation process linked to the data science activity Put in place the metrics and the dashboards to provide visibility for data science activity Promote and evolves the innovation process within the Data Science community Business Modeling: Understanding operational needs by collaborating with specialized teams Formalize needs into mathematical models and problems Explore databases (including large databases, unstructured and open) to find relationships and insights Problem solving: By leveraging the formalization of appropriate problems, propose theoretical solutions based on available tools Choose relevant techniques and create data processing solutions for the addressed needs Present and promote the solutions to the relevant communities and committees Manage and transmit the knowledge through appropriate documentation and events (training courses, seminar, etc.) 
 RequirementsSuccessful qualifier of this mission: Professional and technical skills: Masters degree or equivalent dual diploma (or PhD) in finance, actuarial, mathematics, statistics, physics or similar; Deep understanding of machine learning concepts and algorithms; Ability to model the reality of business into equations, and to understand the implications and limitations of a model; Relevant work experience in data processing (data mining, social network analysis, text mining, etc.); Good programming skills (Python, R, Java, Scala, SQL, Hive, etc.); Good knowledge in machine learning tools and libraries (scikit-learn, R, MLlib, etc.), bigdata tools (Spark, Hive), databases (relational and NoSQL), data visualization, web scripting; Analytical skills and mindset to produce useful business insights from data; Proven experience in distributed architectures applied to big data; Professional experience in research (fundamental or applied) is a plus; Professional experience in Web marketing is a plus; English  fluent in speaking and writing is mandatory; Ability to work into multi-disciplinary team; Good communication skills necessary to contribute to complex projects involving many stakeholders; Autonomy, curiosity and innovation capability; Business oriented; Experience: 5 to 10 years of strong professional experience; Work experience in an international environment is a plus. Please send your updated resume to
hr@axa.com.sg As we are continuously looking for great talents like you, do share AXA career opportunities with other talents! Link for our website is
https://www.axa.com.sg/about-axa/careers To all recruitment agencies
AXA ONLY accept resumes from appointed agency under our Preferred Supplier List. Please do not forward resumes to our jobs alias, AXA employees, any AXA entities or company location. AXA is not responsible for any fees related to unsolicited resumes. 
"
69,Data Analyst,ST ENGINEERING AEROSPACE LTD.,Salary undisclosed,"Roles & Responsibilities Educate project team members on analytic techniques and evangelise the benefits of data science to internal and external stakeholders. Develop and execute analysis plans by translating business requirements into technical designs for data acquisition, analysis and modelling, dashboards and performance metrics etc. Capture and evaluate the improvements to productivity and profitability for data analytic initiatives. Assist with the development of the companys overarching data strategy and implementation plans  Requirements Bachelors or Masters in data/business analytics or other related quantitative fields. Proficiency with programming and statistical software such as R, SPSS, Matlab, Python, Excel etc. Experience with handling data from SQL type relational databases. Experience with developing reports and visualisations with Qlikview will be an advantage. Experience with handling data from Hadoop and NewSQL databases will be an advantage. Applicants with no prior experience are welcome to apply. "
70,Data Scientist Big Data Hadoop Hive Machine Learning Business Analytics,3TOP CONSULTING PTE. LTD.,"$4,000to$7,500Monthly","Roles & ResponsibilitiesBusiness Analytics team and collaborate with subject matter experts to develop analytic statistical models, machine learning methods and solutions 
 RESPONSIBILITIES:   Work with internal and external stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions by testing various statistical models.  Improve on effectiveness and accuracy of new data sources and data gathering techniques, or create new processes and tools to monitor and analyse model performance and data accuracy.  Explore third-party and open source solutions for fast execution and for specific use cases  Engage in fundamental research to develop novel solutions to solve diverse business problems Requirements Bachelors degree in Computer Science, Mathematics & Statistics, Economics, Analytics or Applied Mathematics  Minimum 2 years of experience in statistical modelling and analysis tools like R, STATA  At least 2 years of experience in programming languages like S-plus, SAS, Python  Handled one of these: Supervised and Unsupervised Learning, Classification Models, Cluster Analysis, Neural Networks, Non-parametric Methods, Multivariate Statistics, Reliability Models, Markov Models, Stochastic models, Bayesian Models  Knowledge of UNIX or Linux environments  Experience working with large data sets and tools like MapReduce, Hadoop, Hive  Proficient in data streaming technologies like Spark, Flink 
 Interested candidates please send in an updated Word CV with a recent photograph attached to kelvinleow@3topconsulting.com EA License: 10C3108 EA Registration No: R1106538"
71,Data Scientist,KELLY SERVICES (SINGAPORE) PTE. LTD.,"$4,000to$6,000Monthly","Roles & ResponsibilitiesThe Logistics Data Specialist/Master Data Analyst/Master Data Executive is responsible for executing all business intelligence and data related activities including setting up databases, obtaining and managing data, performing data analysis and validating data. He/She is also responsible for managing Electronic Data Interchange (EDI) data and knowledge management projects and performing system reviews to improve the system.  He/She is required to handle data and data analytics. He/She is also expected to coordinate closely with data owners to obtain data and work under time pressure. Requirements~ Adapt latest technology to support team operations improvement activities. ~ Analyse data and research outputs to offer explanations for data findings. ~ Analyse data sets to develop tools and solutions that identify logistics process improvement opportunities. ~ Analyse data, analysis and research to determine weaknesses in evidences, quality and limitations of analytics. ~ Analyse the wider implications of analysis and research to draw inferences on logistics operations. ~ Develop data management systems and databases for logistics process improvements. ~ Proficient in a data science or statistics programing language, preferably Python or R ~ Develop plans to implement innovative logistics solutions. ~ Develop technology solutions and automations to improve processes. ~ Evaluate risk factors that impact on efficiency. ~ Facilitate delivery of key outcome within team/ departmental projects. ~ Facilitate key activities and milestones in technology projects. ~ Facilitate team/ departmental projects. ~ Manage data through a combination of data mining, modelling, analysis, cost-benefit analysis, process mapping and/ or problem analysis to support data management initiatives. 
"
72,"Senior Associate, Big Data IM, Advisory",ERNST & YOUNG ADVISORY PTE. LTD.,"$4,100to$8,200Monthly","Roles & ResponsibilitiesEY Data and Analytics is the data and advanced analytics capability within EY Asia-Pacific.
 We have vibrant practices in Australia, New Zealand, Singapore, Hong Kong, Korea, The Philippines and Malaysia. EY Data and Analytics creates intelligent client organizations using data & advanced analytics.
 We go beyond strategy and provide end to end implementation of real life data environments and have some of the best architects, project managers, business analysts, data scientist, big data engineers, developers and consultants in the region.

 
 Due to our continued growth we are looking for a talented, inquisitive and proactive Big Data IM join our team. RequirementsREQUIREMENTS:   Bachelor degree and above in Analytics, Information Systems Management, Computer Science or related fields. Hands on experience in implementing data integration processes, designing and developing data models(ER/Dimensional/Vault), designing, developing and building in detail ETL/ELT processes or programs. Contributed in at least 2 phases of SDLC lifecycle and experience in Big Data, data warehouse, data analytics projects, data migration, change management process, and/or any IM (Information Management) related works. Experience with Hadoop Technologies such as HDFS/MapRFS, Map Reduce(II), Advanced HDFS ACLS, Hive, HBase, Cassandra, Impala, Spark, Drill, Sentry, Sqoop, Flume, Kafka, Storm, Zookeeper and zkClient tool Good understanding on Cloudera or Horton Works or MapR Hadoop Distribution with deep understanding of administration concepts Experience in working with RDBMS technologies such as, Oracle, Microsoft SQL Server, PostgreSQL, DB2, MySQL etc. Experience in MPP database technologies such as Teradata Hands-on experience on Spark, SparkSQL, Hive QL, Drill QL, Impala, Spark Data Frames and Flink CEP, Flink TableAPI&SQL as ETL framework Hands-on programming skill on Scala/Python using Spark/Flink Framework Strong knowledge of
Big Data stream ingestion and IoT streaming using Flume, or Kafka, Storm, MQTT, RabbitMQ Good understanding Spark Memory management with and without Yarn memory management Should have basic understanding on Cloudera Manager or HortonWorks Ambari and MapR Control System Should have experience developing and designing in one or more NoSQL database components and objects using Cassandra, Mongo, HBase, CouchDB/Couchbase, Elasticsearch Should have experience developing and designing in one or more NoSQL database technologies such as Cassandra, Mongo, HBase, CouchDB/Couchbase, Elasticsearch etc. Should good working knowledge of HCatalog and Hive Metadata. Should have working knowledge of Kerberos authentication tool Experience in commercial ETL tools like Talend, Informatica or Alteryx will be added advantage Greenplum, IBM Pure Data etc. will be an added advantage Experience in working with RDBMS technologies such as, Oracle, Microsoft SQL Server, PostgreSQL, DB2, MySQL etc. Experience in MPP database technologies such as Teradata, Greenplum, IBM Pure Data etc. will be an added advantage Good knowledge of data warehouse and data management implementation methodology. Good knowledge of the Information Management framework, including operating model, data governance, data management, data security, data quality and data architecture. Knowledge and experience in
 data visualisation concepts using tools such as SAS Visual Analytics or WRS, Tableau, Microsoft PowerBI or Reporting Services, IBM Cognos, SAP Business Objects, etc. will be an advantage. Ability to pick up new tools and able to be independent with minimal guidance from the project leads/managers. Strong analytical and creative problem solving capabilities. Ability to establish personal credibility quickly and demonstrate expertise. Ability to create a positive learning culture, coach and develop team members.  
 ADDITIONAL REQUIREMENTS:   3
to 10 years of experience in data warehouse, data analytics projects, change management process, and/or any IM (Information Management) related works. Delivered at least two (2) full SDLC lifecycle projects. At least one of the industry or domain experiences in Banking/ Telecommunications/ Consulting Preferably with experience in implementation best practices involving data management, data reconciliation, data duping, scheduling, etc. Able to assess design considerations in the aspect of data management and integration Experience with Agile/SCRUM/Kanban software implementation methodology Should have good knowledge in DevOps engineering using Continuous Integration/Delivery tools such as Docker, Jenkins, Puppet, Chef, GitHub Atlassian Jira etc. Certification in any of Hadoop Big Data tool/technology, data integration, data management, or visualisation tools is an added advantage. Knowledge about the infrastructure paradigms such as OS, network etc. is an added advantage.  
 ABOUT US The EY Data and Analytics team are specialists in information management, advanced analytics and business intelligence. We implement the information-driven strategies and systems that offer the highest return on investment, profitability, and service or policy outcomes for our clients. Our consultants work to create a lasting organisational culture that encourages people to use information and technology more creatively and more intelligently to get better business results.
 

 WHY US We work with some of the worlds most influential businesses on many of their most exciting Bigdata and IoT projects. Our sheer scale, scope and reach will provide you with the experiences, challenges and contacts that can inspire you for life Our culture means you can succeed whatever your background, work to your natural strengths, and learn from a remarkably diverse and talented group of people in a dynamic and collaborative global business environment 
 
 
 WHAT WORKING AT EY OFFERS EY offers a competitive remuneration package commensurate with your work experience where youll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements, where this may be needed, guided by our FWA Policy. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way thats right for you 
 
 ABOUT EY  As a global leader in assurance, tax, transaction and advisory services, were using the finance products, expertise and systems weve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, well make our ambition to be the best employer by 2020 a reality. 
 If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.  Join us in building a better working world.  Apply now"
73,Data Scientist,SENSE INFOSYS PTE. LTD.,"$4,500to$6,500Monthly","Roles & ResponsibilitiesWe are looking for a savvy Data Engineer/Scientist to join our growing team of analytics experts and will be responsible for expanding and
optimising
our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. Responsibilities:  Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Product, Analytics and Solution teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and AWS regions. Create data tools for analytics team that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems.  
 Requirements
  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.   Experience building and optimizing data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable big data data stores. Experience supporting and working with cross-functional teams in a dynamic environment. With 3+ years of experience in a Data Engineer role, who has attained a degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
 	 Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools Experience with AWS cloud services Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.   "
74,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a data scientist who can contribute on text mining-related projects. Researchers with expertise in the areas of natural language processing, deep learning, machine learning, ontology engineering and/or knowledge-based data analytics are welcome. In particular, we may collaborate with the successful candidate to establish research milestones in integrating text mining with common-sense and/or domain knowledge by constructing, populating and/or engineering ontology (or knowledge base). Responsibilities:  Deliver results: Develop new technologies, improve performance 
Demonstrate long-term vision, while effectively supporting short-term goals  Requirements PhD in computer science or related topics
 Being an excellent team player Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
75,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data scientist
to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements PhD in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Entry Level candidate with relevant experience may apply Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas Good knowledge on data analytics, machine learning, data mining and experiences in solving real-world problems Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus. Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
76,Data Scientist,AXA DIL@ASIA PTE. LTD.,"$4,500to$6,800Monthly","Roles & ResponsibilitiesThe AXA Group, a worldwide leader in Insurance and Asset Management, supports and advises its customers, individuals and businesses at every stage of their lives by meeting their needs for products and insurance, pension, savings and wealth transmission. Our expertise is expressed through a range of products and services tailored to each client in three major areas: property & casualty insurance, life & health insurance and asset management. Present in 59 countries, 161,000 AXA employees are committed along with 103 million customers. Created in January 2014, the Data Innovation Lab (DIL) acts for the Group as a business-focused center of expertise on data analytics to foster R&D for AXAs offers and services. The DIL supports AXA entities big data projects by acting as an accelerator to carry out pilots and drives the creation of technological platforms to ease the operational roll-out. We have gathered both the latest data science tools and a team of experts in innovation, data and data science. The DILs key mission is to help AXA entities become data - driven companies by contributing to build technological platforms, acting as a technological hub towards external to explore the technological opportunities for insurance business. A glimpse of your daily mission: Contribute to the data strategy of the company: Link business needs to analytical solutions Build and promote data strategic assets for the business: marketing, products, services and tools Help for relevant stakeholders to define the data management strategy: acquisition, data flow process Maintain and evolve the part of the innovation process linked to the data science activity Put in place the metrics and the dashboards to provide visibility for data science activity Promote and evolves the innovation process within the Data Science community Help to manage the compliance with data privacy Business Modeling: Understanding operational needs by collaborating with specialized teams Formalize needs into mathematical models and problems Explore databases (including large databases, unstructured and open) to find relationships and insights Problem solving: By leveraging the formalization of appropriate problems, propose theoretical solutions based on available tools Statistics: regression and statistical analysis Algorithms: machine learning, data mining, clustering, artificial intelligence Choose relevant machine learning techniques and create data processing solutions Present and promote the solutions to the relevant communities and committees Involvement in the data community: 
 Participate in AXA community of experts to discuss the resolutions of problems Promote the work of data science and R&D through new disciplines and new activities, promote best practices and knowledge between teams and countries RequirementsSuccessful qualifier of this mission: Professional and technical skills: Masters degree or equivalent dual diploma (or PhD) in finance, actuarial, mathematics, statistics, physics or similar; Deep understanding of machine learning concepts and algorithms; Ability to model the reality of business into equations, and to understand the implications and limitations of a model; Relevant work experience in data processing (data mining, social network analysis, text mining, etc.); Good programming skills (Python, R, Java, Scala, SQL, Hive, etc.); Good knowledge in machine learning tools and libraries (scikit-learn, R, MLlib, etc.), bigdata tools (Spark, Hive), databases (relational and NoSQL), data visualization, web scripting; Analytical skills and mindset to produce useful business insights from data; Proven experience in distributed architectures applied to big data; Professional experience in research (fundamental or applied) is a plus; Professional experience in Web marketing is a plus; English  fluent in speaking and writing is mandatory; Ability to work into multi-disciplinary team; Good communication skills necessary to contribute to complex projects involving many stakeholders; Autonomy, curiosity and innovation capability; Business oriented; Experience: 5 to 10 years of strong professional experience; Work experience in an international environment is a plus. Please send your updated resume to
hr@axa.com.sg As we are continuously looking for great talents like you, do share AXA career opportunities with other talents! Link for our website is
https://www.axa.com.sg/about-axa/careers To all recruitment agencies
AXA ONLY accept resumes from appointed agency under our Preferred Supplier List. Please do not forward resumes to our jobs alias, AXA employees, any AXA entities or company location. AXA is not responsible for any"
77,"Senior Associate  /  Associate, Data Scientist, IBG Digital, Institutional Banking Group (180000ZI)",DBS BANK LTD.,"$4,000to$8,000Monthly","Roles & Responsibilities Partner with business stakeholders to understand needs and identify opportunities to apply data science Frame this opportunity as a data science problem, formulating hypotheses and techniques for experimentation Work with data analysts and engineers for data exploration and preparation Conduct experiments, assess model performance, and present results to business stakeholders to obtain feedback Present key insights to management with actionable recommendations Facilitate deployment of finalised solution to production environment Monitor model performance over time and retrain model if necessary Work with other data scientists to drive projects and guide juniors as required Accountable for the delivery of data science projects that drive value for business  Requirements For PhD holders (in computer science, machine learning, statistics, decision science, mathematics or equivalent)  at least 3 years of industry experience developing data science solutions For non PhD holders  at least 6 years of data science industry experience Advanced degree holder in computer science, machine learning, statistics, decision science, mathematics or equivalent Excellent advanced analytics skills, with prior industry experience developing machine learning solutions for classification, prediction, forecasting and/or anomaly detection problems Highly proficient in data manipulation Highly proficient in R, Python, Spark Deep expertise in at least one of the following areas (or equivalent): deep learning, NLP, graph mining, anomaly detection, large-scale recommender engines, large-scale optimizations, large-scale multivariate time-series forecasting, causal and statistical reasoning Ability to present analysis in a manner accessible by non-practitioners Good verbal and written communication skills and the ability to interact professionally with business executives Has a can-do attitude "
78,System Engineer - Data Centre Automation,EIRE SYSTEMS SINGAPORE PTE. LTD.,"$4,800to$6,800Monthly","Roles & Responsibilities Implementation, monitoring, optimization and support of processes in the BI-IT-Automation computer system. Manage and coordinate critical preventive maintenance, performance monitoring initiatives, and documentation reviews/updates. Provide 2nd level support in the Center of Excellence (CoE) for Cloud Computing team
 Handle tickets and escalations from the Incident management team and provide support on technology and troubleshooting. Actively participate in global and regional IT projects and initiatives.  Requirements Knowledge of ITIL processes and methodologies Minimum of 6
years experience in IT Infrastructure Automation and support  Experience with using REST API within automation workflows, orchestration, and BPM  Strong technical proficiency with in scripting and automation technologies is a must  Experience with programming languages such as Powershell, Perl, Automic/UC4, XML, Ruby, Python, JavaScript, and/or Bash  IDE based tools such as Eclipse or virtual studio code and using of code and binary repositories (e.g. GiTHub, GiTLab and BitBucket) Hands on experience with Text-file formats for structure data (e.g. JSON and YAML) General skills with administration of server based operating systems such as Redhat Linux Server OS (6.x and 7.x), Windows Server (2012 and 2016) Experience with virtualization technologies related to VMware vSphere ESXi and vCenter  
"
79,Data Analyst,GO GAME PTE. LTD.,"$4,000to$6,000Monthly","Roles & ResponsibilitiesYour go-Getting Mission  Use statistical methods to analyze data and generate useful business reports Work with management team to create a prioritized list of needs for each business segment Identify and recommend new ways to save money by streamlining business processes Use data to create models that depict trends in the customer base and the consumer population as a whole Work with departmental managers to outline the specific data needs for each business method analysis project  
   
 RequirementsThe Prerequisites  Bachelors or masters degree in mathematics, statistic or analytics Experienced with R, SQL, Python and Tableau tools 1 to 3+ years in data analyst experience "
80,Risk (Data) Analyst,ADYEN SINGAPORE PTE. LTD.,"$3,750to$6,000Monthly","Roles & ResponsibilitiesOrdering a pizza? Buying a pair of trainers? Watching a movie?
Hailing a ride? Chances are Adyen is handling your payment. We are a fast-growing technology company, delivering seamless payment experiences to customers around the world.
 Driven by a vision to improve customer experience, streamline processes, and ultimately increase revenue, we enable businesses to process payments across online, mobile, and Point-of-Sale (POS) with over 250 payment methods in 185 transaction currencies all over the world. Over 4,000 businesses use the Adyen payment platform, including Facebook, Grab, Spotify, Groupon, Evernote and
Booking.com. As a part of our skilled team in Singapore,
we need you
to contribute to our growth in APAC, by supporting our biggest and most high profile merchants.
Your risk (data) analysis will often be the
starting point for new business opportunities, so you will make direct impact on business development, next to supporting flawless
operations.
The
Risk (Data) Analyst works closely with other teams, such as
Account Managers, Acquiring, Sales & Compliance
teams, but is part of our
Global
Risk team. This position reports to the
Team Lead Risk APAC.
 RequirementsYou will:
  Execute risk assessments and (data) analysis related to fraud and chargeback for new merchants and monitor the risk exposure during the relationship of these merchants with Adyen. Advice on fraud redundancy to account management based on the data analysis. Provide the risk recommendations and the impact analysis of the risk recommendations to the merchants. Develop projects to improve risk management analysis
and dispute management. Communicate with colleagues on execution and improvements of the fraud & chargeback avoidance or resolution. Determine the necessary data required to address questions, extract the required data, and perform risk analysis for the merchants. Clearly communicate accurate results in a simple and transparent manner.  You are:  Able to approach complex and multivariate calculations in a structural and analytical way Able to work in a high-paced environment with the ability to quickly shift priorities and produce consistent results Capable of effectively communicating complicated data analysis results in a simple fashion A self-starter. You take initiative and ownership and you dare to take decisions You have the ability to thrive in a start-up environment with minimal supervision Comfortable dealing with confidential information and you have high integrity Accurate and inquisitive A team player Fluent in English, both spoken and in writing A recent graduate with an academic bachelors or masters degree  You know and have experience in:  Database SQL Data analysis languages such as R, Python or Matlab
would be an asset.
  Preferably you have:
  Experience in fraud analysis and risk management
 Ability to analytically assess clients on risk exposure Enthusiasm to find creative solutions to mitigate risks related to fraudulent activities "
81,Data Engineer,Company Undisclosed,"$7,000to$9,000Monthly","Roles & ResponsibilitiesWe are requiring Data Engineering for long term projects. This person will be responsible for
developing cutting edge products and solutions. She will be part of the team to offer innovative and ingenious solutions for clients in banking. The Data Engineer ensures that any data is properly received, transformed, stored, and made accessible to other users. The Data Engineer will constructing data pipelines as well as building APIs for data consumption. Besides this person will support
the Data Platform. They will ensure ensure optimized performance by monitoring the system. RequirementsYou will need to have minimum 5 years of IT development experience. The ideal candidate will have experience working with file transfer solution (CFT, sfTP, MQ, kafka) and should be have strong knowledge and experience with reporting packages/tools (tableau etc.), databases (SQL etc.), programming (Python, R, JavaScript or ETL frameworks). The candidatre should be have knowledge of statistics or experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.). Prior experience with data management tools (Ab initio) and Advanced SQL database management is 
a plus."
82,Data scientist,TERALYTICS PTE. LTD.,"$6,000to$12,000Monthly","Roles & ResponsibilitiesWe at Teralytics are searching for an exceptionally talented & highly-motivated data scientist for our team in Singapore. Your responsibilities will include:  Designing and prototyping models to extract insights or make predictions based on mobility, web browsing and demographics data of up to hundreds of millions of people Analysing and making inferences upon the data in order to evaluate the feasibility of data projects or test the performance of existing models Supervising data science interns and assisting software engineers in implementing models in large-scale production systems  RequirementsYou display a keen desire to develop your career in the areas of data analytics, applied statistics and artificial intelligence, and are passionate to learn and develop new techniques. You are experienced in working with data, either professionally or academically. You possess programming skills and are comfortable operating datasets in a programmatic way. You have interest in the realms of urban planning and human mobility and how technology can be leveraged to create Smart Cities. You enjoy working closely with other people in a highly diverse and multicultural environment. Must have:  BS/MS/PhD in Computer Science, Statistics, Mathematics, Physics or related technical fields Experience (preferably 4+ years) with data science topics (such as machine learning, statistical learning, target tracking and localization, probabilistic graphical models, neural networks, etc.). PhD holders may treat their PhD study, if relevant, as part of their professional experience Experience (preferably 2+ years) with programming, data structures and algorithms. Proficient in at least one scripting language suitable for data processing, such as Python, R or MATLAB Experience with location data analytics Experience with processing cellular, Wi-fi, or URL data
  Advantageous:  Substantial experience in applying machine learning and statistics to large amounts of data in either academia or industry. A PhD in the topic is a plus Experience working with distributed computation tools (e.g. Hadoop, Storm, Spark, Hive) and/or streaming data Knowledge of statistics including those in multivariate statistics, spatial-temporal statistics and time series analysis. Experience with Bayesian estimation techniques such as particle filters, Viterbi algorithm and Markov Chain Monte Carlo (MCMC) methods Experience with Python, Scala and/or functional programming "
83,Data Engineer,SEPHORA DIGITAL SEA PTE. LTD.,"$4,500to$5,500Monthly","Roles & ResponsibilitiesThe Sephora Data team is expanding. As a critical business function finding the right people to contribute to our high growth, fast changing environment is critical and challenging. The Data teams mission is to create the necessary data pipelines between our applications and enable teams across the business to use the data for informed decision making. To succeed in this team youll be super smart, passionate about innovation and trying new approaches, and youll be a skilled programmer with strong commercial instincts and passion for business success. Sephora South East Asia operates digitally in 8 markets and through bricks & mortar stores in 5. With a mission to become the leading omnichannel player in the region by 2019, the business is going through a transformation. This is especially true on the digital side, where rapid revenue growth and the increased resources that have come from being part of Sephora / LVMH have presented us with a tremendous opportunity. As you will work in a small team with a broad scope, you may play one or more of the following roles:  Data Warehouse Architect: Our Data Warehouse is the data gold mine of the group, the data is used by all our entities across Asia and Oceania. You will build and maintain data pipelines to enrich the DWH. You will also bring your devOps expertise to enhance the infrastructure as we are growing very fast. Analytics Expert: Were currently selling products in 8 different countries, through websites, mobile apps, retail stores to internal applications. You will build a solid analytics strategy to collect the right information from the right places and make sure we are aligned with the business KPIs. Software Developer: You will create and enhance innovative data products and automations that change our teams/customers life. From marketing to CRM, from finance to BI, you will collaborate with different teams, understand their needs and build disruptive solutions to support them.  RequirementsIf taking on the responsibilities of one or more of these roles seems like your ideal job, please send us your application. Your attitude, experience and passion is more important than specific experience. These are technologies / notions were using: being the master of some, and familiar with most will be a significant advantage.  Python / Go / NodeJS / SQL Django / Express BigQuery PostgreSQL Google Analytics Google Tag Manager Experiences with APIs (Google, Facebook, Adwords...) Experiences with AWS or Google Cloud Platform Git "
84,"Analyst, Data Science and Intelligence (1 Year Contract)",RESOURCE SOLUTIONS CONSULTING SINGAPORE PTE. LTD.,"$2,850to$4,380Monthly","Roles & ResponsibilitiesMUFG Bank, Ltd, a member of Mitsubishi UFJ Financial Group Inc (MUFG), is Japans premier bank, with a global network spanning more than 40 countries. Outside of Japan, MUFG offers an extensive scope of commercial and investment banking products and services to businesses, governments and individuals worldwide. In the Asia and Oceania region, MUFG has presence in 13 key markets with 32 offices and closed to 4,500 employees serving largely corporate and institutional clients. Singapore has served as the regional headquarters for South Asia, South-east Asia and the Oceania region since July 2013. While the regional headquarters for the East Asia region remains in Japan. MUFG is one of the worlds leading financial groups with total assets of JPY 258.1 trillion by the end of March 2014. MUFGs services include commercial banking, trust banking, securities, credit cards, consumer finance, asset management, and leasing. The Groups operating companies include MUFG, Mitsubishi UFJ Trust and Banking Corporation (Japans leading trust bank), and Mitsubishi UFJ Securities Holdings Co., Ltd., one of Japans largest securities firms. MUFGs shares are traded on the Tokyo, Nagoya, and New York (NYSE: MTU) stock exchanges respectively. Job responsibilities include:  To manage data teams end-to-end activities which includes raw/reporting data production in SAS Enterprise Guide, data cleansing and reconciliation to support Credit Risk Management for Asia region To identify and implement business process improvement to meet the reporting and business requirements, ensuring process and data quality control To manage regular and adhoc data requests from internal and external stakeholders To contribute to projects for enhancing risk management framework including defining its measurements and establishing the methodology of setting risk limits  RequirementsJob requirements include:  Degree in analytics, engineering, computing or other equivalent 1-2 years of relevant experience Knowledge of programming skills (VBA, SQL and SAS) is required Understanding of database design principles is a plus Basic understanding of risk management related modules and measurements is also a plus Team player with a positive attitude and ability to perform tasks independently to meet tight deadlines  Recruiter Name: Natalie Tan EA License No: 12C5536 EA Registration No: R1106672



 
 We regret to inform that only shortlisted applicants will be notified."
85,Market Data Business Analyst  /  Project Manager,ALLEGIS GROUP SINGAPORE PRIVATE LIMITED,"$12,000to$15,000Monthly","Roles & Responsibilities Engage customers and operational staff in documenting detailed requrements as we progress through our strategic customer journey. Working with Trade Services management team, implement a PMO framework; build programme-based business plans, project budgets and resource break-down streams that allow investment decisions. Monitor progress and delivery across the portfolio of approved projects and business plans. Manage communication plans across the division and our customers. Provide structured reports to management on programme execution performance, resource management and cost management across the portfolio. Where a vendor-lead solution is appropriate, work with the market data team, engaging with our vendors and sourcing colleagues, to prepare RFIs, RFPs.  Requirements Demonstrated experience in project management and formal project management, preferably with PMP / PRINCE2 qualifications 10+ years experience working in banking environments or other highly regulated environments. 10+ years working in the market data industry, with market data product awareness and exposure to market data contracts and technologies. 10+ years working with market data delivery technologies and associated commercials. Demonstrable experience in executing RFI and RFPs as a market data subject matter expert. Experience in managing resource groups in matrix organisations and in leading teams of less than 5 people. Experience in working with the SDLC and development teams. Comfortable in communicating with SVP, ED and MD leaders.  Preferred Experience  Experience in working with financial sales and trading staff; financial business management is a plus Book keeping or financial accounting knowledge is a plus. Public cloud experience is a plus. "
86,Data Engineer,Company Undisclosed,"$3,500to$5,500Monthly","Roles & ResponsibilitiesAbout Our Client Our client is a Fortune Global 500 management consulting firm with a well-established market presence in Asia. You will be part of a dynamic and high performing team dedicated to drive innovation and to facilitate their client's digital transformation projects in Singapore. Job Description  Ensure the data warehouse load jobs run as per schedule and data availability to the business is uninterrupted. Implement and maintain data pipelines, both bath and real time, as well as the infrastructure required. Develop advanced analytical models that help the business identify trends within customer base and behaviour. Perform all needed data cleansing and transformation to improve quality of input for research.  RequirementsThe Successful Applicant  Bachelor's degree in Computer Science (or equivalent experience). Hands-on development experience with ETL/ELT tools. Proven experience with Data Warehousing and Big Data technologies. Working knowledge of big Data Technologies like Hadoop, Hive, Spark and streaming/messaging services like Kafka,Spark streaming. Solid understanding of some BI tools such as Cognos, QlikView or Tableau.  What's on Offer This organisation is a global brand name, with strong presence in Singapore as their regional headquarters. They have been constantly growing in the APAC region and are one of the most trusted companies globally. The firm is highly focused on on-boarding the right talent to support their growth and you will play a crucial role in leading the business in its next phase of growth. If you are driven, determined and want to fast - track your career, this job will be a good fit for you. You will be a part of a forward-thinking company that values innovation and a progressive mind-set. Contact:
 Rodrigo Narcizo Quote job ref:
4007951 +65 6419 9681"
87,"Lead Engineer, DCIM ( Data Centre Infrastucture Management)",KEPPEL DATA CENTRES HOLDING PTE. LTD.,"$4,500to$6,500Monthly","Roles & Responsibilities Ensure DCIM systems are operating as designed to protect the data center, capture power usage, calculate available capacity, and provide meaningful, timely alarms, notifications and reports to end users Interface with design consultants and BMS vendors to ensure BMS reliability objectives are met for new data center deployments and data center retrofit projects. Coordinate application deployments and IT infrastructure between the vendor and Corporate IT departments. Provide tactical leadership to implement enterprise alarming standards at the site level. Ensure site alarms are delivered to the Keppel Control Center teams Develop validation program for system alarms to ensure the right alarm is received by the right person at the right time. The configuration of EPMS applications in support of new data center deployments, new data requirements and data center retrofits. Create standards and follow implementation by regional engineers on system administration of DCIM systems which include: application/database backups, redundant platform readiness, licenses management, infrastructure coordination for application support, etc. Prepare and maintain DCIM systems support documentation, test plans, and change management records. Coordinate DCIM systems Ethernet and IT requirements with internal IT operations. Engage, lead, and direct vendors via Scope of Work and Requests for Proposals/information documents. Implement corporate policies procedures and standards to maximize the performance of systems, applications and networks. Work closely with co-workers, maintenance personnel, project managers, building managers, engineers, and contractors on site-specific projects. Perform inspections, and assist in the testing and commissioning of the facility system (as required).  Requirements Degree in Electrical Engineering, Engineering Technology, or other related Engineering degrees or equivalent professional experience. 10 or more years of experience with critical monitoring/control systems and support for critical facilities. Working knowledge and experience with a BMS and building EPMS systems. Familiarity with power distribution systems in a data center environment or similar critical systems environment. Expertise in systems Programming using Java/C++, data modelling and event processing techniques. Demonstrated experience with SQL and No-SQL technologies (Cassandra, Storm, MongoDB etc.) Highly desired to have hands-on experience with Datacenter infrastructure monitoring platforms and frameworks. Experience performing commissioning, qualification & change control activities related to BMS including but not limited to HVAC, chiller plants, domestic and process water systems, building automation systems, etc. Ability to read, interpret, and produce engineering documents that may include: Control Drawings, Sequence of Operations, Bill of Materials, Graphical User, Interface requirements, and Functional Specifications. Experience with BAC-net, Modbus, TCP/IP configuration, SNMP communication protocols, Active Directory security and Microsoft Office tools. Understanding of basic power calculations on single and 3-phase circuits, electrical diagrams, control diagrams Demonstrated experience with cloud computing and IoT models/architecture is preferred "
88,AI and Data Engineer,FLEXOSENSE PTE. LTD.,"$3,600to$4,600Monthly","Roles & ResponsibilitiesThere is an opportunity to make a difference where it matters. We are looking for visionaries who are keen to make a positive impact on the way the world lives. 
 At FlexoSense, the future is yours to determine, create and enjoy. Join us as the pioneering team on a game-changing journey. Job Responsibilities  Interact closely with research project team which includes academics, clinicians and industry partners. Conceptualise, develop, integrate and maintain in-house AI and Cognitive solution. Apply state-of-the-art AI algorithms, explore alternatives and build working prototypes. You will also deploy systems and scale the solution. Create models, train and leverage machine learning APIs to build solution with embedded intelligence in use-cases like Chatbots. Follow Agile/Lean/Scrum software methodologies for development. Certified ScrumMaster (CSM) will be an advantage. To research and be updated on the state of the art on AI, data engineering and data science practices. Be plugged into the wider community on these key areas.  
 Requirements
 1. Bachelors or Masters degree in AI, Machine Learning, Statistics, Computing, Biostatistics, Information Technology, Social Sciences or related fields. 
 2. Experience preferably in  Open source DevOps tools and software-as-a-service solutions Development and implementation of AI and machine learning algorithms AI or deep learning work at a commercial company or research laboratory. Experience in building deep learning models with popular frameworks e.g. TensorFlow. Knowledge of common machine learning techniques and key parameters that affect performance.  3. At least 2-3 years hands-on experience in developing applications and with various data analysis and visualisation tools. Experience with R and/or Python. 4. Proven experience with track record of processing and extracting value from large data sets. i.e. Data analysis and discovery with new insights. Understand relevant statistical measures (development and evaluation data sets, confidence intervals, significance of error measurements, etc) 5. Data warehousing/RDBMS experience with SQL Server, Oracle, MySQL, etc. 6. Demonstration of self-learning through hackathons, MOOC or open user-group and conference participation. Self-motivation with side projects, Kaggle competitions, etc. 7. Proficient in running deep learning modules on Cloud platforms like Azure or Google Cloud. 
Able to use Virtual Machine instances on these platforms. Experience in test automation, test-driven development and cloud-based implantation will be an advantage. 8. Strong system-building and management skills and keen interest in working with emerging technologies and frameworks. 9. Good awareness of security considerations/best practices for web-facing applications. Having a strong interest in learning new security technologies and tools are essential. 10. Good data skills; able to combine technical visualisation libraries (e.g. Python) with more user-friendly tools like Tableau. Ability to apply good design principles to visualisation, dashboard and reports 11. Strong communication skills and early adopter and growth mindset is highly regarded. Ability to present and explain difficult concepts clearly and concisely in plain English. 
 About FlexoSense FlexoSense is a startup with co-founders from the National University of Singapore. Our flexible sensors enable new experiences in markets like healthcare, lifestyle, sports, robotics and more. We champion those with bold ideas and with a can do spirit in creating a difference for our customers. We want to spark something remarkable in bringing together people committed to a common goal. 
"
89,Business Analyst - Big Data & Analytics (JD#4293),SCIENTE INTERNATIONAL PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesWe are looking for a Business Analyst with good business domain knowledge in Treasury & Markets space to propel
new Big Data & Analytics initiatives
within the bank. RequirementsWe are looking for a Business Analyst with good business domain knowledge in Treasury & Markets space to propel
new Big Data & Analytics initiatives
within the bank. Mandatory Skill-set  Degree
in Banking, Commerce or Information Systems; At least
5 years of relevant Business Analyst experience in the Financial Services Industry; Hands on experience in Big Data projects; Proficient
in Microsoft Excel, VBA, SQL queries for data analysis and reporting; Familiar with both Waterfall and AGILE development methodologies; Excellent stakeholder management skill to liaise with people across different levels and departments; Good presentation skills to be able to articulate clearly with attention to details; Resourceful, active team player with strong analytical skill; Excellent verbal and written communication skills.  Desired Skill-set  Familiar with BI tools such as Qlikview, Qliksense and R; Has knowledge in treasury with expertise in at least one asset class.  Responsibilities  Responsible for working with business users to gather, understand, collate and document business requirements; Involve in new project implementation, enhancements and Business As Usual operational support; Work closely with the technology team to articulate business requirements and translate into technical specifications; Coordinate closely with stakeholders to conduct business requirements walk-through on enhancements and new projects; Create and execute testing plans and coordinate both the System Integration Testing and User Acceptance Test; Identify obstacles, proactively mitigate risks and escalate issues to be resolved effectively; Support in the Business-As-Usual activities and ensure that users requirements and requests are delivered timely, accurately and successfully. "
90,AI DATA SCIENTIST (MACHINE COMPREHENSION),AMARIS.AI PTE. LTD.,"$4,000to$9,000Monthly","Roles & ResponsibilitiesWe are looking for exceptional Machine Comprehension
Data Scientists to embark on our journey to deploy world class
deep learning and machine learning algorithms in the investment and portfolio management space  The Data Scientist (Machine Comprehension) should
have a PhD or Masters in Computer Science, Statistics, Deep Learning or Machine Learning and a strong background in statistical methods such as Bayesian statistics, time series, and feature engineering.  If you have a passion for building
state-of-the-art deep learning and machine learning models and have an keen interest in
Natural Language Processing and semantic AI, this is your opportunity. Requirements  Implement state-of-the-art deep learning and machine learning models for feature engineering and question/answer/prediction in investment platform   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions  "
91,"VP, Data Engineer, Asian Insights Office, Group Research (180002PI)",DBS BANK LTD.,"$10,400to$18,700Monthly","Roles & Responsibilities Work as part of a team to architect, design and develop a platform for semantic knowledge capture and representation for quantitative modeling, analysis and prediction of economic and financial metric and trends and from institutional and public data; Lead and work within the knowledge content team to drive strategic projects and initiatives to achieve customer experience excellence; Build data analytics capabilities in areas such as predictive/ prescriptive analytics across functional areas especially in the area of equity research; Conduct strategic data analysis, identify insights and implications from institutional and public data to enhance our research product offerings; Develop data displays that clearly communicate complex analysis; Thrive in an Agile environment & be able to perform end-to-end development from requirements gathering, to prototyping, design, development, testing and deployment; Manage other data instrumentation projects undertaken by the team, and be accountable for their delivery (including planning, prioritization, scope, risk/ issues management).  Requirements Masters Degree holder from an accredited college or university in a quantitative discipline such as statistics, quantitative finance, business/ finance, computer science, mathematics, economics or related fields of study; At least 8-10 years of relevant work experience in the area of big data and data science; Proficiency in data collection, cleaning and curation and feature engineering; Experience designing, architecting and developing high throughput data pipelines for real-time analytics; Experience with cloud based solution development, architectures and operations; Experience with Agile, XP development practices, Continuous Integration, Test Driven Development approaches; Knowledge of big data toolsets, including R, Python, Apache Spark and/or Hadoop; Expert in at least one machine learning technology including Regression, Ensemble Models, Gradient Boosting and Deep Belief Networks; Excellent verbal & written communication skills, including ability to facilitate meetings and present to senior business executives. "
92,Data centre operations engineer,ENCORA TECHNOLOGIES PTE. LTD.,"$4,000to$5,000Monthly","Roles & ResponsibilitiesJob Description for the Datacenter Hands & feet operations Position: The Data center hands and feet engineer will Perform day to day activities, users, visitors and subscribers co-ordination. Co-ordinate with visitors visiting the DC for activities Will co-ordinate with respective teams with in a project Will be responsible for handling issues pertaining to operations and production Will be responsible to manage incidents during the shift Will be part of DC hands and feet operation team to work for customer on different DC member sites (




 Singapore) in the project and performing equipment Installation and Decommission, troubleshooting. Travel to different sites for INC/Planned activities Will be installing and decommissioning equipments, servers racking and stacking in the Datacentre Will be performing DC Cabling, labelling, patching Daily DC server health checks, walkthroughs, reporting, printing, remedy and email queue management Will be responsible for keeping cardboard and contaminants out of the Data centres and ensuring the space is safe and secure Must have DC Cabling and equipment hardware troubleshooting knowledge Should have basic understanding of DC facilities, environment and standards Receiving the material deliveries, maintaining the inventory store room Maintaining visitor records & access logs 24*7 environment, shift rotation Flexibility per team rotation requirement Professional in 24/7 operational team availability Additionally, must have strong verbal and written communication skills, be a motivated team member. Job Requirement (The Skill required) Hands on with DC infrastructure environment Good Experience in DC 24*7 Operation process & procedures DC racking and stacking & structured cabling understanding RequirementsShift Timing: 3 shift( Morning, afternoon and night shift)"
93,Data Scientist,NIOMETRICS (PTE.) LTD.,"$5,000to$10,000Monthly","Roles & ResponsibilitiesWHAT WE DO Niometrics captures, organises and extracts insights from some of the biggest and most complicated datasets that our modern societies currently produce. We put a magnifying glass on the realities collectively constructed by billions of connected individuals and machines, making sense of how humanity is re-creating wholly new digital universes with bits and bytes  universes that need to be seen, interpreted and explained. From taking deep dives into digital behaviours, to exploring the most intimate interactions between network technology and user experiences, we do it all. Our Data Science team consists of ambitious, creative and passionate individuals, united in the common goal of making a difference. With millions of users generating hundreds of TBs of data daily, our day-to-day job becomes an adventure of connecting digital signals with real-life habits to formulate granular audience insights  who they are, how they behave, and ultimately, how we can expect them to behave in the future. The action does not stop there  we also take pride in working with the latest high-end hardware and world-class software architecture. This means there are virtually no limits to the scope of future events we can model, giving us insights on not just people, but also the entire inter-connected ecosystem to which they belong. We are perfectionists and we do not hide it. You will join a thrilling environment, implementing and deploying data science solutions that are both efficient and secure, setting the basis for a groundbreaking software platform for the long run. RequirementsYOUR ROLE AS DATA SCIENTIST As a Data Scientist, you will work end-to-end, leading entire projects and owning their outcomes through their entire lifecycle. You will formulate hypotheses on structured and unstructured data, design experiments, draw meaningful conclusions and effectively communicate the results to business stakeholders. You will be part of a relentless team, curious to extract the highest value possible in the most effective way. You will put into action your machine learning skills, and together, we will build optimum algorithms for regression, classification, clustering, and information extraction. WHAT WE VALUE  BA/BS (or MA/MS) or equivalent experience in applied Data Science.  Proficiency in statistical packages and ML libraries for both big and not so big data (e.g. Python SciPy ecosystem, NLTK, Tensorflow or equivalent, Spark ML and MLlib, etc.)  In depth knowledge of cutting-edge machine learning algorithms, as well as the strengths and weaknesses of the different methods and algorithms on different applications.  Experience in Unix systems and scripting in bash.  Proficiency in code optimisation (knowledge of Cython or similar)."
94,Reinsurance Data Analyst,AXA INSURANCE PTE. LTD.,"$3,800to$6,000Monthly","Roles & ResponsibilitiesThe AXA Group is a worldwide leader in insurance and asset management, with 166,000 employees serving 103 million clients in 64 countries. AXA is the number 1 Global Insurance Brand for the 9th year running, and is also the number 1 insurance company in the Top 50 Most Innovative Companies. 
 The position contributes to strengthen the Reinsurance Optimization capabilities of AXA Singapore as one of the main local market players and within the dynamic environment of a worldwide leading insurance group. Linking Reinsurance modelling, profitability enhancement and strategic business decision is a key challenge for the department to ensure the companys profitable growth and assist AXA to maintain its reputation as an innovative and technical company. An independent team member with a self-starter mindset, the Reinsurance Data Analyst within the Actuarial team is expected to efficiently identify pockets of optimization within several sub sections in the GI and Life Reinsurance portfolios. It is a role allowing a deep dive into the Finance and Reinsurance expertise, providing a wide exposure across the GI, Life and Health business, allowing the analyst to develop cutting hedge Reinsurance technics and business understanding across portfolios per LoB and treaties. A glimpse of your daily mission:  Improve our capability to quantify retention for all LoBs in GI and Life, this includes managing different systems and enhance calculation of earnings impacts per band of exposure Develop if possible our capabilities in flood modelling in Singapore and overseas to which we are he exposed taking examples on
 known systems (Aon Analytics, Guy Carpenter) Enhance Life Admin system on Reinsurance Administration Management (RAM) Phase II - claims module that would be used by Reinsurance and Life teams  RequirementsSuccessful qualifier of this mission:
  Graduate in Engineering, computer science, actuarial sciences or financial engineering Strong IT knowledge: Excel, VBA, SAS,R, Python Excellent analytical and problem-solving skills Good presentation, communication and inter-personal skills Strong team player and influencing team / internal stakeholders positively Solid project management skills due to large number of parties involved and tight deadlines Timely and accurate delivery Independent innovative with a self-starter mindset  Please send us your updated resume to hr@axa.com.sg As we are continuously looking for great talents like you, do share AXA career opportunities with other talents! Link for our website is https://www.axa.com.sg/about-axa/careers To all recruitment agencies
AXA ONLY accept resumes from appointed agency under our Preferred Supplier List. Please do not forward resumes to our jobs alias, AXA employees, any AXA entities or company location. AXA is not responsible for any fees related to unsolicited resumes.
 
"
95,Semiconductor Manufacturing Equipment Data Scientist,TOKYO ELECTRON SINGAPORE PTE. LTD.,"$4,000to$7,000Monthly","Roles & ResponsibilitiesResponsibilities To integrate TELs tool and customers quality data to provide statistical or machine learning analysis to improve TELs equipment overall efficiency  To
 partner with customers Data science group
 and TELs process engineers to define problem statements, acquire and analyse data , create visualization to explain the data and to identify sensors of interest that correlate to customer quality data (yield, defect, CD, etch rate etc.,.) Understand the data infrastructures requirements, define the best data storage solution and support TELs development team to design data analytics applications. These applications will extract data ( and images) from relational databases and big data storages, processing and analysing data, calculating summaries and indicators, detecting patterns and finding the root cause, performing commonality analysis and data mining.  
 Requirements
Requirements  BS or MS in Computer Science/Data Science/Statistics or
a related field with at least 3 years of experience Candidates with prior semiconductor manufacturing data analysis experience preferred The candidate must have a strong knowledge in one or more of the following areas: Big Data Technologies, relational databases, machine learning algorithms, data mining, yield analysis, statistical analysis, and image processing. Expertise in Web development, Hadoop, HBase, Java, Python, R and SQL is/are preferred This position requires strong written and oral communication, analytical problem solving, leadership
 and teamwork skills "
96,Senior Data Engineer,VISENTI PTE. LTD.,"$4,500to$7,000Monthly","Roles & ResponsibilitiesOur Cloud application development team is looking for an experienced Software Engineer to work with us on building a robust framework for data management (archival, provisioning, streaming, translations) to various applications and distributed access for our Big Data analytics platform. Must have experience handling noSQL databases especially MongoDB. If you live and breathe SQL/noSQL, apply today! We have a strong team that needs to work with data, but we're missing key personnel to help us manage the terabytes of data. We are a team that loves to experiment and explore, with very rapid decision making and a solid foundation of engineers. Responsibilities  Build and maintain code to manage data received from heterogenous sources including field sensors, web-based sources, internal/external databases, flat files, heterogenous data formats (binary, ASCII, audio/visual etc.) Perform all necessary data transformations to populate data into a warehouse optimized for Data Mining. Design, build and support data formats, conversion, validation, XML, Json Design, build and launch new data extraction, transformation and loading processes Design and support effective storage and retrieval of BigData > multi TB Assess the impact of scaling up and ensure sustained data management and delivery latency performance Build interfaces for accomodating new sources/types of data Build interfaces for supporting evolving applications / new applications' data needs  
 RequirementsQualifications: Minimum of 2-5 years relevant experience, relevant certification will be a strong plus.

 Requirements:  Experience with Hbase or comparable NoSQL. Experience with Hadoop stack (HIVE, Pig, Hadoop streaming) and MapReduce Solid experience in custom ETL design, implementation and maintenance Database experience with MySQL, MSSQL or equivalent Experience in cross-platform message queues, and ESB (Mule, Fuse) Software development: C/C++ or Java, Python , Linux/Unix Excellent analytical and problem solving skills with the ability to think quickly and offer alternatives Organized, goal-oriented, motivated self-starter who can work well in a team environment; Working knowledge of agile software development life-cycle "
97,Big Data Engineer,BIGO TECHNOLOGY PTE. LTD.,"$4,000to$12,000Monthly","Roles & Responsibilities Build highly scalable and optimized data products/manage data sets via stream processing. Build tools and frameworks that ensure highest quality of data, make data discovery and data access easy for everyone at Bigo. Own the data products critical for product innovation and recommendation engines; define and drive the adoption of data logging standards Partner with various Engineering teams, UI teams, Product Managers and data scientist to understand the business context  Requirements You have coding experience in one or more programming languages (Scala, Java, C++, etc) Familiar with the mainstream distributed processing framework - Hadoop, hive, flink or Spark programming. Excellent communication skills and teamwork skills. "
98,Senior  /  Lead Consultant (Data Scientist),NCS PTE. LTD.,"$6,000to$10,000Monthly","Roles & Responsibilities Work with customers to identify opportunities where Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) can be applied to data to solve the customer painpoints. Individually or collaborate with other team members to develop AI/ML/AA prototypes/Proof-of-Concept/Proof-of-Value to derive actionable insights from data. Collaborate with the customers and internal stakeholders to architect the overall supporting storage and compute infrastructure to support the deployment of the AI/ML/AA models, applications, and visualisation of the results.

 Collaborate with the relevant project managers to conceptualise, develop project scope, requirements, budget, and timeline for the implementation of the identified AI/ML/AA projects. Implement the AI/ML/AA projects and to ensure that the projects AI/ML/AA objectives are met.  

 Requirements PhD/Masters/Bachelors (with good honours) in Computer Science, Statistics, Applied Mathematics, Operations Research, or related disciplines. Prefer candidates with
5 or more years of working experience, with at least
3 years of Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) experience. Domain experience in public safety, defence, transport, education, and healthcare are highly desired. AI/ML/AA experience in smart city, social media, and procurement are also highly desired.
 Good knowledge of AI/ML/AA models, software, and tools with the ability to conceptualise and architect the key components of AI/ML/AA projects; and to develop prototypes using statistical software packages such as R/SAS/SPSS. Experience working with very large data sets, including statistical analyses, data visualization, data mining, and data cleansing/transformation and machine learning. Experience in solutions using technologies such as Hadoop/Hive/Hbase/NoSQL and developer skills in Python, Perl, and Java are highly desired. "
99,Senior Data Transformation Analyst,IHS GLOBAL PTE. LTD.,"$7,000to$8,000Monthly","Roles & ResponsibilitiesThrough its product offerings covering the offshore infrastructure markets, IHS Markit provides an impartial online service incorporating valuable data, market intelligence, news and analysis to support our customers' commercial and contracting decisions with accurate, up-to-the minute information.  To achieve the company's goal of providing accurate, independent and impartial data and analysis, the Senior Data Transformation Analyst will undertake continuous research of the offshore infrastructure market for real-time news and data updates, maintaining constant direct dialogue with oil and gas operators, shipyards, equipment manufacturers and service companies, providing independent verification of asset status, contractual information and technical specifications. Job Description  Based in Singapore this is a critical position in support of the company's varied customers who participate in the offshore market. These customers include international and state-controlled oil and gas companies, contractors, financial analysts, vessel owners, shipyards, equipment suppliers and others. Some travel may be necessary. The role includes a range of responsibilities, including, but not limited to:  Contacting external sources for information retrieval and verification;  Maintaining and updating the company's proprietary databases;  Analysing internal IHS Markit and external industry data and market intelligence, and incorporating conclusions into publications and reports;  Contributing editorial content to the company's news service, monthly market intelligence publications, offshore market forecasts, and other research reports as assigned, with emphasis on timely delivery, data quality and insightful analysis;  Supporting industry news and data gathering and reporting activities as assigned. Become an expert on the Rig and Marine markets as well as Field Development activity.  Prepare written reports or presentations following IHS Markit standards. Present at tradeshows and conferences as well as to clients.  Maintain a fundamental working knowledge of the basic IHS Markit databases and tools  Collaborate with Sales and Marketing to develop, execute and optimise promotion of products and services. 
 Requirements Excellent verbal and written communication skills with fluency in English  Ability to interact with clients, either internal or external, and identify the critical elements that need to be examined from a process standpoint  Effective communication skills including ability to develop presentation of findings suitable for upper management review  Strong analytical skills  Working knowledge of common spreadsheet, word processing and presentation software  Solid grasp of global geography  Presenting at conferences and trade shows"
100,Data Scientist,NCS PTE. LTD.,"$6,000to$9,000Monthly","Roles & Responsibilities Work with customers to identify opportunities where Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) can be applied to data to solve the customer painpoints. Individually or collaborate with other team members to develop AI/ML/AA prototypes/Proof-of-Concept/Proof-of-Value to derive actionable insights from data. Collaborate with the customers and internal stakeholders to architect the overall supporting storage and compute infrastructure to support the deployment of the AI/ML/AA models, applications, and visualisation of the results.

 Collaborate with the relevant project managers to conceptualise, develop project scope, requirements, budget, and timeline for the implementation of the identified AI/ML/AA projects. Implement the AI/ML/AA projects and to ensure that the projects AI/ML/AA objectives are met.  

 Requirements PhD/Masters/Bachelors (with good honours) in Computer Science, Statistics, Applied Mathematics, Operations Research, or related disciplines. Prefer candidates with
5 or more years of working experience, with at least
3 years of Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) experience. Domain experience in public safety, defence, transport, education, and healthcare are highly desired. AI/ML/AA experience in smart city, social media, and procurement are also highly desired.
 Good knowledge of AI/ML/AA models, software, and tools with the ability to conceptualise and architect the key components of AI/ML/AA projects; and to develop prototypes using statistical software packages such as R/SAS/SPSS. Experience working with very large data sets, including statistical analyses, data visualization, data mining, and data cleansing/transformation and machine learning. Experience in solutions using technologies such as Hadoop/Hive/Hbase/NoSQL and developer skills in Python, Perl, and Java are highly desired. "
101,DevOps Engineer (Big Data),NTT DATA SINGAPORE PTE. LTD.,"$6,000to$8,000Monthly","Roles & Responsibilities
-
Experience
building solutions with Apache Kafka.

 - DevOps experience
deploying, monitoring, 
automating
and maintaining
distributed Big Data
cluster.

 - Understanding of system operations concepts (disk, network, operating systems).

 - Experience with automation and
provisioning
tools like
Ansible and Terraform.
 


 RequirementsWe are looking for candidate with strong system engineering skills in an operational role. We may also consider any (preferably
Big Data) developer
candidates who has experience working on the
Dev side in a
DevOps environment who are open to switch over to a opps heavy role.
"
102,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$2,500to$5,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Possess minimum 1 year of relevant work experience Ability to work independently to translate research ideas into programs with efficient coding Basic knowledge on data analytics, machine learning, data mining Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
103,Data Scientist / Senior Data Scientist,SINGAPORE POWER LIMITED,"$4,000to$8,000Monthly","Roles & ResponsibilitiesWhy Work for Us We Power the Nation.  Make the most of your talents and develop products that can create impact on a national scale. We are an in-house software team, assembled to move with speed and deliver with quality. 
 We Build Reliable Solutions. For Customers, Company and Country.  You will be part of the Digital Technology Team and together, you will innovate, create, and deploy digital products that will empower more than 3,800 employees within SP Group and improve the quality of life for the 1.5 million commercial, industrial and residential customers that SP Group serves. We build solutions that enable sustainable high quality lifestyles and help consumers save energy and cost, as well as supporting national goals for a sustainable livable city. Now, imagine the impact you can create. 
 SP Digital Technology aims to use cutting edge technologies to help SP Group to revolutionize future utility/energy industry by providing better services and more efficient energy solutions to our customers. Data charter consists of data engineering, business intelligence, data science/machine learning teams. We oversee and drive all data and AI initiatives for SP group. It includes the following  Build next generation data infrastructure to collect/process/analyze different data from consumers, assets, energy  Discover the business problems/opportunities and design data-driven solutions to improve operation/business/customer experience  Uncover the actionable insights for multiple stakeholders to drive business growth 
 The mission of data team is to drive SP to become data-driven company and create data-driven products. As a data team member, you will be responsible for designing, developing and deploying data-driven solutions to create business value. We are looking for a Data Scientist who will help us discover patterns hidden in large amounts of data and make decisions from different sources. Your primary focus will be in applying data wrangling and machine learning techniques to build high quality anomaly detection, prediction and recommendation systems integrated with our products. You will work closely with customers and data engineers to understand the business requirements, in-house infrastructure and help build solutions for different business users. 
 What You'll Do  Understand business logics from domain experts and come up with reasonable targets for data projects  Data fetching from different sources such as database, big data lake running on hadoop/hive  Enhancing data by building autonomous pipelines from different sources  Data wrangling by preprocessing, cleansing, and feature engineering  Applying state-of-art machine learning techniques such as RNN, CNN for predictions and anomaly detections  Build agile data products in a team of data engineers, scientists and business users  Doing ad-hoc analysis and presenting results in clear manner  Guide junior team members on their projects  Help find opportunities from different business partners 
 RequirementsWhat You'll Need We are looking for Passion and Proficiency  Data-oriented personality and software engineering practices  Excellent understanding of machine learning models, their pros and cons  Experience with common data science toolkits such as Python/R  Experience with data visualization tools such as D3.js, matplotlib and etc  Proficiency in using query languages such as SQL, Hive  Good understanding of statistics, such as distributions, A/B testing, model overfitting/underfitting  Experience with one of deep learning libraries such as Tensorflow, Keras, Pytorch, CNTK, MXNet etc  Master or PhD of Computer Science/Engineering, Applied Mathematics or other engineering related area"
104,Data Analyst,TUV SUD ASIA PACIFIC PTE. LTD.,"$5,000to$6,000Monthly","Roles & ResponsibilitiesEstablished 150 years ago in Germany, TV SD is an international service corporation and a world leader in consulting, testing, certification and training. We are headquartered in Munich, Germany with more than 24,000 highly skilled individuals across 850 offices and operates in more than 50 countries around the globe. In line with Singapores Smart Nation initiative, TV SD has set up a CoE for our Digital Service business to drive the development of new services and future businesses in the smart industry sectors. The first site of CoE was launched in January 2016 in Singapore, followed by the launched of the second CoE site in Munich the same year. We are currently looking for a highly skilled and proactive Data Analyst to join our growing team. We offer the unique opportunity to work in a dynamic start-up environment within an established Multinational Corporation. Position Summary The candidate will be expected to work closely with the business and technical team members, as well as internal and external partners, in order to develop, apply and recommend Data Analytics solutions in the field of Smart Buildings & Lifts and Smart City sectors. A sound knowledge of Data Analytics and corresponding software packages, as well as application specific expertise enable the candidate to efficiently implement and run context dependent data based solutions. Key Responsibilities  Cooperate with subject matter experts and customers to develop application specific data based solutions Perform data mining from various data sources collect, store and model real-time and offline data for specific applications Implement and develop real-time analytics and business intelligence platform Review and provide recommendations on data analytics platform implementation and algorithms during the implementation of IOT projects Generate, maintain and provide statistical information for the specific applications on real-time basis Review the data collection platform to ensure accuracy and reliability for analytics Develop and lead data analytics activities in Singapore through strong interaction with other TUV SUD legal entities. Prepare reports, presentations and information to management, business development and partners Publish latest developments in articles and conferences  RequirementsKey Requirements  Degree in Statistics, Mathematics, Computer Sciences, or equivalent studies with at least 4 years of data analyst experience in the technological field Knowledge of data modeling, statistical methodologies, data mining techniques and testing Good knowledge and understanding of local digital landscape, technology, business trends, business intelligence and smart technology applications Expert in real-time analytics, scripting languages and adept with Java, MapReduce and Hadoop, SQL databases Able to learn and deploy new systems and applications Able to articulate complex data and information effectively and clearly An independent, confident and proactive team player with work experiences in a multi-cultural, cross-divisional and inter-disciplinary culture "
105,"Contract Staff (Senior), Business Analyst, Data & Transformation, Technology & Operations (18000308)",DBS BANK LTD.,"$5,000to$10,000Monthly","Roles & ResponsibilitiesJob Purpose
 Define and design experiences that drive the worlds best digital bank. DBS is at the forefront of leveraging digital technology to shape the future of banking. Digital defines who we are, the way we live, work and play. Here at DBS, we recognize that delivering great customer experiences goes hand in hand with providing great employee experiences. As part of the Employee Experience team within DBS Transformation Group, youll take part in a new wave of transformation, delving into the complexities of designing enterprise systems used every day by 25,000 employees across 19 markets. If you have a proven track record of building products that exceed users expectations, this opportunity may be of interest to you. Responsibilities
  Support design, build, test, and implementation activities for our internal-facing web and mobile applications
 Assist with defining and prioritizing product backlogs and release plans Capture and decompose requirements into clearly articulated specification (user stories) for the development team Analyze requirements for business impact and technical feasibility Ensure test plans are properly developed and provide testing support Collect and utilize qualitative and quantitative data to make value-driven decisions and uphold user experience quality Facilitate alignment of requirements between cross-functional teams and stakeholders (business owners, designers, researchers, engineers, vendors, etc)  Requirements 2-3 years of experience building digital experiences Working knowledge of Agile development methods Familiarity with human-centered design techniques and front-end development processes (Bonus: experience working in a design team, or as a developer) Youre task-oriented and organized, with excellent attention to detail Youre a holistic thinker and consider multiple angles and perspectives You can work collaboratively with stakeholders, users, and multi-disciplinary teams while holding and challenging strong points of view
 "
106,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data scientist
to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements PhD in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Entry Level candidate with relevant experience may apply Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas Good knowledge on data analytics, machine learning, data mining and experiences in solving real-world problems Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus. Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
107,Manufacturing Central Team Data / Label Lead Engineer,Company Undisclosed,"$4,000to$8,000Monthly","Roles & Responsibilities
 Description As a Data Systems and Product Label Lead Engineer in company, you will lead a small team of engineers who support manufacturing of Module and SSD products within the Manufacturing Central Engineering Team.
 You will provide front line support for centralized data systems and product label implementation, preforming tasks and supervising the team simultaneously.
 You will work with Marketing, Planning, Engineering, Management, Production team members, and various support teams throughout company, as well as external subcontractors, customer and suppliers.
 You will support projects that lead to the continuous improvement in the methods and systems your team is responsible for. 
 Engineer Responsibilities Create and maintain the module and SSD Bill of Materials (BOMs), Product Label documentation and Label files used for consumption by various Manufacturing Systems and personnel. Collaboratively work with key material groups for new Product Label material implementation. Support manufacturing with new and modified Product Label deployment. Build and maintain SharePoint sites and web pages owned by the Data/Label team. Create and maintain the description of components in the SAP system including but not limited to: capacitors, resistors,
 
 PCBs, controllers, and registers. Manage and support the component input system used in manufacturing. Create, implement, and approve global attributes used by Manufacturing Execution Systems. Create and modify Engineering Change Notifications (ECNs) for Global changes to manufacturing process flows in the
 
 Manufacturing Execution System and Test software updates. Communicate and coordinate with global teams on updates needed to be proliferated to global manufacturing sites. Troubleshoot global SAP manufacturing system issues. Work cross functionally with other teams to troubleshoot production issues. Work overtime as necessary, including occasional 24/7 on-call emergency support. 
 Supervisor Responsibilities Maintain a safe workplace by identifying and responding to safety concerns and issues. Mentor and develop team members using the Performance Management System. Provide direct real time feedback. Perform employee evaluations (PPAs). Recognize employees for their achievements. Ensure that the team is meeting performance goals and development goals. Develop a strong partnership between the MOD/SSD Data/Label team and the manufacturing site teams. RequirementsQualifications Must be proficient in English, both verbally and written. Excellent time management and organization skills, able to balance multiple tasks in a fast-paced environment. Strong leadership and communication skills. Strong interpersonal, relationship and team building skills. Superb attention to detail and the ability to react quickly under pressure and constant change. Ability to work under minimal supervision and support a global team during non-standard working hours. Strong computer skills related to the management of data. Able to effectively use Microsoft Excel, Word, Outlook and SharePoint. Excellent problem solving skills, able to identify and correct processing errors. Demonstrated ability and desire to develop team members to achieve their fullest potential. 
 Education Bachelors degree in Engineering, Science or Programming 
 Experience Must have previous supervisory experience A minimum of five years of engineering experience Prefer SAP experience MAM experience is a plus"
108,Data Engineer,KNOREX PTE. LTD.,"$3,000to$5,000Monthly","Roles & ResponsibilitiesDescription We have an existing cloud-based, highly scalable, all-in-one advertising platform where Marketers, Media Owners and Agencies can easily create, optimize & publish Dynamic Ads world wide. Product website:
https://xpo.knorex.com/ You will work closely with our cross-country teams located regionally to learn about the business and technical analytics requirements and translate them into production system. Owing to the large data and real-time stream of data, coming up with efficient and pragmatic solutions and algorithms to the challenging problems will be come imperative. You will work with other team members to ensure the timely delivery of the systems and solutions and critically assess and monitor the efficiency and/or effectiveness of the developed solution.
   Key Responsibilities  Develop clever algorithms and pragmatic solutions to our data analytics problems.
 Develop metrics to measure the outcome/impact of your introduced solutions.
 Work with other members to implement and integrate into our existing systems.
 Document and improve the solutions over time.
 Evaluate and identify new technologies for implementation.
 Communicate with our business and technical teams to understand the analytics requirements.
 Respond and follow up to incorporate feedback and draw new insights.
 Prioritize tasks to meet multiple deadlines.  Requirements Good knowledge of algorithms and data structures Experience with ad serving, ad tracking and optimization is a plus Strong in analytics and problem solving technique
 Willingness to learn and able to pick up new technology or new concepts fast;
 Able to work independently as well as in collaborative mode with minimum supervision;
 Work productively even under pressure;
 Possess good work ethic, attitude with good follow-through;
 Excellent communication in written and spoken English.
 Knowledge using Python, Scala, Spark is a plus.   Benefits  Ample opportunities to grow. You get to propose your own ideas and see it through Work with passionate, talented and driven colleagues who get things done ! Opportunity to work cross-country and with variety of projects of different nature Challenging and exciting problems that await you to solve "
109,"Contract Staff (Senior), Application Development Lead, Institutional Banking Tech, T&O (18000190)",DBS BANK LTD.,"$5,000to$10,000Monthly","Roles & ResponsibilitiesJob Purpose  Responsible with the entire development process (technical analysis, design, development, testing and implementation). Team effort coordination, dependencies management. Establish best practices for coding standards and code review process. Key decision maker in frameworks and architecture. Design and implement the analytic data pipeline from storage layer to analytics layer. Work with data analyst to productionize the analytic data mart and optimize the performance. Deploy / configure analytic tools and optimize computing environment for analytic projects
 Automation and productionize analytic data marts, deploy analytic projects to production, deploy data science product via either API or batch job, automate the refresh of machine learning models. Deploy real time models.  Key Accountabilities
  Review activities from time to time and ensure project scheduled and cost is met Lead Technology team on how to implement the business requirements. Leading the Business Analyst and Developer to deliver business requirement. Understand the bank framework and ensure the delivery is follow the framework. Setup cadence and update management on the progress.  Responsibilities
  To evaluate the user requirement with BA and Development team and come out the schedule and feasibility. To have good understanding of the bank systems and where are the data located when needed Manage the project with the approved cost and agree scheduled Establish best practices for coding standards and code review process. Make collaborative decision on system framework design  Requirements Degree in Computing / Computer Science / Engineering preferred. 8+ years of experience, preferably in financial services industry.
 Java development experience, especially with integration and APIs. Experience with ETL, data transformation and analytics use cases. Data engineering skill with open source big data stack Familiarity with deployment and optimization of open source big data analytics stack on distributed environment Compiling, deployment, and configuration of open source data science tools including Python, R, Tensor Flow, and CPU computing Experience with Hadoop ecosystem and tools. Experience with CI/CD tools. Proven experience with agile methodologies (Scrum, Kanban) Excellent interpersonal skills are required to work within the department, across the broader T&O department, with business partners and with vendors. Strong communication skills, able to communicate effectively at all levels, and both internally and externally. Concise and precise. Experience with cloud computing preferred. "
110,"Business Application Analyst (Finance, WMS & Data Management)",THE SUPREME HR ADVISORY PTE. LTD.,"$2,500to$5,000Monthly","Roles & Responsibilities Assist the Group roll-out of ERP and be familiar with all aspect of ERP Financial and WMS modules. Responsible to co-ordinate any software integration and external interface development if needed Monitors process adherence and consults with the process owner and user for issue resolution Supports and work with Vendor and IT Team on enhancements with a continued focus on process improvement to meet business case goals Co-ordinate test processes and configuration assuring quality of any additions, changes or deletions to the system Consults with business stakeholders to identify and document business needs and objectives, current operational procedures, problems, input and output requirements, data scope, usage, formatting and security requirements Provides timely response to end user calls and help tickets assisting in problem resolution Works together with business experts for implementation project and delivers on time for each project phase  Requirements Minimum 7 years of experience working with ERP solutions as Business Applications Analyst for Financial and/or WMS roles with proven experience in unit / integration testing, user acceptance testing, preparation of test scripts, authorization and roles design, end user training and data migration. Minimum 5 years of experience working with cross-functional teams and heavily matrixed multinational organization Diploma in Information Technology or related Any experiences in SAP Hana or Dynamic 365 in Marine industry will be a plus Conversant with programming languages such as .Net, PHP, ABAP, Ms SQL and report writing experiences will be a plus Good understanding of large data set and business intelligence; Detailed, meticulous and strong analytical skills; Independent, self-driven and initiative Team player "
111,Data Analyst,ADECCO PERSONNEL PTE LTD,"$4,000to$6,000Monthly","Roles & ResponsibilitiesThe role is to maximum the power of data with advanced analytics and produce quality analysis, driving
real-time insights for a dynamic business. The potential project scope include data preparation and cleaning, then followed by exploring various multiple advanced analytics methods to improve related KPIs in the service & quality
area, and finish by creating user friendly UIs for the business. The specific tasks may focus on one or two stages of the whole analytic process. The current pipeline includes projects in text analytics, prediction, etc.  Work with business stakeholders to identify business requirements and user cases; Obtain and clean the large-scale dataset; Develop and fine tune analytics models; Challenge internal thinking constantly to ensure the modeling is fitting and robust; Design visualization (e.g. dashboards) and conduct presentations to communicate analytics findings; Development of analytics tools and applications for business users to consume the analytics results; Other analytics related tasks assigned by the managers  Requirements Bachelor
degree in Engineering, IT, Mathematics, Economics, Statistics, Sciences or technical discipline Master degree is a plus 2-3 years of experience in data analytics is highly preferred, i.e. prediction, optimization, segmentation, etc. Strong analytical framework to process complicated issues and solve problems Strong capability of utilizing
industry standard analytics and statistical techniques to aid business decision making, e.g. regression, time series, random forest, etc Expert knowledge of R/Python programming Experience in analytics tools (e.g. SAS / SPSS) and visualization tools (e.g. Qliksense) is a plus; Good command of English Hands-on and able to work independently Ability to adapt and demonstrate
integrity "
112,Fiber Optics Cabling Engineer (Data Centre),OPTIMUM SOLUTIONS (SINGAPORE) PTE LTD,"$3,000to$5,000Monthly","Roles & ResponsibilitiesCompany UEN: 199700895N  Work Location:
Bayfront Ave  Experience
: Minimum 2 years of relevant experience in Cabling
  Job Role:  Facilities Management related tasks, including but not restricted to structured 
network cabling, cable tracing, patching
and rack management in relation to Data Center / ELV operations.  Installation, termination, testing and labeling of all
 cross-connects (copper, coax, fiber) cable.  Moving and installation of cabinets, racks and IT equipment.  Hardware installation including but not restricted: shelves, iPDU, rails, cable management and IT equipment.  Exhibit quality workmanship on all work and maintain colocation space cleanliness.  Liaise with Facilities, Security and Surveillance teams to ensure optimal operation of electricity, HVAC and monitoring environments within Data Centers and ELV rooms.  Data Center Operations (DCO) Equipment configuration & management, including but not restricted to IPKVM, iPDU and DCIM software.  Manage & monitor the physical health of the network & server environments.  Follow established processes used by the team and participated in regular process review and maintain service standards defined in OLA/SLA.  Respond to incidents following the standard incident response procedure & assist with resolution.  Ticket management and queue monitoring (incident, service request & change) for network & system queues.  Perform tasks at the direction of supervisor.  Daily handover to shift personnel, Project support, Timesheet and team documentation.
  
 Requirements-"
113,Data Engineer,COGNIZANT TECHNOLOGY SOLUTIONS ASIA PACIFIC PTE. LTD.,"$3,000to$4,500Monthly","Roles & Responsibilities Working on Big Data, Data Visualizations, Business Analytics or Data Warehousing Presentation with use of advanced analytics via complex mathematical and statistical models Provide clients with actionable insights to drive key business decisions Follow best practice analytics and data management principles Delivering technical business solutions via data or consulting projects with clients  Requirements Minimum Diploma in Computer Science,
IT or equivalent qualifications Less than 1 year of work
experience "
114,"Engineer, Data Centre Operations",KEPPEL DCS3 SERVICES PTE. LTD.,"$2,500to$4,000Monthly","Roles & Responsibilities To support the Facilities (FAC) Team Lead and the FAC Assistant Manager in the management, operation and maintenance of all facilities equipment / services and building management functions To supervise facilities management service vendors and ensure full compliance to the contract scope and expectations To support the Network Operations Centre (NOC) Team Lead and the NOC Assistant Manager in the management, operation and maintenance of all mission critical systems in NOC To attend to clients requests for technical assistance To generate incident reports and escalation To drive projects for continual improvement to existing systems and Standard Operating Procedures  Requirements Degree / Diploma in Mechanical Engineering / Electrical Engineering / Facilities Management or equivalent Minimum 5 years of relevant experience in data centre operations
 Strong analytical and communication skills "
115,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$2,500to$5,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Possess minimum 1 year of relevant work experience Ability to work independently to translate research ideas into programs with efficient coding Basic knowledge on data analytics, machine learning, data mining Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
116,Data Analytics Analyst,COMTEL SOLUTIONS PTE LTD,"$6,500to$9,750Monthly","Roles & Responsibilities Perform full life-cycle of Data Scientist / Analyst activities, including conceptualization, visualization to operationalization Primary focus will be in applying data science to solve business problems; data mining techniques, doing statistical analysis, building high-quality prediction systems, and use deep learning techniques Able to understand and solve the business problem by translating into a data model and building insights into an actionable outcome
 Collaborate with cross-functional teams to identify and prioritize actionable, high-impact insights across a variety of customer servicing areas
 Research, design, implement and validate models / algorithms to analyse diverse sources of data to achieve targeted outcomes
 Carry out customer behaviour analytics and deliver actionable insights in real time; through behaviour segmentation, predictive modelling, lifetime value modelling, churn prevention, statistical simulations and what if scenarios  Requirements Deep and practical understanding on implementing high performance, well-behaved analytics applications with a focus on data ingestion, feature engineering, model selection, training, validating and deployment A deep understanding of statistical and predictive modelling concepts, machine-learning approaches, clustering and classification techniques, and recommendation and optimization algorithms Must have excellent Python, R and software development skills Familiarity with Linux based operating system environments Experience with scripting languages (e.g. Python, R, Julia) for data manipulation and statistical computing tools i.e. Spark Streaming (extraction, cleansing, transformation, smoothing, PMML model execution) Experience in working with large datasets through OLAP tools i.e. Druid Experience manipulating structured and unstructured data sources for analysis i.e. Greenplum, SparkSQL, HBase, S3 by using Notebook technologies such as Jupyter and Zeppelin Working experience in cloud based and open source technology components  Interested applicants are invited to apply by clicking upon the link below or by email to recruit@comtel-solutions.com"
117,"Software Engineer, Data Services",SPIRE GLOBAL SINGAPORE PTE. LTD.,"$8,000to$12,000Monthly","Roles & ResponsibilitiesAt Spire, you'll have the chance to work with unique datasets that only a few companies in the world can provide. Our growing satellite and ground-station network powers a range of impactful applications including weather forecasting and real-time global ship monitoring. Spire gives you the opportunity to work on exciting technical challenges as part of a team of collaborative engineers who are changing the world with data from nanosatellites. We promise you this: you'll never be bored at Spire. You will join a team responsible for the design and maintenance of our ground-side data processing pipeline, from ingesting satellite data all the way through designing and scaling the APIs that our customers depend on for global data insights. We care a lot about the quality and expressiveness of our code. We think TDD is great, and we're working toward Continuous Delivery of code that passes our CI builds. We recognize that professional growth comes from operating at the boundaries of our comfort zones, and we encourage and support each other through code reviews, pair programming, and lots of communication. If this sounds like your cup of tea, we'd love to hear from you! Responsibilities of your role:  Working as part of a small team to design and deploy web applications, services, and data streaming/processing systems Designing and implementing robust and scalable APIs
 Developing and deploying distributed applications on AWS
 Working closely with Product Management to define and enhance customer-facing products and applications
 Helping to lead the design, implementation, and deployment of new applications and features  *At a minimum, you must have at least 2 years of real-world software development (not academic) experience. RequirementsQualifications / Experience:  Have 2+ years of experience programming REST APIs and backend systems in Python
 Are comfortable with full-stack web development tasks, from designing and implementing UIs all the way down through domain modeling, data processing, and database tuning
 Know how to develop in and deploy to POSIX environments
 Enjoy working as part of a team, but can also take on and complete tasks on your own  Strong candidates will also possess skills in one or more of the following areas:
  Writing automated unit and integration tests, ideally in a TDD fashion
 In-depth knowledge of API design principles and best practices, caching strategies, and designing for resiliency and scalability
 Building fault tolerant distributed systems in environments with intermittent and high-latency connectivity
 Working with relational and non relational database theory and practice e.g. PostgresQL, Redis, ORMs, consistent hashing
 Familiarity with tools and techniques in distributed systems and handling large volumes of streaming data: queues, RPCs, serialization, versioning, eventual consistency, exactly/at-most/at-least-once message semantics  Apply for role here
https://spire.com/careers/openings/?gh_jid=900264
"
118,Data Engineer,CHEIL SINGAPORE PTE. LTD.,"$4,000to$9,000Monthly","Roles & Responsibilities Integrate all owned media touch-points data into single view and build data supply structure Utilize big data stacks to build scalable pipeline and monitor data infrastructure Conduct detailed part verification, validation and reliability testing. 

 Develops and maintains data pipelines, code/update Ansible and Phython jobs Test and maintain running of current data pipeline jobs and highly scalable data management system of Ansible playbooks, Pythons jobs, PySpark jobs, Infrastructure on AWS, GoCD build server Integrate new data management technologies and software engineering tools into existing structures Recommend ways to improve data reliability, efficiency and quality Collaborate with data architects, modelers and IT team members on project goals Collaborate with Marketing Planner, and Data analyst to contribute to new use cases Enhance data collection procedures, including applying data cleansing, outlier identification, and missing data techniques that are relevant for building analytic systems  Requirements 4 to 6 years hands-on experience in the data platform and Python development experience. 4 to 6 years experience of successful application of machine learning, data mining, and statistical analysis with demonstrable impact and proven tracks records. Strong data architecture, data modeling, schema design and effective project management skills. Excellent communication skills and proven experience in leading data driven projects from definition through interpretation and execution. Self-starter, capable of experimenting with various tools and developing own code and scripts for data manipulation, experimentation, algorithm implementation, accuracy measurements, etc. Demonstrate understanding and expertise in commonly used machine learning algorithms, feature selection techniques and data modeling processes Experience with large data sets, Spark, Hadoop, Github, Chartio, and data visualization tools a plus. Have a passion for data analysis and delivering data solutions to help others make faster data driven decisions Excel at getting to the root of an issue and building compelling, data driven decks that can be easily understood and acted upon at various levels Written and Spoken proficiency in English necessary "
119,DATA ANALYST,R SYSTEMS (SINGAPORE) PTE LIMITED,"$4,000to$4,500Monthly",Roles & ResponsibilitiesLooking for a candidate who's pretty good in sql and/or excel RequirementsDATA ANALYST EXCEL SQL
120,"VP  /  AVP, Data Scientist, IBG Digital, Institutional Banking Group (180000ZI)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & ResponsibilitiesJob Purpose
 The Lead Data Scientist manages a team of data scientists within IBG Business Analytics to drive value for the business by leveraging machine learning. He will have opportunities to work on various projects that provide data-driven insights that enable enhanced capabilities in the areas of business growth, risk management, productivity etc. Responsibilities  Lead, guide, and manage the team of data scientists Overall accountable for the teams delivery of data science projects that drive value for business Manage and guide a team of experienced data scientists to drive projects and be accountable for the output of the team Partner with business stakeholders to understand needs and identify opportunities to apply data science Frame this opportunity as a data science problem, formulating hypotheses and techniques for experimentation Oversee the process of data exploration & preparation, the conduct of experiments, review of model performance, and presentation of results to business stakeholders for their feedback Lead the presentation of key insights to management with actionable recommendations Manage the team to facilitate deployment of finalised solutions to production environment Oversee the ongoing monitoring of model performance, and the process of model retraining if necessary  Requirements For PhD holders (in computer science, machine learning, statistics, decision science, mathematics or equivalent)  at least 5 years of industry experience developing data science solutions For non PhD holders  at least 8 years of industry experience in data science PhD or advanced degree holder in computer science, machine learning, statistics, decision science, mathematics or equivalent Prior experience managing teams of PhD-level data scientists preferred Excellent advanced analytics skills, with prior industry experience developing machine learning solutions for classification, prediction, forecasting and/or anomaly detection problems Highly proficient in data manipulation Highly proficient in R, Python, Spark Strong expertise in at least one of the following areas (or equivalent): deep learning, NLP, graph mining, anomaly detection, large-scale recommender engines, large-scale optimizations, large-scale multivariate time-series forecasting, causal and statistical reasoning Ability to present analysis in a manner accessible by non-practitioners Good verbal and written communication skills and the ability to interact professionally with business executives Has a can-do attitude Prior experience in banks not required but may be considered "
121,Data Centre Operations Engineer,HCL SINGAPORE PTE. LTD.,"$4,500to$5,000Monthly","Roles & ResponsibilitiesThe Data center hands and feet engineer will Perform day to day activities, users, visitors and subscribers co-ordination. Co-ordinate with visitors visiting the DC for activities Will co-ordinate with respective teams with in a project Will be responsible for handling issues pertaining to operations and production Will be responsible to manage incidents during the shift Will be part of DC hands and feet operation team to work for customer on different DC member sites (Singapore) in the project and performing equipment Installation and Decommission, troubleshooting. Travel to different sites for INC/Planned activities Will be installing and decommissioning equipments, servers racking and stacking in the Datacentre Will be performing DC Cabling, labelling, patching Daily DC server health checks, walkthroughs, reporting, printing, remedy and email queue management Must have DC Cabling and equipment hardware troubleshooting knowledge Should have basic understanding of DC facilities, environment and standards Receiving the material deliveries, maintaining the inventory store room Maintaining visitor records & access logs 24*7 environment, shift rotation Flexibility per team rotation requirement Professional in 24/7 operational team availability 
 RequirementsHands on with DC infrastructure environment Good Experience in DC 24*7 Operation process & procedures DC racking and stacking & structured cabling understanding GOOD to HAVE Any Technical certification DC Certification Technical / Professional Skills Experience working with external Vendors Good communication and interpersonal skills Non-Technical / Soft Skills Excellent team player flexibility in 24*7 environment Maximum availability for operational requirements 
"
122,Bioinformatics Specialist,ENGINE BIOSCIENCES PTE. LTD.,"$60,000to$100,000Annually","Roles & ResponsibilitiesEngine Biosciences is a venture-backed biotechnology company discovering and developing novel therapeutics and precision medicines, utilizing a proprietary platform that integrates massively parallel biological experimentation with data science, machine learning and AI.
 Led by scientific experts from MIT, Harvard, Mayo Clinic and UCSD, and successful drug developers, informaticians, and company builders, Engine is working on multiple programs and therapeutic areas and growing rapidly across US and Asia. The Bioinformatics & Data Scientist will analyze multi-dimensional biological and genomics data, enhance algorithms and develop novel methods for the utilization in Engines analytics platform that combines advanced system biology analytics with genomics data science and machine learning for accelerated drug discovery and biomarker identification. 
The successful candidate will bring hands-on experience in bioinformatics, algorithm development, in-silico drug discovery, data science, machine learning and cloud compute. 

As a Bioinformatics and Data Scientist, you will collaborate globally with Engines teams and external partners in Asia, US and EU. 

  Hands-on industry experience in Next Generation Sequencing (NGS) and multi-dimensional omics data analysis, algorithm development and machine learning in application for drug discovery and biomarker identification. Real time analytics, predictive models, classification, in-silico validation, queries and visualization of high throughput biological data. Strong peer reviewed publication record in bioinformatics, data science and machine learning. Experience in biological interpretation, pathway analysis and disease biology. Amazon Web Services (AWS) experience including DevOps, Security, VPC, EC2, EMR, Docker, SPARK, ElasticSearch, Lambda, Redshift, and Amazon Machine Learning (TensorFlow, MXNet). Experience working across multiple time zones with executive leadership, scientists and engineers.  Requirements Ph.D. in Bioinformatics / Statistical Genetics / Machine Learning / AI, or related field. Experience in bioinformatics, genomics data analysis, algorithm development and machine learning. Experience in cloud based (e.g. AWS) data science. Programming skills in Python, AngularJS, Node.js., Java. R., Matlab, SQL and NoSQL dbs. Agile development methodologies such as SCRUM and Kanban. Strong communication and global collaboration skills. "
123,APAC Lead Data Scientist,UPS ASIA GROUP PTE. LTD.,"$7,482to$9,975Monthly","Roles & ResponsibilitiesSummary The APAC Lead Data Scientist provides leadership in implementation of advanced analytics models and solutions to yield predictive and prescriptive insights from large volumes of structured and unstructured data. 

 He/ She programs, develops, tests, estimates/runs, and validates models to ensure they are predictive and prescriptive and follow best practices. The Lead Data Scientist leads junior team members involved in advanced analytics activities and tasks. He/ She guides and influences department and project teams and facilitates collaboration with stakeholders. He/ She has experience applying models to large scale problems and advanced knowledge and experience with tuning a number of machine learning models. Responsibilities  Engages and collaborates with business leaders across the organization to help assess business needs and define research questions. Develops hypotheses, approaches (i.e., analytic plans and model development process), models, and solutions to solve problems and increases profitability. Provides appropriate direction for selection and implementation of model development processes to answer business problems. Provides overall direction for model KPI expectations, validation, test and re-train of existing models to meet business objectives. Manages the execution of advanced analytics projects based on statistics, machine learning, experimental design and the scientific method principles to derive insights. Evaluates synthesized insights and findings of model results in reports and presentations to prescribe action. Presents to management analytic findings and recommendations for defining problems, proposing business cases and strategies, and gaining support. Implements repeatable solutions through written project documentation, process flowcharts, logs, and commented code to produce datasets that can be used in analytics and/or predictive modeling. Reviews properties of models to correct for over-fitting, lack of convergence, incomplete separation, multicollinearity, heteroscedasticity, etc. Writes code to collect and manipulate data from multiple data sources. Develops strategy to monitor model and system performance/integrity. Supports the analysis and integration of tools and methods to provide desired results from models and requirements. Identifies opportunities and leads the effort to move from predictive to prescriptive analytics to more quickly turn data into results that support evidence-based decisions. Provides consultation to functional partners to support the design of planning systems. Manages team member activities to ensure tasks are completed within established deadlines and to rectify issues and roadblocks. Leads technical documentation in compliance with UPS Software Development Lifecycle to communicate and update project teams and stakeholders. Manages resources and people processes including performance management and career development.  RequirementsSkills and Qualifications  Has an expert level of knowledge in statistical methodology, analyses and tests (e.g. multivariate analysis of variance, factor analysis, multiple and non-linear regression, cluster analysis, structural equation modeling, partial least squares analysis, etc.); 
selects most appropriate methodology to use; guides, coaches and teaches others in running appropriate statistical analyses; develops tools using statistical analyses. Strong people management and development skills. Strong communication skills in both oral and written and ability to interact with senior executive management Strong project management skills, Project Management Office (PMO) or similar training or certification. Education or experience in disciplines associated with data science including advanced analytical techniques, data architecture, machine learning and associated mathematics and statistical capabilities. "
124,Contract - Data Scientist for Business Analytics (BA),INFINEON TECHNOLOGIES ASIA PACIFIC PTE LTD,"$3,500to$5,500Monthly","Roles & ResponsibilitiesIn your new role you will:  Collect, analyze and
interpret qualitative & quantitative data
with statistical theories and methods Prove concepts, prototypes and implementations, mainly pertaining to the
solutions and services in Business Analytics
encompassing: Machine learning; Diagnostic Analytics; Predictive modelling; Macro/Micro econometrics analysis; Social Media Analytics; Web Analytics Apply standard process
Cross Industry Standard Process for Data Mining
(CRISP-DM) Create and review technical design documentations
to ensure accurate development of analytical models Build text analytical models
using different types of sources including but not limited to internal portals and social media platforms Build Performance Metrics & dashboard / storyboard
to present information and insights gathered as part of analysis  RequirementsYou are best equipped for this task if you have:  Bachelor / Master Degree
in any IT-related discipline / Mathematics / Statistics with
at least 1 year
relevant working experience in IT Hands-on working exposure in
data mining and modelling techniques, statistical analysis and
econometric Proficient with
SPSS Modeler
and programming languages such as
Python, R, SQL Deep understanding of
Statistical and Predictive Analytics, as well as
'Text Analytics implementation process
 Highly motivated, structured
and
methodical
with high degree of self-initiative Customer and result orientated
team player, with good
intercultural communication skills
to work in international team  Please apply via
https://www.infineon.com/cms/en/careers/jobsearch/jobsearch/27658-Contract-Data-Scientist-for-Business-Analytics-BA/"
125,Data Engineer,JEWEL PAYMENTECH PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesAs a Data Engineer you will get to work on a wide range of problems using the cutting-edge technologies in Big Data and Data Science. You are required to translate Data science and Machine learning based solutions into scalable code, and to develop innovative solutions to collect/cleanse/store/process data. In case you are very passionate about building high throughput, low latency, fault tolerant software then this position is for you. To be successful in this role, you will need to:  Analyze requirements and deliver solutions that meet requirements. Write code by using best software development practices. Produce code that meets security standards. Estimate timelines and deliver solutions within agreed timeline. Write clear & concise documentation for solutions/code. Contribute ideas within team to build better code. Continuously improve knowledge on new technologies. Excellent in English, both written and spoken.  Requirements Two or more years of relevant work experience. B.Sc., Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.). Knowledge in the use and application of Python to develop complex software. General machine learning techniques and technologies (e.g., Bayesian classifiers, regression techniques, graphical models, working with unbalanced data-sets) as well as applications (e.g., predictive analytics). NoSQL Database Programming/Development. Manipulation of various types of data; data cleaning, filtering, and pre-processing for example with text/images. Knowledge and experience in the use of cloud computing platforms (AWS/Azure/GCP/etc). SQL familiarity and database technologies (e.g., row versus column stores, in-memory DB, DB clustering, HA for DB). Familiarity and experience with Linux environments. Understanding batch (e.g., Apache Hadoop / Map Reduce) and stream processing approaches / frameworks (e.g., Apache Spark).  
 Youre a perfect fit us if you are  A master problem solver, and able to use own initiative to develop suitable solutions. A strong communicator with the ability to convey information to others in a simple and unambiguous way. An innovative, original thinker approach to job responsibilities, methods and processes. An energetic person who can be trusted to get a job done. "
126,Data Engineer,LOVEBONITO SINGAPORE PTE. LTD.,"$5,000to$8,000Monthly","Roles & ResponsibilitiesThe role You will be tasked with the monumental responsibility of shaping Love, Bonito into a more data-driven team by kickstarting the development of our data warehouse. You will be responsible for Love Bonitos data architecture and will spearhead exciting data projects that will be instrumental in driving the performance of the group.  Main responsibilities   Create and maintain optimal data pipeline architecture and warehouse   Design, and prototype data processing pipelines that are used for making product decisions   Build/Improve and deploy data tools for data analysis   Create and expansion of ETL data flows from all data sources i.e. web analytics, e-commerce store, retail POS, ERP etc.   Design, construct, install, test and maintain highly scalable data management systems   Assemble large, complex data sets that meet functional business requirements   Continuously identify, design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability   Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies   Build high-performance catalog algorithms, prototypes, predictive models and proof of concepts   Implement web tracking to provide advanced reports on the customers experience   Integrate new data management technologies and software engineering tools into existing structures   Collaborate closely with other functional stakeholders especially BI, Marketing and Management to support in their data infrastructure needs   Work closely alongside BI team who will be responsible for the visualizaton and building of reports   RequirementsYou should have    A self starter with a strong work ethic and get things done attitude   A genuine curiosity to know how things work and how to make them better   A knack for solving problems in a creative manner   Humility and self confidence in being comfortable with the fact that you will be the wizard who will be building the underlying infrastructure, but ultimately always in a supporting role for all other teams   Focus and a high attention to detail especially in understanding the intricacies of how and why a data pipeline works as it does   Strong project management skills especially with meaty data warehousing projects   Strong relationship management and influencing abilities; ability to build strong relationships and trust with internal and external stakeholders   Strong project management skills and ability to manage and influence other functional peers 
   Experience & Preferred Qualifications   Highly proficient in MySQL/MariaDB   Experience in AWS Redshift   Programming proficiency in at least major language such Python/Java/Scala   3+ years of experience in a Data Engineer role with a degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines.   Experience in building data pipelines using Hadoop, Spark is a big plus   Strong project management and organizational skills   Experience supporting and working with cross-functional teams in a dynamic environment   Able to communicate and collaborate with business stakeholders to understand data requirements and translate them  "
127,Data Analyst,LAZADA SOUTH EAST ASIA PTE. LTD.,"$8,000to$15,000Monthly","Roles & ResponsibilitiesIntroduction to Lazada
 Launched in 2012, Lazada is the number one online shopping and selling destination in Southeast Asia  present in Indonesia, Malaysia, the Philippines, Singapore, Thailand and Vietnam. As the pioneer of the eCommerce ecosystem in Southeast Asia, Lazada helps more than 80,000 local and international sellers as well as 2,500 brands serve the 560 million consumers in the region through its marketplace platform, supported by a wide range of tailored marketing, data, and service solutions. With over 80 million SKUs available, Lazada offers the widest range of products in categories ranging from consumer electronics to household goods, toys, fashion, sports equipment and groceries. Focused on delivering an excellent customer experience, it offers multiple payment methods including cash-on-delivery, comprehensive customer care and hassle-free returns through its own first- and last-mile delivery arm supported by 80+ logistics partners. Lazada Group is majority owned by Alibaba Group Holding Limited (NYSE:BABA).
 
 The Business Intelligence team
supports the Lazada business to drive data led decisions, collecting data from various sources to analyse metrics related to Buyers, Sellers and our Customers. 
 The Role We focus on understanding big data, and act as a bridge between the technical and commercial side of business and uses data to align with strategic goals. If you like a good challenge and love to find new ways of interpreting data then youre a perfect fit. 
 Key tasks and responsibilities  Be the expert in using data to measure and analyse business performance in each our markets and lines of business. Explore business issues/opportunities, uncover insights and/or identify targeted areas for business growth. Partner with management and operational teams to deep dive on core issues and use our data to find answers. Collaborate with various expert teams to rollout effective products/services and to expand data for building richer insights. Lead new data analytics capability rollouts and/or data-led initiatives throughout Lazada Monitor key metrics and alert the business on potential issues. Analyse operational efficiency and build business models to guide decision-making. Design market/business intelligence reports and performance measurement dashboards to share with senior management Daily/Weekly/monthly performance analysis to monitor the performance of business, to locate risk and to discover potential business opportunities. 
 Perform ad-hoc business analysis, to drill down on certain business challenges, providing conclusions and advice based on data analysis. Help summarizing data analysis requirements to conduct data application projects (need communication with data tech team).
  Talent Attributes Across Lazada, we expect our talents to embrace values that enables delivering on our ambitious agenda. We will expect the candidate to be Entrepreneur & Owner Takes initiative, proactively thinks ahead and holds self constantly accountable to drive the end result Prefers to try and fail rather than not to try at all Wants to achieve companys success as if he/she was a founder and owner of the company Puts companys success ahead of own success Customer & Seller Centric Puts customers and sellers first 
Is determined to deliver the best experience for customers and sellers Always looks proactively for areas to improve Innovative & High Standards Sets stretch goals for self and business. Is known for bringing new ideas to the table and always looks at ways to innovate processes or products Will always go for best achievable outcome while taking into account and motivating others Digs deep into content. Understands the relevant details, and how they impact the big picture Drives organization to make structural, impactful improvements Humble & Challenging Challenges ideas, while always showing respect for others Holds other people accountable, while setting the right example Agrees to disagree and then commits whole-heartedly to the decided approach Demonstrates open-minded thinking Communicative & Integrity Communicates clearly and listens effectively Works effectively by keeping their stakeholders informed of necessary information and initiatives Clearly practices honesty and respect to forge an environment built on trust Gives regular, actionable feedback RequirementsQualifications & Skills  Bachelors/Master Degree, preferably in Analytics, statistics, mathematics or business/marketing management
 5 years + working experience in business performance analysis reporting, data analysis, with independent thoughts and insight.
 Experience in business, strategy and/or tech consulting would be an advantage Experience of managing teams and senior stakeholders. Ability to perceive opportunities from mass data Experienced SQL skill, as well as basic analytical tool such as SAS, SPSS etc. Experience in leading cross BU level analysis projects Excellent communication skills and interpersonal skills.
 Results and detail orientated with a strong emphasis on problem solving English is must. Ecommerce experience is a plus "
128,Data Analyst / Scientist,NATIONAL UNIVERSITY OF SINGAPORE,"$6,000to$7,000Monthly","Roles & ResponsibilitiesTo assist the Director with the collection, analysis, visualisation of research and education data and presentation of analytical results for regular and ad-hoc reporting purposes to meet multiple information requirements of the various stakeholders of the university. Duties & Responsibilities  Research, collect, analyse and report on key indicators, for both regular and ad-hoc reporting purposes. Program and develop depositories and system for accessing regular reports by key stakeholders. Develop visualizations and presentations for dissemination of analytical results and derivation of actionable insight. Create detailed reports on data sources, methodology, analytical techniques, analytical results and insights for stakeholders.  Requirements PhD in operations research, applied statistics, data mining or a related quantitative discipline. Strong analytical skills, highly proficient in statistical and predictive modelling concepts, clustering and classification techniques, and optimization algorithms. Experience in query databases from different sources and perform quantitative modelling and statistical analysis. Experience in developing or programming databases. Some understanding of the higher education sector and the needs of related key stakeholders in the university. Ability to work autonomously. At least 5 years of similar experience. "
129,Senior  /  Staff Data Scientist,NCS PTE. LTD.,"$8,000to$11,000Monthly","Roles & Responsibilities Work with customers to identify opportunities where Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) can be applied to data to solve the customer painpoints. Individually or collaborate with other team members to develop AI/ML/AA prototypes/Proof-of-Concept/Proof-of-Value to derive actionable insights from data. Collaborate with the customers and internal stakeholders to architect the overall supporting storage and compute infrastructure to support the deployment of the AI/ML/AA models, applications, and visualisation of the results.

 Collaborate with the relevant project managers to conceptualise, develop project scope, requirements, budget, and timeline for the implementation of the identified AI/ML/AA projects. Implement the AI/ML/AA projects and to ensure that the projects AI/ML/AA objectives are met.  

 Requirements PhD/Masters/Bachelors (with good honours) in Computer Science, Statistics, Applied Mathematics, Operations Research, or related disciplines. Prefer candidates with 5
or more years of working experience, with at least 2 years of Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) experience. Domain experience in public safety, defence, transport, education, and healthcare are highly desired. AI/ML/AA experience in smart city, social media, and procurement are also highly desired.
 Good knowledge of AI/ML/AA models, software, and tools with the ability to conceptualise and architect the key components of AI/ML/AA projects; and to develop prototypes using statistical software packages such as R/SAS/SPSS. Experience working with very large data sets, including statistical analyses, data visualization, data mining, and data cleansing/transformation and machine learning. Experience in solutions using technologies such as Hadoop/Hive/Hbase/NoSQL and developer skills in Python, Perl, and Java are highly desired. "
130,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a data scientist who can contribute on text mining-related projects. Researchers with expertise in the areas of natural language processing, deep learning, machine learning, ontology engineering and/or knowledge-based data analytics are welcome. In particular, we may collaborate with the successful candidate to establish research milestones in integrating text mining with common-sense and/or domain knowledge by constructing, populating and/or engineering ontology (or knowledge base). Responsibilities:  Deliver results: Develop new technologies, improve performance 
Demonstrate long-term vision, while effectively supporting short-term goals  Requirements PhD in computer science or related topics
 Being an excellent team player Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
131,CyberSecurity Big Data Lead Engineer,"JPMORGAN CHASE BANK, N.A.","$7,500to$15,000Monthly","Roles & ResponsibilitiesAs an experienced professional in our Cybersecurity organization, youre equally committed to watching over our data today, as well as finding innovative new ways to protect it in the future. To do that, youll help lead a highly motivated team laser-focused on analyzing, designing, developing and delivering solutions built to stop adversaries and strengthen our operations. Youll use your leadership skills to give guidance, best practice advice and support across all our business and technology groups. Youll take the lead on incident response, risk reviews and vulnerability assessments, identifying threats, all of which ladder up to driving and selecting cost-effective solutions. Youll deploy best practices, new policies, and emerging trends to strengthen our strategic roadmap. Youll keep management, executive directors, managing directors and stakeholders in the loop, as well as managing people and budgets. As part of JPMorgan Chase & Co.s global team of technologists and innovators, your work will have a massive impact, both on us as a company, as well as our clients and our business partners around the world. 
 RequirementsThis role requires a wide variety of strengths and capabilities, including: 
 





 Excellent command of Cybersecurity organization practices, operations risk management processes, principles, architectural requirements, engineering
 threats and vulnerabilities, including incident response methodologies 





 Keen understanding of national and international laws, regulations, policies and ethics related to financial industry cybersecurity 





 Noted cybersecurity expert, keeping technical skills current and participating in multiple forums 





 Expertise in Agile and can work with at least one of the common frameworks 





 Ability to identify network attacks and systemic security issues as they relate to threats and vulnerabilities, with focus on recommendations for enhancements or remediation 
 Your focus will be on:  Focus on the development of tools and technologies that are at the core of the companys capabilities to manage, monitor and hunt for cyber security incidents. Architecture and development of large scale solution (big data) to be used in a very large production environment System, network and application troubleshooting Provide engineering support for cyber security products developed Proven track record of manage a highly technical team of Big Data and Machine Learning experts  
 Skills required:  Strong research, analytical and problem solving skills Independent problem-solving, highly motivated and self-directing Ability to write and debug administrative and reporting tools in some programming languages (Shell/Perl or Python,
 Scala/Java/R, C/C++,
 HTML5, or other experiences acceptable) Comfortable with most aspect of operating system administration such as tweaking, hardening and configuring services A solid understanding of Unix-based operating systems, including paging/swapping, IPC, drivers and filesystem (inode, partitions, etc.) Experience with host and network security (identity/password management, ACLs, file permissions and integrity) Strong interpersonal and communication skills; capable of writing documentation, training users in complex topics, making presentations to
 junior and very senior audience Ability to work under pressure in a fast-paced environment while remaining productive and professional; exercise patience and ability to multi task  
  In addition, skills in the below areas is a major plus that will help the candidate integrate within the team and environment Experience with hadoop ecosystem: Hadoop, Spark, Map/Reduce, Hive/Pig, Impala/Drill, etc. Experience with Data Science:
 MLlib, Scikit, h2o, TensorFlow, Caffe, Singa, etc. Experience with NoSQL stacks: Elasticsearch, MongoDB, etc. Experience with SIEM products: Qradar, Arcsight, Splunk, etc. Experience with messaging and data transport tools: Kafka, NiFi, LogStash, Syslog-ng, rsyslog, etc. Experience with Link Analysis tools and GraphDBs Experience with data visualization tools: Hue, Kibana, Qlikview, Tableau, etc. Knowledge in RIA: HTML5, node.js, bootstrap, angular, extJS, etc.  Your expertise in cyber, combined with your desire to provide innovative security services, will be an asset to our Cybersecurity team. Help deliver high-quality security solutions across all our lines of business around the world by creating, designing, implementing, and maintaining next-level technology. The work youll do is vital, as it will protect over $18 trillion of assets under custody and $393 billion in deposits every day. 
 We strongly encourage all applicants to apply via our careers website where you are able join our Talent Network to receive customized vacancy notifications and ensure that your details are accessible by our global recruiting team - www.jpmorganchase.com/careers. 
 A quick link to this particular job posting can be found in this URL: http://jobs.jpmorganchase.com/ListJobs/ByKeyword/180035474/  Please note that only short-listed candidates will be notified. We thank you for your interest and wish you all the best in your career.  Yours Sincerely, Human Resources JPMorgan"
132,Data Analyst,U3 INFOTECH PTE. LTD.,"$6,500to$9,500Monthly","Roles & Responsibilities Interact with the business to identify, capture and analyze business requirements. Improves business processes as intermediary between Business and IT. Perform data analysis including data mapping, report analysis, interface definitions. Supporting project management  Requirements Experience on with visualization tools (tableau) Experience with data management tools (Ab initio) is required 3+ years of associated work experience in a relevant role Excellent interpersonal communication skills to explain complex technical topics in an easily digestible manner Willingness to work independently and as part of a team Knowledge of banking application. Technical expertise regarding data models, database design development, data mining and segmentation techniques. Strong knowledge and experience with reporting packages/tools (tableau etc.), databases (SQL etc.), Knowledge of statistics or experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.). Adept at queries, report writing and presenting findings. Working knowledge in any analytical tools like Alteryx, Dataiku. "
133,Data Engineer,KRIS INFOTECH PTE. LTD.,"$6,500to$7,500Monthly","Roles & ResponsibilitiesPURPOSE 
 Design, develop, and implement scalable and robust software platform for data ingestion, data streaming, data staging, data transformation, and data operation in near real-time and micro/macro process solution. 
 KEY ACCOUNTABLITIES 
 








Design, develop, and implement end to end data pipelines and integration process. This include: data analysis, data discovery, data profiling, data cleansing, data lien-age, data mapping, ETL,and deployment of the data solution. 








Recommend, develop, and implement ways to improve data reliability, data efficiency, and data quality 








Execute standard data management processby delivering/building metadata, data operation, data development, and etc. 








Prepare test data. Assist in creating and executing the test plan, test casesand test scripts. 








Collaborate with SMEs, Data Architect, Data Modellers, IT team members, Vendors, and other Stakeholders for the project goals, requirements, and technical specifications. BAU Support for any data issues and change request. Documents all data investigation, findings, and resolution
 
 RequirementsQUALIFICATIONS: 
 






Bachelor Degree in IT, Computer Science or Equivalent 






Experience in ETL, Streaming, CDC, AWS, Data Lake, Data Warehouse,and Data Management 
 SKILLS/KNOWLEDGE: 
 Main Key Strengths 






At least 2 to 4 yearsof experience
in Talend and Spark(Scala/Python) 






At least 1 year of experience in AWS (S3, Redshift, Athena, Kinesis,
EMR, EC2) 






Knowledge of AWS architecture, infrastructure, and other Services. 






Minimum 2 years of experience for the
design and development of ETL process
including fine tuning and optimization. 






Hands-on experience inbuilding data lake/big data ecosystem. 






Very good skills and experience in
SQLand other programming language like
Java
including
best approach and practices. 






Experience in handling and processing different types of data
(structured, semi-structured, and unstructured)and source systems AS400 and Relational Database
(SQL Server) 






Experience in Data Governance and Management (metadata, data operation, data development, and etc.)"
134,Data Scientist,NATIONAL UNIVERSITY OF SINGAPORE,"$5,000to$7,500Monthly","Roles & Responsibilities1. Work with Industry Partners in Challenging Business Analytics Projects  Work with BAC industry partners to conduct applied research projects Collaborate with BAC industry partners to collect business requirements, design and develop analytics and optimization solutions Design and develop innovative analytics and optimization models and algorithms to solve the challenging business problems; Publish papers/industry reports and file patents in analytics areas  Requirements Good knowledge in Operations Research and Mathematical Optimization areas, e.g. Mixed Integer Programming (MIP), LP (Linear Programming), NLP (Non-linear Programming), Meta-heuristic search algorithms, etc. Good knowledge in transforming business requirements into mathematical models Good knowledge in manufacturing systems and supply chain planning areas Good knowledge in commercial optimization tools, e.g. IBM Cplex optimization studio, Gurobi, Fico Xpress, etc. Other analytics knowledge is big plus, e.g. machine learning, simulation, visualization, etc. Excellent communication skills Able to confidently deal with different level staffs from top tier MNCs Willing to go the 'extra mile' for BAC industry partners Ability to build rapport Time management and planning skills Able to travel to oversea based on project requirements Minimum university degree holder; Masters and PhDs are welcome to apply "
135,Data Analyst,DUN & BRADSTREET (SINGAPORE) PTE. LTD.,"$2,500to$3,500Monthly","Roles & Responsibilities Provide data analytics planning and strategy that involves data analytics visioning and road mapping, business case development, implementation planning, organizational planning, budget and risk management planning. Gather and document business requirements from business stakeholders, scope the problem and develop business case to transform data into critical information and knowledge that are essential for policy making and streamlining operations. Perform data cleaning, pre-processing and feature engineering that will aid in the process of meaningful analysis. Design dashboards and interactive visualization as tools for data exploration. Present data insights to business users and stakeholders. Work with stakeholders to ensure smooth deployment and adoption of new solution  Requirements Diploma / Degree in Business Analytics, Computer Science, Information Systems or related fields. Proficiency in data visualization tools, such as Qlikview, Tableau or Microstrategy. Competent in SQL to query databases. Possess good communication and presentation skills to explain the findings to business stakeholders. Possess strong reasoning and analytical skills to merge statistical insights with business realities.  
"
136,Data Engineer,DATASPARK PTE. LTD.,"$3,500to$6,000Monthly","Roles & ResponsibilitiesResponsibilities  design and implement scalable and robust software platform for ingesting and transforming telco network
datasets in (near) real-time using a variety of open-source and proprietary Big Data
technologies recommend and implement ways to improve data reliability, efficiency and quality collaborate with product management, sales and marketing, and solution delivery teams to support the objectives that customer requirements are well
managed and reflected in product releases support the deployment of DataSpark software within clients' IT environment working closely with stakeholders to ensure high standards of data governance during implementation serve as technical subject matter expert in latest big data technologies  RequirementsRequirements  7+ years of superior software development experience building commercial large-scale software systems and database systems Excellence in algorithms, data structure, discrete math, data base and data warehousing Expert knowledge in data management technologies and software engineering tools to efficiently process large volume of data Demonstrated
clear and thorough logical and analytical thinking, as well as problem solving skills Experience of data warehouses in excess of 10TB Experience of Web UI, middle tier, and
data back end development Production coding experience in choice of programming languages and development frameworks Proven professional experience in processing large-scale commercial data. Experience with telco data a plus. Superior and proactive communications skills, including verbal, written, and presentation. A proven team player and contributor. Self-directed, ability to work independently and research innovative solutions to business problems Aptitude of working on multiple projects in parallel Attention to details and data accuracy MS or BS degree in Computer Science/Engineering, Statistics, Mathematics, or equivalent is required for this position. "
137,"Associate / AVP, Senior IT Analyst (Big Data)",GIC PRIVATE LIMITED,"$5,000to$10,000Monthly","Roles & ResponsibilitiesThe Technology Department (TD) is a key enabler to keep our business moving forward and is constantly exploiting state-of-the-art information technologies to enhance GICs ability to be the leading global long-term investment firm. We aim to provide users with empowering and transformational capabilities, and to create an inclusive, innovative and integrated work environment. 
 We are looking for a dynamic, self-motivated and technically competent individual who has an interest in data and technology  data architecture, data modelling, data integration etc. Specialising in the Data domain, you will work in a high-pace data engineering team that is delivering and supporting GIC data needs.  Responsibilities 
  Work closely with data analysts, data scientists and business end-users to implement and support data solutions using best-of-breed technology and methodology. Conduct requirement workshop with business users and analyse requirements holistically. Design robust and scalable solutions to meet business needs and takes operational considerations into account. Demonstrate technical expertise in the assigned area. Analyse, tackle and resolve day-to-day operational incidents and advisory to business users Analyse systems operations data (SLAs, customer satisfaction, delivery quality, team efficiency etc.) to identify actionable trends for continual improvements. Play an active role in the project coordinating between internal resources and third parties/vendors for project execution. Provide technical coaching and guidance to juniors  RequirementsRequirements 
  A good degree in Computer Science, Computer Engineering
or equivalent Possess more than 2 years of relevant working experience in data modelling and data integration, preferably in an investment and banking environment. Experience working with enterprise databases using database technologies (PL/SQL, SQL, NoSQL) data integration products (e.g. Informatica) Good knowledge of Linux family of OS  
 Exposure and knowledge in any of the following technologies is advantageous: 
  Big Data  Hadoop Technologies: HDFS, Zookeeper, Yarn, Spark, Hive, Impala, Sqoop, Solr, ELK, Flume, Kafka Hadoop Platforms: Cloudera, Databricks NoSQL Databases: Neo4J Cloud based Big Data Services: AWS EMR, Azure HDInsight Elastic Search    
  Programming/Scripting Language  Python Java/Scala Shell Script RESTful Data API 
    
  Experienced with the Systems Development Life Cycle implementation methodology (SDLC) and/or agile methodologies like Scrum and Kanban. Good team player, with strong analytical skills and enjoy complex problem solving with innovative ideas Strong communication/people skills required to interact with data analysts, business end-users and vendors to design and develop solutions Passion for data and technology CFA equivalent certifications would be an added advantage. Good at working with details and is meticulous for operations  You can apply directly through our recruitment portal
at https://career10.successfactors.com/sfcareer/jobreqcareer?jobId=3621&company=gicprivate&username="
138,"Senior Analyst, IT (Data Analytics)",SCOOT TIGERAIR PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesMain Responsibilities  Understand and gather business requirements to design and develop data models, dashboards, graphs and visualization to meet both end users and reporting needs and facilitate sharing of business intelligence between multiple data sources (structured and unstructured date) using Qliksense and MSSQL Develop and compose functional and design specifications Optimize BI data model and dashboard to ensure BI applications are run at optimum performance
 Promote QlikSense as self-help reporting tool with aim to increase the adoption rate of utilization Recommend and carry out recommendations to improve IT systems capabilities to better delivery of data in a way that will be easily understand by business users to help them in decision making  RequirementsEssential Skills  Candidates must have at least a Bachelor degree in Computer Science or equivalent. A minimum of 4-5 years experience in BI development is essential. Experience in building predictive analytics data model is an added advantage Having solid experience with MS SQL Server to be able to build efficient data models Candidates should possess strong analytical, problem solving, communication, and interpersonal skills Knowledge/Experience in QlikSense Knowledge/Experience Dell Boomi integration preferred  Desirable Traits  Knowledge/ Experience with end users reporting tool Knowledge/Experience with airline industry technology Familiar with predictive analysis and machine learning techniques using relevant tools (eg Hadoop, RStudio, RapidMiner, SAP Business Objects) Good development and analytics skill set. Able to conceptualize and formulate a feasible solution based on loosely-defined and abstract user requirements. Able to work well with all levels of users and peers. Able to be independent. Able to plan and manage timeline Candidate must be a strong team player, proactive, resourceful and self-motivated Candidate who are able to multitask and work under pressure Candidates with a proven track record for high quality standards "
139,High-Performance Data Engineer,NIOMETRICS (PTE.) LTD.,"$5,500to$11,000Monthly","Roles & ResponsibilitiesWHAT WE DO We invite you to be part of our ambitious, close-knit team creating systems for large customers who need to crunch through Tbps of data in real-time. Our approach is relentless performance-oriented software engineering vs. server sprawl in our customers' datacenters. You will use the latest high-end hardware and continuously devise ways to push the envelope of software performance. We build in-house systems if we must. We had to for indexing 1M 60-column rows/s, for aggregating high throughput event streams over hundreds of combinations of dimensions, and for pattern matching 5M patterns at 100Gb/s per 2RU. We use these to solve real customer problems. You will experiment wildly. For example we implemented network monitoring using a GPU, and we tested 4-socket machines with 2T RAM. Our current favorite platform is a 2-socket system with E5-2699v4 CPUs (88 lcores in total), 4x40Gbps NICs and 1T RAM, which we use to process 160Gbps. You will help us build a successful software platform for the long run. We invest a lot in flexibility, such as with our extensible rule engine and declarative aggregation system that empowers our analysts and helps us minimise the C code we have to write for supporting disparate use-cases. We know the devil is in the details. You will improve performance through better memory allocation systems and better data structures, all while ensuring that they are integrated with Address Sanitizer and fully tested using unit tests and end-to-end regression tests. We work end-to-end. You will implement data engineering solutions that are both efficient and secure for handling events from 500 million users, and to extract insight without leaking individual information. We want to show off. To attract the best programmers we plan to showcase our technology. You can be part of our effort to open-source interesting pieces of our technology stack. RequirementsYOUR ROLE AS HIGH-PERFORMANCE DATA ENGINEER As a high-performance data engineer, you will create and maintain tools, mainly in C, for crunching large amounts of data in files or streams.
 You will have to think both big, in terms of overall architecture, and small, in terms of low-level optimisations, to deliver solutions that are reusable, and match the performance of the best hardware.
 Every capability you add directly translates to new offerings made possible. Every percent of performance improvement directly translates to large cost savings. At the same time, the correctness and reliability of your work will be the cornerstone to our customers trust.
 WHAT WE VALUE  Bachelors or Higher Degree in Computer Science or equivalent  Software craftsmanship  Attention to reliability and successful delivery  Experience with large C code bases and high-performance C programming  Familiarity with shared memory data structures and parallel algorithms  Proficiency with Linux system & development tools"
140,Data Scientist,ACCENTURE PTE LTD,"$6,500to$13,000Monthly","Roles & ResponsibilitiesThe digital revolution is changing everything. Its everywhere  transforming how we work and play. Are you reacting to the disruption each day or are you leading the way as a digital disrupter? Accenture Digital is driving these exciting changes and bringing them to life across 40 industries in more than 120 countries. At the forefront of digital, youll create it, own it and make it a reality for clients looking to better serve their connected customers and operate always-on enterprises. Join us and become an integral part of our experienced digital team with the credibility, expertise and insight clients depend on. Accenture Digital offers a comprehensive portfolio of business and technology services across digital marketing, mobility and analytics to help our clients unleash the power of digital to drive growth and create new sources of value. No other company offers the same blend of insight, assets and industry expertise to help companies become digital businesses. Analytics, part of Accenture Digital, help our clients grow their business in entirely new ways. Analytics enables our clients to achieve high performance through insights from data - insights that inform better decisions and strengthen customer relationships. From strategy to execution, Accenture works with organizations to develop analytic capabilities - from accessing and reporting on data to predictive modelling - to outperform the competition. As part of our Analytics practice, you will join a worldwide network of over 13,000 smart and driven colleagues experienced in leading statistical tools, methods and applications. From data to analytics and insights to actions, our forward-thinking managers provide analytically-informed, issue-based insights at scale to help our clients improve outcomes and achieve high performance. JOB DESCRIPTION Your clients eyes probably glaze over when you discuss in detail logistic regression, cluster analysis, neural nets and other segmentation models, but they certainly appreciate your uncanny ability to utilize those to lower their marketing costs and improve marketing effectiveness. Or perhaps they rely on you to provide analytics that stimulate sales, strengthen customer loyalty and generate purchases. If youve earned a reputation for your analytics expertise, Accenture may be the perfect place to take the next step in your career journey.





 YOUR ROLE:
 Data Scientist As a Data Science professional, the individual will help drive sales and solutioning of data science/analytics engagements, manage and/or supervise project delivery, mentor teams, build new capabilities, support/contribute to thought leadership and building new skills.
 The candidate should be able to seamlessly work with Client teams in positioning data science/analytical capabilities and with help of them drive an deliver data science/analytics engagement. The successful candidate should have strong consultative, business and communication skills in addition to quantitative ability. As well as be exposed to the challenges of using statistics in a business setting, such as incomplete data, biased data, large data sets, low signal-to-noise ratios, high variance and multiple objective functions. Requires being creative and resourceful and will utilize traditional statistical methodologies as well as newer techniques from computational statistics and data mining and big data capabilities. RequirementsYOUR EXPERIENCE: Basic Qualifications  Degree in a relevant field like statistics, computer science or applied maths, physics or relevant subjects or 3+ years of experience in computer science, applied mathematics, or other quantitative/computational discipline. Strong background in statistical concepts and calculations 3+ years of experience with real data Innovative and strong analytical and algorithmic problem solvers 3+ years of experience with scripting languages (e.g., Python, Ruby, Perl, Bash) for orchestration and data manipulation 3+ years of experience with statistical computing tools like R, SAS, and SPSS Data engineering experience, including SQL and experience manipulating structured and unstructured data sources for analysis.  SET YOURSELF APART: Preferred Skills  Experience with MapReduce/Hadoop and related technologies (e.g., Pig, Hive, Cascading). Familiarity with Amazon Web Services and Elastic MapReduce a plus. Familiarity with Hadoop based commercial packages (e.g. Cloudera, Hortonworks Experience in text mining/NLP  All of our consulting professionals receive comprehensive training covering business acumen, technical and professional skills development.
 Youll also have opportunities to hone your functional skills and expertise in an area of specialization.
 We offer a variety of formal and informal training programs at every level to help you acquire and build specialized skills faster. Learning takes place both on the job and through formal training conducted online, in the classroom, or in collaboration with teammates. The sheer variety of work we do, and the experience it offers, provide an unbeatable platform from which to build a career. Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law."
141,Research Associate,Company Undisclosed,"$3,400to$5,000Monthly","Roles & ResponsibilitiesData Scientist / Programmer for Regional ATM Modernisation Programme Under the Air Traffic Management Research Institute (ATMRI) (http://atmri.ntu.edu.sg/), Nanyang Technological University, you will be part of Regional ATM Modernisation Programme team to perform programming and data analytics for the ASEAN air routes and ATM operations in the region. Primary Duties or Responsibilities Specifically, you will  Undertake research and development related to Air-space management & Data Analytics. Perform programming support for fast time and real-time simulation tools, doing analytics, and building high quality strategic planning system for future for Air Traffic Management (ATM) eco-system for the region. You will provide expertise on mathematical concepts for the broader applied analytics of flow management and inspire the adoption of advanced analytics and data science across the entire breadth of regional ATM system. Conduct stakeholder meetings to solicit input for development of systems. Interact with senior personnel such as project lead and ATC operations specialist on significant technical matters and coordinate with other specialist teams within programme. Represent the Institute at regional/global ATM platforms, international forum/conferences. Occasional overseas travel may be required.  Requirements Masters degree in a relevant field. At least 3 years experience in any aviation-related fast-time simulation environment. Knowledge of tools like SAAM and AirTop will be an added advantage. Strong programming skills. Experience in
Data Science (knowledge in Aviation / Air Traffic Management Good English writing and communication skills Independent and team player "
142,Lead  /  Senior Data Scientist,Company Undisclosed,"$11,000to$13,500Monthly","Roles & Responsibilities Serve as primary source of data insights supporting internal and external constituencies Analyse and translate data findings into meaningful, actionable insights  including synthesizing relevant insights from different customer touch points and data sources Lead, design and implement quantitative analytical frameworks, including scalable predictive models, customer segmentation and marketing mix optimization that improve business performance and customer engagement Institute and adopt best practices in data science, platforms and approaches. Establish internal organisational standards and benchmarks Work with other teams in Mediacorp to understand business needs, document data and data integration requirements, and resolve conflicting business/data architecture rules. Ensure compliance with internal customer contact governance policies and drive closed-loop measurement through smart data capture. Become an internal authority on Mediacorps data tools and resources. Function as a power user of data analytics to guide other business users. Support ad-hoc business intelligence and other strategic initiatives  Requirements PhD or MS degree in Statistics, Mathematics, Machine Learning, Operations Research, CS, Econometrics or related field. Minimum 5 years hands-on experience in data science. Demonstrated expertise in developing and implementing a full range of analytical techniques to address commercial challenges. Proficiency in at least one statistical analysis tool such as R or Weka. Demonstrated experience with distributed databases and query languages. Proficiency in at least one programming language (preferably Java, C++, Python, or Perl). Must possess exceptional business judgment to identify core business objectives; synthesize and interpret disparate quantitative information, develop meaningful insights and clearly disseminate to key stakeholders Strong project management and time management skills. Able to lead data initiative independently with minimal supervision. Relevant experience in web, video, mobile or adtech domain is a plus. "
143,System Engineer - Data Centre Automation,KLARE SERVICES SINGAPORE PTE. LTD.,"$5,000to$8,000Monthly","Roles & ResponsibilitiesImplementation, monitoring, optimization and support of processes  Manage and coordinate critical preventive maintenance, performance monitoring initiatives, and documentation reviews/updates. Provide 2nd level support  Handle tickets and escalations from the Incident management team and provide support on technology and troubleshooting. Actively participate in global and regional IT projects and initiatives. RequirementsMinimum of 2 years experience in IT Infrastructure Automation and support Experience with using REST API within automation workflows, orchestration, and BPM Strong technical proficiency with in scripting and automation technologies is a must Experience with programming languages such as Powershell, Perl, Automic/UC4, XML, Ruby, Python, JavaScript, and/or Bash IDE based tools such as Eclipse or virtual studio code and using of code and binary repositories (e.g. GiTHub, GiTLab and BitBucket) Hands on experience with Text-file formats for structure data (e.g. JSON and YAML) General skills with administration of server based operating systems such as Redhat Linux Server OS (6.x and 7.x), Windows Server (2012 and 2016) Experience with virtualization technologies related to VMware vSphere ESXi and vCenter"
144,Senior Electrical Engineer (Data Centre),PM ASIA PROJECT SERVICES PTE. LTD.,"$5,500to$8,000Monthly","Roles & ResponsibilitiesOverview:  Lead the Electrical design of large scale, high end industrial facilities.
 Have knowledge and experience in designing Electrical systems for Data Centres, including Medium Voltage, Low Voltage Power Systems, Emergency Power Systems, ELVs (CCTV, Interlocks, Fire Alarm, Power Monitoring System) Work in a multi-disciplinary design office environment for global clients. Display a personal commitment to safety, hold safety as a core value and provide safety leadership in the performance of all work activities Be quality focussed, producing well engineered designs to the highest standards in an ISO9000 Quality System environment  
 Requirements Degree in Electrical Engineering, Chartered Engineer preferred At least 6 years of experience of relevant experience
 Experience within the Data Centre industry is required
 "
145,Data Analyst,FORESENSE PTE. LTD.,"$3,500to$4,500Monthly","Roles & ResponsibilitiesAs a Data Analyst your job will be to partner with the Product, Finance, and Engineering teams, and apply your expertise in quantitative analysis, data mining, and machine learning to create and scale insights. You will create and test hypotheses as well as build models to understand how Acers interact with each other. Additionally, you will be responsible for reporting insights and helping the Business and Engineering teams make decisions based on data as well as solving problems and identifying trends and opportunities. Ultimately, you will inform, influence, support and execute our product decisions and product launches. Responsibilities and Duties:  Work with other technical and business development teams to define and develop new research areas and innovative business applications
 Listen and intelligently probe clients to negotiate useful and feasible analytics projects Clearly explain the intuition behind technology options without relying on jargon  what is possible as opposed to how it is done. Forecasting and setting product team goals. Produce clear graphics and visualizations to explain procedures and communicate results. Lead/contribute to efforts on engaging new customers and developing new business opportunities, including proposal development. Writing reports on some specific areas which he/she has spent the time to study and presenting the findings.  RequirementsAt least Bachelor Degree in Computer science, Applied Physics, Applied Statistics, or other related fields from Singapore Local Universities (National University of Singapore, Nanyang Technological University, Singapore Management University, Singapore University of Technology and Design are preferable).
  Master Python or other equivalent programming languages.
 Experience with machine learning classifiers and models Experience with web analytics and advertising. Excellent pattern recognition and predictive modelling skills. Experience in hard problem solving and researching. Familiar with social website like Facebook, Twitter, Blog and Weibo etc. Strong knowledge of statistics and mathematics. Youre practical and realistic: you can start contributing to a production system and make things better. Youre independent and self-motivated with empathy and a positive attitude. Able to write reports & emails fluently in English and Mandarin. Able to communicate in English and Mandarin. Actively participate in sports. Have knowledge of English football teams and tactics. Some knowledge of Forensic Science/Medical science. Fresh Graduates are welcome to apply. "
146,Data Scientist: Urban-Rural Systems (UR-Scape),ETH SINGAPORE SEC LTD.,"$5,000to$10,000Monthly","Roles & ResponsibilitiesData Scientist: Urban-Rural Systems Future Cities Laboratory, Singapore-ETH Centre The Urban-Rural Systems (URS) research team focuses on the complex patterns of settlement emerging in the hinterlands of many large cities in Southeast Asia, the Indian sub-continent and China. To aid this research, the team has developed an open source interactive application, ur-scape, that allows users to simultaneously visualise several geospatial datasets and reduce the analytical complexity with easy-to-use tools. We are looking for a talented individual to join our multidisciplinary team and contribute to the development of ur-scape. Key responsibilities Main tasks include:  Providing technical expertise related to GIS data processing Compiling, validating and organizing GIS data from maps, databases and other sources Supporting ur-scape users and actively engaging community of users Optimising the process of data import to ur-scape Developing new GIS based tools supporting data import to ur-scape Developing new data related functions in ur-scape in collaboration with software engineers Research new methods to derive indicators from various data sources Create documentation relevant to given topics  RequirementsKey Skills The candidate should have:  A Bachelor degree in in Geographic Information Systems, Computer Sciences, Engineering Technology, or equivalent Knowledge of modern GIS tools and methodology for municipal and utility GIS use cases Excellent oral and written communication skills Experience with SQL databases with PostGIS Experience with ArcPy or NumPy databases Experience in working in an interdisciplinary team  Work location: 1 Create Way, CREATE Tower, Singapore 138602 (NUS University Town) Duration: Contract,full-time position For more information, please contact Chen
 Serene Kaixin at serene.chen@arch.ethz.ch. The Singapore-ETH-Centre is an equal opportunity and family-friendly employer. All candidates will be evaluated on their merits and qualifications, without regards to gender, race, age or religion. About Singapore-ETH Centre The Singapore-ETH Centre was established as a joint initiative between ETH Zurich  the Swiss Federal Institute of Technology in Zurich and Singapores National Research Foundation (NRF), as part of the NRFs CREATE campus. The centre serves as an intellectual hub for research, scholarship, entrepreneurship, postgraduate and postdoctoral training. The centre currently runs two research programmes, the Future Cities Laboratory (FCL), followed by Future Resilient Systems (FRS). It is home to a community of over 100 PhD, postdoctoral and Professorial researchers working on diverse themes related to sustainable cities and resilient infrastructure systems. In the course of their work, researchers actively collaborate with universities, research institutes, industry, and government agencies with the aim of offering practical solutions."
147,Senior Advanced Software Engineer,LAZADA SERVICES SOUTH EAST ASIA PTE. LTD.,"$9,000to$11,000Monthly","Roles & ResponsibilitiesLaunched in 2012, Lazada has grown rapidly to include over 4.900 full-time employees in the region, with eCommerce operations in Indonesia, Malaysia, Philippines, Singapore, Thailand, Vietnam and a sourcing center in Hong Kong that drives cross-border marketplace activities as well as an R&D TechHub in Russia. Revolutionizing the way customers shop in Southeast Asia and perform online transactions across the region, Lazada has reached an online footprint of approximately 6 million unique daily visits to its websites, and the largest Facebook community in Southeast Asia with over 16.5 million fans. Lazada Group owns the biggest and the most efficient technology driven logistics and fulfilment ecosystem in the region  Lazada eLogistics. With 11 own warehouses, 5 sorting centers, 78 last-mile hubs we are ensuring 48 hours delivery of more than 6 million orders every month. Our warehouses cover more than 115 thousands of square miles and it takes less than 2 hours to process every order even during massive sales campaigns. Having our own cross-border operator helps us connect more than 100 million of customers and businesses from all over Asia. Our transportation is driven by our own Lazada Express delivery fleet which, together with more than 80 third-party logistics, guarantees high quality 48 hours delivery. All of that would be impossible without sophisticated IT systeregams, which are being developed and expanded in-house by one of the most experienced and agile tech teams in Southeast Asia! As a Senior Data Engineer in Lazada eLogistics Tech Team, you'll be part of an extremely motivated and experienced group of people. You'll help drive LEL business and be a key contributor. You may also become mentor for other developers and business members in future. Does the real-time challenge of dealing with massive datasets (billions of transactions a day) get you excited? If yes, then we would like to speak with you. Lazada eLogistics is using a mix of cutting edge and proven technologies to build new data products that aim to change the E-Logistics landscape. You will be the tech leader of a data engineering team that primarily focuses on productionalizing data pipelines that drive our most critical applications. The tech lead position is the a critical layer that makes sure projects get done. Your daily duties will be:   Develop real-time data ingestion pipelines and batch data ingestion pipelines for analysis, machine learning, dashboards, alerts and visualizations.   Develop new systems and tools to enable data scientists to consume and analyse data faster and more efficiently.   Convert specs into to working code.   Mentor engineers in the team.   Execute code review.   Work and tune data warehousing and data ingest environments.   Script programs and APIs in Python/Go.   Create, monitor and manage low latency ETL and Data pipelines.   Your future benefits will be:    Class ""A office with the best view on business district of Singapore.   Official employment and relocation coverage.   Medical insurance from the first day.   Comfortable working hours in the office.   Caring and respectful HR team.   Powerful workstations and various software licenses (Mac / Winbook + HD displays to your liking).   Daily snacks, chill-out on Friday and of course high quality coffee.   Personal development system for both specialists and managers.   Choice of hackathons, meetups and other entertainment activities.   Opportunity to become public speaker in technology and take part in industry conferences  for top performers.   Exciting international business travels.   No dress code.   RequirementsRequirements:   Minimum 6 years of data engineering experience.   Knowledge of PostgreSQL.   Great experience building production applications in a heterogeneous environment.   Experience with Multithreaded and Concurrent programming.   Ability to write well-abstracted, reusable code components (TDD / Git / Jenkins / Ansible as plus).   Experience in cloud computing services, relational, and non relational databases for business intelligence and analytics.  "
148,Healthcare Data Insights Analyst,CLEARSTATE (PTE.) LTD.,"$4,000to$5,000Monthly","Roles & ResponsibilitiesEIU Healthcare is the specialist research consulting division of the Economist Intelligence Unit (EIU). We offer specialized healthcare market tracking intelligence complimented by strategic advisory services to help medical device, pharmaceutical, biotechnology, and healthcare service firms understand their current and potential markets, and implement pragmatic and innovative strategies to ultimately tap into new growth opportunities across the globe. At EIU Healthcare, we believe that actionable strategy for our client is built on the basis of market realities, where data insights and its robust analytics drive informed decisions. To this end, we are looking to fill an Associate position who will report to Director of Global Innovative Data Insights Solutions in our Data Insights & Analytics team to conceptualize and operationalize the data insight product development. 
 Key responsibilities are: In the role you would be expected to:  Manage GDPR process, connecting to our panel providers to ensure data transfer and handling on EIU Healthcare is within compliance. Execute the modeling framework, which is conceptualized by Team Director and the Modeling associate Desk research on strategic topics that would translate into drivers in the modeling and database Identify new technical possibilities to proxy hard-to-get-data sources with agreement from the team lead Be responsible for accurate and quality modeling implementation Translate modeling technicality into visualization planning by working with another data analytics associate  RequirementsCandidates profile To succeed in the role you must have:  Dedicated experience in GDPR audit 3-5 year strong experience in both market research and market modeling (both are must) Comprehensive knowledge in Healthcare industries Hold a bachelor degree in Economics, Mathematics or
Life sciences.
 Master degree in Economics or Life sciences is strongly preferred  You will be able to demonstrate:  Willingness to take intellectual challenges Versatility, ability to think both inside and outside of the box Ability to work in a fast paced team structure Passion about healthcare Proactive attitude to solve problems for clients and internal teams "
149,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data scientist
to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements PhD in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Entry Level candidate with relevant experience may apply Ability to work independently to innovate, and develop prototypes to demonstrate the feasibility of research ideas Good knowledge on data analytics, machine learning, data mining and experiences in solving real-world problems Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus. Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
150,Data Scientist,CLARIANT (SINGAPORE) PTE. LTD.,"$5,000to$8,000Monthly","Roles & ResponsibilitiesResponsibilities:  Perform data analysis and creation of non-linear models for predictive analytics to support decisions processes Support of data engineering for the set-up of data structures, data analytics platforms and automated data pre-processing Explorative data analytics using supervised and un-supervised learning algorithms with data from multiple data sources. 
 Transfer the findings and knowledge to production and product development  RequirementsRequirements:  Master in chemistry, physics, mathematics, or computer sciences with experience in data mining, non-linear modelling or machine learning, PhD preferred Strong capability in abstraction and model building to transfer real problems to algorithms Good knowledge in chemical engineering and chemistry Independent work on your own responsibility, highly structured working style Good communication and convincing capabilities "
151,Contract Operations Analyst (Reference Data),HR-PRO RECRUITMENT SERVICES PTE. LTD.,"$3,500to$4,800Monthly","Roles & Responsibilities Maintenance of securities database for the Bank Private Bank division, by activation and amendments 

of various financial instruments on IT platform Ensures efficient and timely request processing Quality control responsibilities within the Reference Data business process Processes customer orders via mailbox and order placement systems Daily interaction with internal and external counterparties/ stakeholders Solution-oriented dealing with customer requirements Responsible for set-up / amendment / enquiry processing and reporting Supports projects and dependencies in the product reference data area Ensures process quality, ongoing process development



  Requirements Diploma / Degree holder 1 to 2 years relevant experience in banking industry Knowledge of financial instruments and understanding of Reference Data processes Enthusiasm and good communication skills Good organization skills and ability to priorities workloads to meet tight deadlines "
152,Data Scientist - Grab Financial,GP NETWORK ASIA PTE. LTD.,"$5,000to$10,000Monthly","Roles & ResponsibilitiesGet to know the Role:  Develop a deep behavioral understanding and intuition of our
passengers and drivers,
especially in the space of how they would violate our policies and game our systems Manage
and
own the
entire
end-to-end
lifecycle of
designing
models, working with
Engineering for implementation, to maintenance and
enforcement Generate multivariate statistical
models to identify
latent factors, preventive and
preemptive
capabilities that the trust framework requires Interface with
business & operation teams to formulate solutions & product changes informed by your findings Work independently or in a team to solve complex problem statements   The day-to-day activities:  Translate these intuitions into actionable,
creative
insights that produces heuristic or classification
models to identify
and take down those who violate our Terms of Services Test and validate these insights via rapid experimentation and deployment  RequirementsThe must haves:  Proficient in RDBMS such as PostgresQL or MySQL; and statistical programming in languages like R, Python, Java, C++ or SAS Experience in ETL, feature selections, modeling, model validation and conducting data analyses using R, SQL, Python or any JVM languages Deep understanding
and implementation experience of predictive modeling algorithms such as logistic regression, neural networks, forward propagation, decision trees and heuristic models, with familiarity dealing with trade offs between model performance and business needs Experience in
interfacing
with
other
teams and departments to deliver impact solutions for organisation Self-motivated, independent learner, and enjoy sharing knowledge with team members Detail-oriented
and efficient time manager in a
dynamic
and
fast-paced
working environment  
 Really nice to haves:  Deep understanding
of the fraud space with hands-on knowledge of fraud, payments and risk, especially on tech products Experience in geospatial databases or graph databases Recent programming experience in a production environment Experience in Scala or PySpark on distributed systems Interest in working with MapReduce technologies (such as Hadoop / Spark) Familiarity with Python Scikit Learn, Panda or Spark ML/Mllib is a plus  
"
153,"SVP, VP business analytics consumer banking",BLUECHIP PLATFORMS ASIA PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesThis client of ours is one of the leading Asian banks and is a market leader in consumer banking, securities brokerage, and treasury and asset management. Currently they are seeking for an experienced Data Scientist to join their consumer banking business. Job Responsibilities This client of ours is one of the leading Asian banks and is a market leader in consumer banking, securities brokerage, and treasury and asset management. Currently they are seeking for an experienced Data Scientist to join their consumer banking business Requirements
 To be successful in this role, you will have a post-graduate degree on a quantitative subject with hands on machine learning or statistical modeling experience. Prior experience of at least 7 years experience solving problems using machine, statistical or data-mining modelling **Apply here** https://www.bluechipcareers-asia.com/jobDetails/3638/svp-vp-business-analytics-consumer-banking For more Banking and Finance Jobs, visit us at https://www.bluechipcareers-asia.com/"
154,Data Scientist,SHOPEE SINGAPORE PRIVATE LIMITED,"$7,400to$14,500Monthly","Roles & ResponsibilitiesResponsibilities:   Develop and enhance data infrastructure using frameworks such as Hadoop, SPARK and Flume Design and build new data models and architects that will provide intuitive analytics Design and build reliable data pipelines that will efficiently move data to our Data Warehouse Design and develop new systems and tools that will enable teams to utilise, understand and process data at faster speeds  
   
 RequirementsRequirements:   Minimum B.S. degree in Computer Science or a related technical field Excellent communication skills with the ability to identify and communicate data driven insights 2+ years of Python development and Unix/linux system experience 2+ years of SQL (Mysql, Mssql, Hive, etc)
experience You must also possess at least 2 of the additional requirements as below 2+ years of working experience in software development/programming in one of Java, C/C++. OS environment: Linux/Unix 2+ years of working experience with distributed databases or distributed systems 2+ years of working experience with dimensional data modelling & schema design in Data Warehouses 2+ years of working experience working on BigData analytics pipelines (Hadoop, Hive, ETL, RDBMS-Hadoop data management tools like Sqoop)  
   
"
155,Data Scientist,PEOPLE ADVANTAGE PTE. LTD.,"$4,500to$5,500Monthly","Roles & ResponsibilitiesJob Responsibilities:   Design analytical solutions to solve various business problems through business engagement Build and deploy machine learning algorithms and data visualisation across the group Partner with other teams and business units to provide data analytics advisory and expertise Cognitive program management o


Engage stakeholders and management to develop uses cases for cognitive initiatives o


Develop CAG Cognition Roadmap o


Project manage and implement cognitive related deployment to various systems  RequirementsJob Requirements:   Degree 
in statistical or computing related fields At least two years data analytics working experience, preferably in banking Strong technical skills in using analytical tools such as R, Python, SAS and SQL Good communication skills, articulate and innovative to engage stakeholders Knowledge of Airline and Customer facing Domain is an added advantage. Strong knowledge on AI and Machine learning Good IT Project management skills  
 
 Interested applicants, please send your profile stating your availability, work experience, current and expected remuneration. 20 Jalan Afifi, Cisco Centre 2, #02-02. (Near to Paya Lebar MRT station) between Monday to Friday 9am to 5pm or contact us at Tel: 6842 8306 / Fax: 6748 7927 For more information about People Advantage, please visit: www.certissecurity.com/peopleadvantage/ (People Advantage is a member of Certis CISCO group) 
 Employment Agency License No.: 11C3955 EA Registration No.: R1543877 
 We wish you all the best in your job search! 
 Please feel free to recommend this position to your contact(s) or friend(s) or relative(s) who may be interested in the above position. 
"
156,Software Engineer(Enterprise data / APIs / UIs / Ontology / Semantic),THE SUPREME HR ADVISORY PTE. LTD.,"$3,000to$5,000Monthly","Roles & Responsibilities Attractive salary packages  Company Bonuses, Benefits & Privileges  Career Progression Opportunities


Interested applicants can send your resume to supreme.cathrynteng@gmail.com and allow our Consultants to match you with our Clients. No Charges will be incurred by Candidates for any service rendered.


Role:

Participate in the development/ implementation of high quality, innovative and sustainable software over the full life cycle of Linking Enterprise Data: From Extraction, Storage/Querying, Authoring,
Interlinking/Fusing, Classification/Enrichment, Quality Analysis, Evolution/Repair to Exploration/Search/Analytics.
Integrate all elements (including UIs, APIs, ontology, and semantic database).
Solve interesting and challenging problems alongside a great team of engineers.
In addition, analysis of user requirements, design, development, test, documentation ofexisting tools, software libraries, develop general user documentation, UI testing and integration ofsoftware solutions are required.



Requirement:

Minimum ITE / Diploma / equivalent
Candidate must possess at least Bachelor's Degree/Post Graduate Diploma/Professional Degree in
Engineering (Computer/Telecommunication), Engineering (Electrical/Electronic) or equivalent.
Candidate should be able to work independently with an ability to multitask.
An effective communicator with excellent interpersonal skills.
Preferably Senior Executive specialized in Engineering - Electronics/Communication or equivalent.
Prefer someone are able to work independently,experience with hand on



Please include the following in your Resume Document * (*.DOC/PDF - Files should not exceed 2MB) 

  Name 

  Contact No. 

  Nationality/PR Status 

  Location/Address 

  Recent Photo 

  Expected Salary Requirements Attractive salary packages  Company Bonuses, Benefits & Privileges  Career Progression Opportunities


Interested applicants can send your resume to supreme.cathrynteng@gmail.com and allow our Consultants to match you with our Clients. No Charges will be incurred by Candidates for any service rendered.


Role:

Participate in the development/ implementation of high quality, innovative and sustainable software over the full life cycle of Linking Enterprise Data: From Extraction, Storage/Querying, Authoring,
Interlinking/Fusing, Classification/Enrichment, Quality Analysis, Evolution/Repair to Exploration/Search/Analytics.
Integrate all elements (including UIs, APIs, ontology, and semantic database).
Solve interesting and challenging problems alongside a great team of engineers.
In addition, analysis of user requirements, design, development, test, documentation ofexisting tools, software libraries, develop general user documentation, UI testing and integration ofsoftware solutions are required.



Requirement:

Minimum ITE / Diploma / equivalent
Candidate must possess at least Bachelor's Degree/Post Graduate Diploma/Professional Degree in
Engineering (Computer/Telecommunication), Engineering (Electrical/Electronic) or equivalent.
Candidate should be able to work independently with an ability to multitask.
An effective communicator with excellent interpersonal skills.
Preferably Senior Executive specialized in Engineering - Electronics/Communication or equivalent.
Prefer someone are able to work independently,experience with hand on



Please include the following in your Resume Document * (*.DOC/PDF - Files should not exceed 2MB) 

  Name 

  Contact No. 

  Nationality/PR Status 

  Location/Address 

  Recent Photo 

  Expected Salary"
157,Pricing and Data Analyst,Company Undisclosed,Salary undisclosed,"Roles & ResponsibilitiesPricing & Data Analyst  Use machine-learning techniques in regression, clustering, and classification to solve insurance pricing problems. Develop algorithms and predictive models using large amounts of structured and unstructured data Support initiatives on claims analytics, data visualization, automation and telematics insurance data analysis Conduct data analysis for pricing of new and existing products for local entities  Requirements Bachelor Degree in statistics, computer science or equivalent 2+ years of relevant quantitative & qualitative analytics experience in non-life insurance industry. Strong aptitude towards math's, statistics and programming with inquisitive mindset Ability to work independently and self-motivated Experience in large data set management, scrubbing and analysis using statistical and scientific computing tools such as R and Python "
158,"VP / AVP, DevOps Engineer, Group Consumer Banking and Big Data Analytics Technology, T&O (180002KI)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & ResponsibilitiesAre you an ascending DevOps engineer seeking the summit of software development and deployment? Then consider joining C2E Big Data & analytics team. DBS setting up from the ground up a Data Platform that will support all the data-driven activities within DBS. 
As part of this work the bank is looking to recruit DevOps engineers. In this role, youll work collaboratively with software engineering to deploy and operate our systems. Help automate and streamline our operations and processes. Build and maintain tools for deployment, monitoring and operations. And troubleshoot and resolve issues in our development, test and production environments. Requirements A Bachelors degree in Computer Science. Strong knowledge and experience in Devops automation, containerisation and orchestration using tools such as Ansible, Docker, Jenkins, SonarQube, Kubernetes etc. Come from a development background wherein you have 4 to 5 years of development and delivery experience with Java, Python, or Go. Extremely strong hands on experience with highly scalable distributed systems. Experience with microservices and container based application architectures. 4 to 5 years of hands on experience in architecting and building platforms for CI/CD release automation platforms. Expert in Automation/ Configuration using tools like Puppet/ Chef/ Ansible/BOSH, etc. Strong knowledge and experience of the available services across major cloud providers such as AWS, Azure, Google. Deep understanding of instrumentation around code, testing and process metrics of the development pipeline Hands on in depth experience in some of the following technologies: 	 Jenkins/Maven/Git/SonarQube/Fortify/Confluence/Jira/Artifactory Cloud Foundry, or other PaaS technologies. Public clouds such as AWS, Google Cloud or Azure. Docker, Kubernetes.   Strong understanding of virtualization and networking. Strong understanding of Linux. Familiarity with Hadoop distributions and ecosystem, and NoSQL databases (e.g. HBase, etc.). Experience working with, or an interest in Agile Methodologies, such as Extreme Programming (XP) and Scrum Knowledge of software best practices, like Test-Driven Development (TDD). "
159,Data Scientist,MEDIACORP PTE. LTD.,"$8,000to$11,000Monthly","Roles & Responsibilities Serve as primary source of data insights supporting internal and external constituencies Analyse and translate data findings into meaningful, actionable insights  including synthesizing relevant insights from different customer touch points and data sources Lead, design and implement quantitative analytical frameworks, including scalable predictive models, customer segmentation and marketing mix optimization that improve business performance and customer engagement Institute and adopt best practices in data science, platforms and approaches. Establish internal organisational standards and benchmarks Work with other teams in Mediacorp to understand business needs, document data and data integration requirements, and resolve conflicting business/data architecture rules. Ensure compliance with internal customer contact governance policies and drive closed-loop measurement through smart data capture. Become an internal authority on Mediacorps data tools and resources. Function as a power user of data analytics to guide other business users. Support ad-hoc business intelligence and other strategic initiatives  Requirements PhD or MS degree in Statistics, Mathematics, Machine Learning, Operations Research, CS, Econometrics or related field. Minimum 5 years hands-on experience in data science. Demonstrated expertise in developing and implementing a full range of analytical techniques to address commercial challenges. Proficiency in at least one statistical analysis tool such as R or Weka. Demonstrated experience with distributed databases and query languages. Proficiency in at least one programming language (preferably Java, C++, Python, or Perl). Must possess exceptional business judgment to identify core business objectives; synthesize and interpret disparate quantitative information, develop meaningful insights and clearly disseminate to key stakeholders Strong project management and time management skills. Able to lead data initiative independently with minimal supervision. Relevant experience in web, video, mobile or adtech domain is a plus. "
160,Data Engineer / Senior Data Engineer,SINGAPORE POWER LIMITED,"$4,000to$8,000Monthly","Roles & ResponsibilitiesWhy Work for Us We Power the Nation. Make the most of your talents and develop products that can create impact on a national scale. We are an in-house software team, assembled to move with speed and deliver with quality. 
 We Build Reliable Solutions. For Customers, Company and Country. You will be part of the Digital Technology Team and together, you will innovate, create, and deploy digital products that will empower more than 3,800 employees within SP Group and improve the quality of life for the 1.5 million commercial, industrial and residential customers that SP Group serves. We build solutions that enable sustainable high quality lifestyles and help consumers save energy and cost, as well as supporting national goals for a sustainable livable city. Now, imagine the impact you can create. 
 SP Digital Technology aims to use cutting edge technologies to help SP Group to revolutionize future utility/energy industry by providing better services and more efficient energy solutions to our customers. Data charter consists of data engineering, business intelligence, data science/machine learning teams. We oversee and drive all data and AI initiatives for SP group. It includes the following  Build next generation data infrastructure to collect/process/analyze different data from consumers, assets, energy.  Discover the business problems/opportunities and design data-driven solutions to improve operation/business/customer experience.  Uncover the actionable insights for multiple stakeholders to drive business growth 
 The mission of the data team is to drive SP to become data-driven company and create data-driven products. As a data team member, you will be responsible for designing, developing and deploying data-driven solutions to create business value. We are looking for data engineers/senior data engineers to join the team. You will work together with data scientists, machine learning engineers to build data ingestion pipelines, design data-driven applications to deploy the machine learning models into production environment. 
 What You'll Do  Selecting and integrating any Big Data tools and frameworks required to provide requested
 Implementing ETL process Research opportunities for data acquisition and new uses for existing data Develop data set processes for data modelling, mining and production Recommend ways to improve data reliability, efficiency and quality Collaborate with data architects, modellers and IT team members on project goals   
 RequirementsWhat You'll Need We are looking for Passion and Proficiency  Good analytical skill with solid software engineering background Experience with both Java and Python Experience working with Hadoop cluster Experience with integration of data from multiple data sources Experience with various messaging systems, such as Kafka "
161,Data Science Training Program Associate,SEAGATE SINGAPORE INTERNATIONAL HEADQUARTERS PTE. LTD.,"$3,500to$4,900Monthly","Roles & ResponsibilitiesThe Analytics Business Solutions team from Operations & Technology Advanced Analytics Group is seeking talented program associate to manage a high profile initiative, helping to design, develop and administer an internal citizen data scientist training program to up skill the data science and analytics skills of Seagate employees across the company. 
The candidate will have opportunities to work with different functional groups across the companies in different regions. Candidates should be passionate about the design, implementation and administration of adult learning, educational and technical training programs. This position will report to the Managing Principal Engineer in the United States. About the Role   Design, implement, execute, administer and maintain training programs   Coordinate with cross-functional teams to execute on deliverables   Monitor and respond to queries on message board; follow up with emails from learners   Create and distribute communication materials to employees and other stakeholders   Create, lead and manage community blog & message board   Coordinate training logistics   Complete ad-hoc projects and assignments, as required   Gather metrics, create and disseminate reports, as required   Will be required to take conference calls outside of regular office hours to communicate with the stakeholders at other regions   Travel: Up to 30%. Include international travels. RequirementsYour Experience Includes:   Demonstrated
program management and problem-solving skills   Effective organizational and time management skills   Knowledge of adult learning and instructional design principles   Demonstrated customer focus, including proactively finds ways to exceed customer needs   Demonstrated discretion, good judgment and professional work ethics   Excellent verbal and written communication skills   Bachelor's degree and/or relevant experience   
 Preferred Qualifications:   Experience running multifaceted training programs   Administrative experience providing training, development and administration support in a corporate environment   Experience using learning & development tools such as Captivate, Camtasia, Linkedin Learning & Brainshark   Instructional design experience is a plus   
"
162,Data Scientist,TONGDUN INTERNATIONAL PTE. LTD.,"$4,000to$6,000Monthly","Roles & ResponsibilitiesResponsibilities:  Work closely with the Sales/business development team to gain an understanding of customer requirements and propose relevant solution to solve the business challenge  Working closely with Solutions team in guiding the product roadmap towards clients risk management & anti-fraud needs.  Deliver workshops to current and prospective customers on the range of solutions.  Deliver product demonstrations/POC as well as conduct workshops on all solutions  Completing RFIs / RFPs to excellent standard.  Work closely with sales by participating in road shows, conferences and industry held seminars.  Provide subject matter expertise to internal as well as external customers.   
 RequirementsSkills:-  Excellent communication skills with the ability to build rapport both internally & externally.  Strong technical understanding/background.  Previous experience of 4-8 years in Pre-Sales or Implementation in a similar industry.  Knowledge in Python/ R / SAS programming language is a must.
  Expertise in several of the following areas of Credit Risk, Anti-fraud and cybersecurity(desired).  Knowledge of the local regulatory requirements.  Financial software knowledge would be highly beneficial.  Fluency in English is highly desirable  Able to communicate with Chinese clients  Enjoys working in a fast paced environment.  A team player with ""can-do"" attitude.  Extensive travel to Asean countries is required. Bachelor or above in Finance, Computing, Economics, Statistics, Mathematics, or equivalent."
163,AI DATA ENGINEER,AMARIS.AI PTE. LTD.,"$5,000to$10,000Monthly","Roles & ResponsibilitiesWe are looking for an AI
Data Engineer to implement
and maintain
the information architecture for the big data business based on the end-to-end vision of the data architect. The AI Data Engineer should be experienced in full stack web development. The AI
Data Engineer will execute
master data management policies developed by the data architect and perform
the data quality evaluations.
 He/She is required to work
closely with business representatives to improve
the
quality of data to the required levels. If you are an experienced software engineer with a passion for designing and delivering big data solutions using cutting edge technologies, this is your opportunity.
 Requirements  Responsible for the integration of large, structured and unstructured data volumes into the cloud platforms   Development of scalable end-to-end data pipelines for batch and stream processing   Execution of the datalake integration workflow and activities for populating the data lake and integrating diverse data sources   Execution an further development of the physical implementation of the logical data model into a physical implementation in the data lake   Implementation of solutions for reference data and master data management within the context of the mobility data business   Execution of data quality measurements and implementation of data quality improvement activities to the required levels of data quality   Support of build-up and maintenance of a data directory for all data relevant to the mobility data business   Representation of the Data Architecture team in selected data architecture, data modeling, and metadata management work teams inside Mobility  "
164,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a capable and responsible scientist to work on and make contributions to big data analytics in particular for various applications in healthcare and advanced manufacturing and engineering (AME) domains. Successful candidates will be involved in the execution of both industry projects and research projects. In addition, the candidate is also required to participate in the drafting of grant proposals and project scoping with industrial partners and/or public sector entities. Not confined to that of healthcare and AME, the candidate will be given opportunities to participate in projects bringing innovation to various economic sectors, including that of the financial service industry entities. Requirements PhD in computer science, computer engineering, mathematics and statisitcs, data science intensive programs with expertise in one or more of the following areas: Data mining, data management, machine learning etc Minimum 2 years of relavant experience Ability to work independently to innovate and develop prototypes to demonstrate the feasibility of research ideas Good knowledge on data analytics/machine learning/ data mining and experiences in solving real-world data science problems Proficient in Python, R, Matlab, C++ or Java Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills Prior experience with time-series forecasting is a big plus Prior experience with healthcare and
AME industry is a plus  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
165,Scientist (Data Analytics /  Deep Learning)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a Scientist who is highly motivated with a passion for machine learning, statistical modeling, and data visualization technologies to join our research team. Successful candidate is expected to contribute positively to the growth of the data science field, work effectively in a team environment, and maintain high productivity and work quality. In this role, successful candidate will interact with a team of experts in machine learning, deep learning, database management and distributed system teams, and work on all aspects of the design, development, and delivery of machine learning solutions. This may include, but is not limited to, the following:  Developing, enhancing, automating and managing analytics model Creating visualizations to unveils insight faster and effectively Develop practical data-driven solutions Perform data cleanup, normalization and transformation and examine data from multiple diverse data sources Process optimization design based on historical data Ensure the integrity and security of institutional data  Requirements PhD in Computer Science, Mathematics and/or statistics degree, electrical engineering, physics, civil engineering, chemical, biochemical engineering, with experience in data analytics Possess minimum 1 year of relevant experience Expertise in problem formulation and solving Experience working in a field related to statistics or data mining Experience performing data manipulation and pattern analysis Experience in applying machine learning algorithms Proficient in multiple programming languages with particular emphasis on Python, R, Matlab, Java and SQL Experience in working in a cross-functional team environment with multifunctional stakeholders Excellent written and verbal communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
166,Senior Consultant  /  Consultant  Technology - Data Engineer (Future Of Mobility)  2 Years Contract,DELOITTE CONSULTING PTE. LTD.,"$6,000to$12,000Monthly","Roles & ResponsibilitiesWhat impact will you make?  At Deloitte, we offer a unique and exceptional career experience to inspire and empower talents like you to make an impact that matters for our clients, people and society. Whatever your aspirations, Deloitte offers you unrivalled opportunities to realise your full potential. We are always looking for people with the relentless energy to push themselves further, and to find new avenues and unique ways to reach our shared goals.  So what are you waiting for? Join the winning team now.   Work youll do 
 Were looking for an experienced data engineer who will work closely with data scientist & software developers to take projects from initial data mining and research through all stages of prototyping, development, large scale deployment  Plan, build, & manage analytics solutions Streamline data access and security to enable data scientists to easily access to data in required form Build out scalable and reliable ETL pipelines and processes to ingest data from a large number and variety of data sources Data crawling from various public data sources Data cleaning & preparation based on data scientist requirements Explorative data analysis  
 
 Your role as a leader
  At Deloitte, we believe in the importance of empowering our people to be leaders at all levels. We expect our people to embrace and live our purpose and shared values, challenging themselves everyday to identify issues that are most important to our clients, our people and the communities, and to make an impact that matters. In addition to living our purpose, Senior Consultants / Consultants across our Firm are expected to:
  Understand the objectives and expectations set and demonstrates personal accountability for keeping own performance on track. Develop themselves by actively seeking opportunities for growth, demonstrating commitment to personal learning and development Seek opportunities to challenge themselves, collaborate with others to deliver and takes accountability for results Build relationships and communicates effectively in order to positively influence peers and stakeholders
  RequirementsRequirements:  Bachelor or above on computer science, electrical computer engineering, information technology or related area 4-6 years hands on experience performing quantitative analysis on large-scale datasets Experience with ETL, Data Modeling, Data integration and working with large-scale data-sets. Extremely proficient in writing efficient SQL on and working with large data volumes. Experience with at least one scripting language, i.e. Python, C#, Java etc.. Knowledge on data mining & machine learning is a plus Ability to effectively function in a fast-paced environment with shifting priorities and simultaneous projects Strong interpersonal, written, and verbal communication skills PMO experience a plus  
 Positions may be based in
Singapore
but project locations could be anywhere in the Asia-Pacific Region.  Due to volume of applications, we regret only shortlisted candidates will be notified."
167,Data Analyst @ Singapore,Company Undisclosed,"$3,000to$3,500Monthly","Roles & ResponsibilitiesActivities to be performed -









Collects, maintains and manages the airlines operational data for P&W/IAE engines -









Update P&W databases with engine operational data received from operators -









Assistance to Field Service Representatives in administrative and technical activities 
 RequirementsMandatory requirement (must) -









Degree in Aeronautical Engineering -









Knowledge of P&W products/gas turbine engines -









Only Singapore nationals Or PR"
168,Data Analyst,PHD SINGAPORE PTE. LTD.,"$3,500to$6,500Monthly","Roles & ResponsibilitiesScope of role:  This community is tasked with creating a recognized market-leading position in trading and media-owner relations.  
  As the Analyst you will play a critical role in attaining this ambition across all of our clients. You will be supporting the Managers in all aspects of campaign implementation, optimization, reporting, data analysis and cost management.  
  Reporting Structure:  You report directly to the Planner / Trader  

  The role encompasses:  Supporting the Planner/Buyer and Manager by developing expertise in all aspects of Campaign Management including:   Management of campaign implementation and reporting process (including creative trafficking, tagging, campaign optimisation, pulling reports from software providers utilized, commencement and post analysis document preparation, BCC entries, timesheet management, and other tasks that may be required as directed by your Manager). Assisting the Manager or Planner/Buyer to grow usage of the resource across the client base. Knowledge of all key media owners and clients (Becoming familiar with all key publisher reps and all key client contacts). Becoming familiar with the Media Landscape and keeping up to speed with industry news and trends as they evolve.  Key Responsibilities:



   Stewardship of the process   Assisting your manager with the following processes:   Pre-campaign, On Booking, Campaign Commencement, During campaign and post-campaign reporting   During Campaign and Post-campaign   Ensure campaign is delivering on time and on budget Optimization of campaign  check with manager before implementing   Where appropriate present work to clients
   Present relevant documentation, where required, with full rationale for results. Attend media presentations (where required) and respond to issues raised therein.
 Maintain regular dialogue on campaign performance and market opportunities to ensure continual management of providing the best results for the brand, with clients and keep Manager informed.   Media Champion   Build strong relationships with your respective area direct teams, solutions and wider agency teams. Review media proposals to gain a better understanding of the digital landscape an opportunities. Provide on-going updates/changes to the rest of the team. Monitor industry press and newspaper articles relating to your area and feed back into the group. Become familiar with media reps and publisher inventory. Attend all relevant media training sessions and be able to apply the principles taught with sound execution.   Protecting our high standards   Ensure that any work that leaves the agency is of the highest standard Be part of producing ideas that inspire, motivate, engage and create commercial action Be part of producing award winning work Always challenge mediocrity (if you dont know what this means, ask your CEO)  5.
 Integration   Think like a solutions provider Ensure you encourage the use of other agency services  Note  other tasks may be assigned to you.
 These will be advised at a later date and recorded on your job spec.  
  
 RequirementsPerformance Measurement:  1. Specific Skills Related To Job Role   Demonstrate an appropriate level of technical competence and ability, particularly in the key areas of the role, but also working towards a greater understanding of other disciplines (e.g. advertising research, direct, PR). Ability to implement campaigns across all media. Full working knowledge of Excel, Word, Powerpoint (as appropriate). Full understanding of research tools both industry and in-house Have a good appreciation of the workings of our specialisms Have a general understanding of the areas of communication outside traditional media  Sponsorship, Direct, Mobile, PR etc. Achieve and maintain a suitable level of autonomy, requiring minimum intervention on a day-to-day basis. Be informed and able to discuss media trends and current industry issues. Established presentation and writing skills. Ability to use digital planning and ad serving tools
  
  2. Business Style   Always represent the company in a positive and professional manner, both internally and externally. Demonstrate energy, enthusiasm and consideration for others. Over and above the specifics of the job description, push for responsibility, self-improvement and the opportunity to contribute to the company. Take responsibility and ownership of your work. Maintain a smart appearance and a positive attitude. Get to meetings on time.   Communication Skills   Communicate with and update your Manager on a regular basis. Communicate with and update your client when required by your manager. Develop interface with colleagues in all departments both media and beyond.
 Should have formed strong relationships with buying and account teams at an appropriate level of seniority. Be an effective presenter. Have well-developed written and verbal skills. Be 100% accurate. Be aware of own progress and self-development.   Organisation & Productivity   Manage own time and workload effectively. Take full responsibility for administration  WIP documents, status reports, contact reports, minutes and agendas. Be accountable for productivity and meeting deadlines.
 Initiate actions from internal meetings. Be able to present WIP document within the team.  
   Developing & Maintaining Relationships   Have client contact when directed by your manager. Should have strong relationships with the wider team on the business they work on.
 In addition they should be familiar with members of other disciplines. Internally, manage upward as well as downward within the company.  
   Analytical Judgment   Demonstrate a significant level of initiative and resourcefulness. Reappraise what has been asked for, thinking creatively and innovatively. Have an understanding of any tracking or Econometric data used by clients. Draw insights, from research or information generated, thats useful to your manager in the development of planning. Be able to analyse campaign reports and actively suggest optimisation recommendations for your manager to review.  Personal Attributes:  A Can Do attitude Tenacious Business savvy Entrepreneurial Persuasive Leadership qualities Great interpersonal and communication skills internally, with media owners and clients
 "
169,Data Scientist,RIDIK SOFTWARE SOLUTIONS PTE. LTD.,"$7,000to$9,000Monthly","Roles & ResponsibilitiesExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets o Experience working with and creating data architectures o Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks o Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications o Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting o Knowledge and experience in Decision Trees, Text mining, social network analysis, etc. o Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. o Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. 
o Clear understanding of concepts and principles in Visualization and Dash-boarding o Good understanding of Semantic Models in QLIKVIEW, TABLEAU and best practices of Visualization design General skills o Should have 8  12 years of experience manipulating data sets and building statistical models 
o Should have a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools: 
o Experience creating and using advanced machine learning algorithms and statistics: regression 
o Experience creating user stories or defining business use cases for applying data science o Should have excellent communicational skills, both written and verbal and capable of smoothly interfacing with the customers 
 RequirementsShould have 8  12 years of experience manipulating data sets and building statistical models 
o Should have a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools: 
o Experience creating and using advanced machine learning algorithms and statistics: regression 
o Experience creating user stories or defining business use cases for applying data science o Should have excellent communicational skills, both written and verbal and capable of smoothly interfacing with the customers"
170,Global CDS Operations OneTouch Data Analyst,BCD TRAVEL ASIA PACIFIC PTE. LTD.,"$2,500to$3,000Monthly","Roles & ResponsibilitiesWhere will
YOUR
career take you?
 
 
 
 
 Were not just a travel company. We help clients

travel smart
and

achieve more. The department Global Client Data Solutions delivers Business Intelligence through the collection of our customers travel data globally and provides this to our consolidated & local customers in a meaningful end product. The information we provide supports our customer in general making decisions in their travel policies as it relates to compliance, spend management and negotiation of global contracts. For Global CDS we are currently looking for a: 
 Global CDS Operations OneTouch Data Analyst In this role you will be the first point of contact for all support queries related to our client reporting tools. You will work on a wide range of different tasks on a daily basis, from troubleshooting data, reports and tool issues to providing training, support and access to the tools. You will work with internal and external customers and coordinate with our internal technical teams. Client Data Solutions is a global team, so the Data Analysts will build close relationships with others from around the globe to support our day to day business. 
 Your responsibilities:  Carry out data investigations and study the issues to deduce origin and potential corrections. Troubleshoot data and tool issues/errors; analyse the return to make an informed deduction to be communicated to requesters. Provide training to internal and external clients on tools usage, processes and best practices. Keep current on all processes Seek opportunity for continued education on various functions/skills utilized. Troubleshoot report queries by reviewing report calculations, parameters and underlying data, and explaining what the reporting fields are returning and the reports purpose. Set up 3rd Party exports/imports, and ensuring that there are necessary Data Release Authorisation in place. Create and maintain internal/external user access to the supported tools such as DecisionSource, FileMover, BCD API, etc. Provide assistance with system issues and maintenance. Consult on workarounds for system issues and work with internal departments to ensure larger issues are documented and in process of correction. Create new department processes with accompanying documentation as directed and approved by supervisor or manager. Provide business support for country reporting and internal data processes. Produce reports on an adhoc basis and investigate scheduled tasks. Support adhoc reports related to 3rd party data provisioning and data processing.  RequirementsWe're looking for you if your profile matches the following:  Bachelor degree or equivalent or minimum 2 years Customer Service experience Excellent analytical and problem solving skills Proven ability to support customers and communicate effectively Excellent organization and time management skills Capability to work independently Advanced knowledge of MS Office Suite is preferred Strong command of English, written and verbal, with fluency in other languages SQL and relational database knowledge is advantageous Travel industry knowledge/experience is advantageous  
 What we offer you: This is an exciting job within an international work environment. You'll be working with a great international team of colleagues. And, we offer you a competitive package, training, career development, flexible hours and a dynamic work environment. 
 Your work location: Singapore 
 How to apply: Is this your next career move? Dont wait any longer. Create a profile in our job portal on our website and upload your CV and cover letter. 
 Get to know us BCD Travel helps companies make the most of what they spend on travel. For travelers, this means keeping them safe and productive, and equipping them to make good choices on the road. For travel and procurement managers, it means advising them on how to grow the value of their travel program. In short, we help our clients travel smart and achieve more. We make this happen in 109 countries with more than 13,500 creative, committed and experienced people. And its how we maintain an industry leading client-retention rate of 95%, with 2017 sales of US$25.7billion. For more information, visit www.bcdtravel.com. This position is not open to third-party recruiting agencies."
171,Algorithm /  Data Scientist,VELOCITY ENTERPRISE PTE. LTD.,"$3,000to$5,000Monthly","Roles & Responsibilities apply proven algorithms to model market behaviour and facilitate decision making;  use machine learning, data mining and statistical techniques to design innovative models for predictive learning;  create and refine scalable, efficient, automated processes for large scale data analyses;
  implement novel machine learning and statistical approaches. Requirements no stranger to using Javascript &/or Python3;  able to appreciate and apply algorithms;  no fear of handling large, complex & challenging datasets;  fluent in English;  driven upstart with a sense of self-deprecating humour."
172,DATA SCIENTIST,Company Undisclosed,"$114,400to$171,600Annually","Roles & Responsibilities Lead and deliver short, time-bound engagements with customers to identify top opportunities and insights from their data assets Apply a broad range of techniques and theories from statistics, machine learning, and business intelligence to deliver actionable business insights to prospects and customers based on large-scale data. Drive creation of Pivotal software opportunities by guiding prospective customer to a top-priority use case based on their business pressures. Partner with customers while deliver Pivotal Data Science engagements to achieve customer success using big data analytics and Pivotal software. Present the Pivotal value proposition related to analytics and develop proposals based on prospects business pressures. Perform half and full-day workshops as needed to identify Pivotal opportunities. Work, under limited supervision, with internal and external teams to understand customers business problems and develop proposals to respond to those problems. Following initial high-level guidance, perform end-to-end steps involved in model development. These include preliminary data exploration and data preparation steps, variable/algorithm selection, and model development/validation and scoring. With guidance, develop and test algorithms' efficacy (i.e., by applying to test/sampled data and assessing accuracy/fit/predictive strength) for differing analytical use-cases. Work with development teams to create applications based on developed statistical models Perform occasional public presentations covering trends in big data analytics and successful uses of data science across all markets. Deliver results and presentations in a timely manner. Lead interaction with external customers to gather project requirements, provide status updates, and share analytical insights. Likely presenting project output to external customers, with limited assistance in presentation preparation. Collaborate with PIVOTAL Sales teams to educate prospects and customers on PIVOTAL software offerings. Participate in pre-sales discussions by presenting on analytic service offering and technology stack. Work with the academic and business community to contribute to research in the area of analytics on large databases. Generate new product requirements for the PIVOTAL engineering group to enhance the analytics capabilities of the big data platform.  Requirements Strong statistical foundation, with broad knowledge of deterministic and probabilistic statistical methods. Broad experience across numerous statistical toolkits, including: SAS, R, SPSS, Matlab, Mahout/MADLib Programming strength in a variety of languages: Python, R and SQL. Details for Python like Scitkit learn, tensorflow etc. Focus on PaaS and frameworks to bring models into production like API first Spoken and written fluency in English and Korean. Deep understanding of cloud computing and strong in machine learning. Optional programming strength in the following Hadoop tools: MapReduce, Pig, Hive, Hbase. Optional but desired exposure to agile development methodologies Initial understanding of the nature of the data available in one vertical/horizontal market, familiarity with typical analytics projects involved in the market, and higher level awareness of business trends in the same. Natural ability to communicate basic and complex quantitative concepts clearly. Natural curiosity to research and identify possible quantitative solutions to common business problems. Team-oriented and collaborative nature, while also able to work in a self-directed manner. Innate customer orientation, with a proactive focus on collaborative problem-solving. Solid knowledge foundation for technical concepts, including distributed computing, database architectures, business intelligence, and ETL processes. Ability to travel for projects (2-6 weeks) as needed, but not expected to exceed 25% of work time "
173,Data Scientist,RESMED ASIA PTE. LTD.,"$6,000to$7,000Monthly","Roles & ResponsibilitiesData Scientist We are currently seeking applications from an experienced Data Scientist to join our Healthcare Informatics (HI) team based in our Connexis office Singapore.
 At ResMed we focus on capability and passion. With your in-depth knowledge and understanding in applied research and development in the areas of data science biomedical informatics, you will use the latest technologies in machine learning and distributed computing. The platform and algorithms developed may be used in a range of diagnostic and therapeutic applications, such as sleep disorder breathing, chronic obstructive pulmonary disorder, and other respiratory disorders, as well as co-morbidities such as congestive heart failure and diabetes and chronic disease management. The candidate we are seeking will specialise in the following areas and be capable of the following responsibilities:  Research, customization, and development of statistical and machine learning algorithms to meet project requirements; tasks include defining hypotheses, executing necessary tests and experiments, evaluating, tuning and optimizing algorithms and methods to specific situations.  Analysis of big data for data-driven solution validation, evaluation and technology innovation.

  Optimize data analysis processes and systems for better efficiency and maintainability.

  Writing of documents that clearly explain how algorithms should be implemented, verified and validated.  Writing documents for use in the preparation of intellectual property and technical publications.  Monitoring the literature of interest and industrial development trends, broadly in the areas of data analysis and machine learning.  Understanding regulatory requirements, such as those mandated by the FDA.  Working within the ResMed Quality system, standards and maintaining training requirements. RequirementsLets talk about you: To really get us excited, you will have extensive working knowledge of machine learning fundamental theories and data mining technologies with proficiency in statistical analysis methods, including analysis of variance, regression, time series analysis, survival analysis, etc. In addition, you will have strong database skills and experience, including experience with SQL programming. You will also have a Post-graduate research experience (Masters or PhD) Degree in a field encompassing Data Science, Applied Statistics, or Biomedical Informatics or related discipline with experience in relevant data science industry. Experience in a medical device company would also be advantageous. Lets talk about the team: Big ideas and big goals reign at ResMed Singapore. Within this growing HI team, youll thrive in an environment filled with self-starters who possess the drive to make a difference. Youll be encouraged within a people-focused culture that motivates and recognises talent, so that together, we can produce the best products and results. OK, so what next? At ResMed, we believe in supporting, inspiring and developing our people. So we recruit the best and then give them the tools to make a real difference in the lives of our patients. We believe that fresh thinking inspires innovation  and our shared success. If this sounds like a place you would like to work and you have the drive to transform and enhance the lives of millions of patients through your contribution at work, then today is your day! Apply now!"
174,Market Data Business Analyst  /  Project Manager,ALLEGIS GROUP SINGAPORE PRIVATE LIMITED,"$9,000to$12,000Monthly","Roles & Responsibilities Engage customers and operational staff in documenting detailed requrements as we progress through our strategic customer journey. Working with Trade Services management team, implement a PMO framework; build programme-based business plans, project budgets and resource break-down streams that allow investment decisions. Monitor progress and delivery across the portfolio of approved projects and business plans. Manage communication plans across the division and our customers. Provide structured reports to management on programme execution performance, resource management and cost management across the portfolio. Where a vendor-lead solution is appropriate, work with the market data team, engaging with our vendors and sourcing colleagues, to prepare RFIs, RFPs.  Requirements Demonstrated experience in project management and formal project management, preferably with PMP / PRINCE2 qualifications 10+ years experience working in banking environments or other highly regulated environments. 10+ years working in the market data industry, with market data product awareness and exposure to market data contracts and technologies. 10+ years working with market data delivery technologies and associated commercials. Demonstrable experience in executing RFI and RFPs as a market data subject matter expert. Experience in managing resource groups in matrix organisations and in leading teams of less than 5 people. Experience in working with the SDLC and development teams. Comfortable in communicating with SVP, ED and MD leaders.  Preferred Experience  Experience in working with financial sales and trading staff; financial business management is a plus Book keeping or financial accounting knowledge is a plus. Public cloud experience is a plus. "
175,AI DATA VISUALIZATION ENGINEER,AMARIS.AI PTE. LTD.,"$4,000to$8,000Monthly","Roles & ResponsibilitiesWe are looking for
a clear, confident and persuasive communicator, with excellent presentation skills and with the ability to structure a coherent, logical argument and the confidence to defend assumptions, projections and recommendations.  The Data Visualization Engineer
should have
an analytical and creative approach to problem solving and have business strategy skills to build the solutions necessary to ask the right questions and find the right answers.  If you have a passion for data analytics, and wants to make an impact by designing and building visually intuitive, information-rich data products, this is your opportunity. In this position, you will be a torchbearer for data visualisation and UI design, and the incredible results it brings in organizations. Requirements  Shape our data visualisation and UI design consulting business by leading business development efforts and consulting projects   Gathering and documenting client requirements and translating these into process and UI architecture designs   Providing thought leadership and actively participating in the application design, implementation, and roll-out of Amaris.AI solutions   Act as a trusted advisor for data visualisation solutions and services for our clients and prospects   Design and develop eye-catching data visualisation demos and storylines, adding to and expanding Amaris.AI services
   Spearhead the evangelisation of and demonstrate the power of data visualisation and UI design inside Amaris.AI, i.e. by teaching, leading community activities and by building reusable assets  "
176,Data / Business Analyst (1 year contract),TANGSPAC CONSULTING PTE LTD,"$2,500to$3,700Monthly","Roles & ResponsibilitiesThis is a one year contract with a leading local bank.
 Responsibilities
  Produce accurate and timely reports to regulators and senior management relating to counterparty groups and related party transactions Conduct post event checking of exposures against internal and regulatory thresholds and work with relevant parties to resolve/mitigate any areas of concern Be part of team to assess and implement changes arising from internal/regulatory demands where required Support Business Unit in exposures reports, earmarking and underwriting requests Perform other adhoc tasks or participate in automation projects where applicable
  RequirementsRequirements

  Degree in Data Science/ IT/ Big Data/ Data Analytics 2-3 years Financial industry working experience preferred Highly organized and flexible in prioritizing competing work demands Proficient in MS Access & SAS. Qlikview experience would be an advantage Meticulous with strong aptitude for numbers and comfortable handling large volumes of data Able to produce quality results under tight timelines Team player with good attitude and excellent interpersonal skills "
177,"Manager, Big Data IM, Advisory",ERNST & YOUNG ADVISORY PTE. LTD.,"$6,000to$12,000Monthly","Roles & ResponsibilitiesEY Data and Analytics is the data and advanced analytics capability within EY Asia-Pacific.
 We have vibrant practices in Australia, New Zealand, Singapore, Hong Kong, Korea, The Philippines and Malaysia. EY Data and Analytics creates intelligent client organizations using data & advanced analytics.
 We go beyond strategy and provide end to end implementation of real life data environments and have some of the best architects, project managers, business analysts, data scientist, big data engineers, developers and consultants in the region.

 
 Due to our continued growth we are looking for a talented, inquisitive and proactive Big Data IM join our team. RequirementsREQUIREMENTS:   Bachelor degree and above in Analytics, Information Systems Management, Computer Science or related fields. Hands on experience in implementing data integration processes, designing and developing data models(ER/Dimensional/Vault), designing, developing and building in detail ETL/ELT processes or programs. Contributed in at least 2 phases of SDLC lifecycle and experience in Big Data, data warehouse, data analytics projects, data migration, change management process, and/or any IM (Information Management) related works. Experience with Hadoop Technologies such as HDFS/MapRFS, Map Reduce(II), Advanced HDFS ACLS, Hive, HBase, Cassandra, Impala, Spark, Drill, Sentry, Sqoop, Flume, Kafka, Storm, Zookeeper and zkClient tool Good understanding on Cloudera or Horton Works or MapR Hadoop Distribution with deep understanding of administration concepts Experience in working with RDBMS technologies such as, Oracle, Microsoft SQL Server, PostgreSQL, DB2, MySQL etc. Experience in MPP database technologies such as Teradata Hands-on experience on Spark, SparkSQL, Hive QL, Drill QL, Impala, Spark Data Frames and Flink CEP, Flink TableAPI&SQL as ETL framework Hands-on programming skill on Scala/Python using Spark/Flink Framework Strong knowledge of
Big Data stream ingestion and IoT streaming using Flume, or Kafka, Storm, MQTT, RabbitMQ Good understanding Spark Memory management with and without Yarn memory management Should have basic understanding on Cloudera Manager or HortonWorks Ambari and MapR Control System Should have experience developing and designing in one or more NoSQL database components and objects using Cassandra, Mongo, HBase, CouchDB/Couchbase, Elasticsearch Should have experience developing and designing in one or more NoSQL database technologies such as Cassandra, Mongo, HBase, CouchDB/Couchbase, Elasticsearch etc. Should good working knowledge of HCatalog and Hive Metadata. Should have working knowledge of Kerberos authentication tool Experience in commercial ETL tools like Talend, Informatica or Alteryx will be added advantage Greenplum, IBM Pure Data etc. will be an added advantage Experience in working with RDBMS technologies such as, Oracle, Microsoft SQL Server, PostgreSQL, DB2, MySQL etc. Experience in MPP database technologies such as Teradata, Greenplum, IBM Pure Data etc. will be an added advantage Good knowledge of data warehouse and data management implementation methodology. Good knowledge of the Information Management framework, including operating model, data governance, data management, data security, data quality and data architecture. Knowledge and experience in
 data visualisation concepts using tools such as SAS Visual Analytics or WRS, Tableau, Microsoft PowerBI or Reporting Services, IBM Cognos, SAP Business Objects, etc. will be an advantage. Ability to pick up new tools and able to be independent with minimal guidance from the project leads/managers. Strong analytical and creative problem solving capabilities. Ability to establish personal credibility quickly and demonstrate expertise. Ability to create a positive learning culture, coach and develop team members.  
 ADDITIONAL REQUIREMENTS:   6
to 15 years of experience in data warehouse, data analytics projects, change management process, and/or any IM (Information Management) related works. Delivered at least two (2) full SDLC lifecycle projects. At least one of the industry or domain experiences in Banking/ Telecommunications/ Consulting Preferably with experience in implementation best practices involving data management, data reconciliation, data duping, scheduling, etc. Able to assess design considerations in the aspect of data management and integration Experience with Agile/SCRUM/Kanban software implementation methodology Should have good knowledge in DevOps engineering using Continuous Integration/Delivery tools such as Docker, Jenkins, Puppet, Chef, GitHub Atlassian Jira etc. Certification in any of Hadoop Big Data tool/technology, data integration, data management, or visualisation tools is an added advantage. Knowledge about the infrastructure paradigms such as OS, network etc. is an added advantage.  
 ABOUT US The EY Data and Analytics team are specialists in information management, advanced analytics and business intelligence. We implement the information-driven strategies and systems that offer the highest return on investment, profitability, and service or policy outcomes for our clients. Our consultants work to create a lasting organisational culture that encourages people to use information and technology more creatively and more intelligently to get better business results.
 

 WHY US We work with some of the worlds most influential businesses on many of their most exciting Bigdata and IoT projects. Our sheer scale, scope and reach will provide you with the experiences, challenges and contacts that can inspire you for life Our culture means you can succeed whatever your background, work to your natural strengths, and learn from a remarkably diverse and talented group of people in a dynamic and collaborative global business environment 
 
 
 WHAT WORKING AT EY OFFERS EY offers a competitive remuneration package commensurate with your work experience where youll be rewarded for your individual and team performance. We are committed to being an inclusive employer and are happy to consider flexible working arrangements, where this may be needed, guided by our FWA Policy. Plus, we offer: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way thats right for you 
 
 ABOUT EY  As a global leader in assurance, tax, transaction and advisory services, were using the finance products, expertise and systems weve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, well make our ambition to be the best employer by 2020 a reality. 
 If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.  Join us in building a better working world.  Apply now"
178,Storage Engineer  /  Data Storage ~ Up $5000,CAPITA PTE. LTD.,"$3,000to$6,000Monthly","Roles & ResponsibilitiesResponsibilities  Configure and administer Redundant Array of Independent Disks (RAID) storage and associated components Configure and administer Storage Area Network (SAN) and associated components; including Fibre Channel switch administration Configure and administer data restore and disaster recovery Configure and administer data backup clients and servers Maintain storage aspects of new server integrations, storage allocation, and Change Management Setup procedures to consolidate storage of data from different platforms (i.e. Windows, UNIX and LINUX) Troubleshoot and fix storage issues Perform routine equipment check and preventative maintenance Storage analysis, capacity planning and performance planning of storage components Document the policies and procedures to support the operational storage environment and participate in the design and ongoing refinement of procedures and policies Prepare reports on storage administration best practices, new technologies, etc. and recommend enhancements and configuration changes to improve and optimize storage 
  RequirementsRequirement:  Minimum 3 years of relevant experience
 Diploma / Degree in Information Technology or equivalent
 CommVault Backup Solution (version 10 and 11) Hitachi NAS and SAN (HUS and VSP) min 1yr experience with G series Hitachi HCP EMC VNX series and Isilon Cisco MDS 	
  Interested candidates, please
click the pply Now"" below Only shortlisted applicants will be notified by our consultants. CAPITA PTE LTD | EA License No : 08C2893 Tan Chin Yin | REG No : R1762272 
"
179,Data Scientist,Company Undisclosed,"$6,000to$10,000Monthly","Roles & ResponsibilitiesJoin the excitement of Artificial Intelligence in the Cloud! We are a fast-paced data science team in the Cloud Artificial Intelligence Platform Group, building deep learning powered intelligent tools and end-to-end solutions for scenarios in diverse enterprise and consumer verticals. We are looking for data scientists who are passionate about data and want to apply machine learning techniques to solve real-world problems for enterprises and consumers. You will help develop capabilities for deep learning models and tools and solutions around it. You would also work on predictive and prescriptive modeling, text and image mining & processing, recommendations, clustering, forecasting methods, and other advanced statistical techniques. You will work with data from diverse structured and unstructured data sources in both batch and streaming modes, and various formats including tabular, image/video, audio, text and time series.
 In this role, you will interact with a team of experts in deep learning, machine learning, distributed systems, program management and partner product teams, and work on all aspects of the design, development and delivery of deep learning enabled solutions, including problem definition, data acquisition, exploration, training, testing and evaluating deep learning models, and creating end-to-end pipelines and solutions in production.

 
 RequirementsRequired:
  2+ years of experience (including PhD research) in machine learning or deep learning Preferred:  PhD /MS/BS degree in Electrical Engineering, Computer Science or an equivalent technical field  Experience in any of the deep learning frameworks (Keras, TensorFlow, CNTK, Theano, Caffe, Torch, H2O)  System-level knowledge of deep learning (such as GPU or FPGA implementations) a plus  Strong software development skills in one or more high level languages (C/C++/Java/C#) and one or more scripting languages (Python/R/javascript)  Publications in related fields (deep learning, machine intelligence, data mining, etc.) preferred  Experience building production grade machine learning enabled solutions end to end.  Strong intellectual curiosity and passion to solve real-world problems for enterprises and consumers"
180,Supply Chain Analyst,33 TALENT SINGAPORE PRIVATE LIMITED,"$4,000to$5,000Monthly","Roles & ResponsibilitiesReporting to the Director in the company's Global Analytics Hub, the Data Analyst is to provide accurate, timely, relevant and quality analysis for supporting the Supply chain arm of the business. You will offer effective reporting, insights and analysis for multiple stakeholders, internal clients, locations and priorities. You will be working hands-on and deliver flexible solutions ensuring stakeholder satisfaction Responsibilities: Data Analytics & Visualization Liaise both internally within the team as well as externally with business stakeholders for completion of data analysis and visualization of Insights. Support the development and testing of hypotheses across all supply chain related data sets supplied by the business Applying Advanced analytics techniques to support data driven decision support for the supply chain
 organization Support the proof of concept, and development of tools and applications. Work with the manager to define key questions and projects that will transform the business This position will be based in Singapore RequirementsAt least 1-3 years' experience working for an enterprise multi-national utilizing multi-datasets and sources running predictive, prescriptive and descriptive analytics. Bachelors degree in Engineering, IT, Math, Economics, Statistics, Sciences or technical discipline; Expert knowledge of R/Python programming and
 visualization tools such as
 Qlik Sense is a must;
 SAS EM / SAS EG experience is desirable; Ability to understand and extract data from large and complex data sets (structured & unstructured) Basic knowledge of data quality measurements, methodology and reporting tools Basic knowledge of data management Basic knowledge of statistical methods and market leading data analysis tools and platforms Strong results driven personality, with a high level of enthusiasm, energy and confidence Excellent analytical, communication, organizational and presentation skills Ability to demonstrate flexibility and integrity: be able and willing to work hands on, independently or with a small team"
181,Data Center System Engineer,SCIENTE INTERNATIONAL PTE. LTD.,"$2,500to$3,600Monthly","Roles & ResponsibilitiesAn exciting opportunity to gain new IT operations experience as a
Data
Centre Engineer for one of the top 10 global e-commerce company in Singapore!  Good chance to get exposed to other aspects within a
data
centre operations i.e. cabling management, power management and the latest IT infrastructure technologies in the e-commerce space! RequirementsMandatory Skill-set  At least Diploma in Computer Science or IT; 
At least 1
year
of experience in
Data
Centre / IT Operations
and Support
; Good knowledge and experience in IP Network, switches, basic network components and networking protocols i.e. TCP/IP; Good working knowledge
in various Operating Systems (OS) i.e. Linux
and Windows;
 Conversant in basic troubleshooting in issues in Windows / Linux systems and networking; Proactive, responsible,
good work attitude and a team player; Good interpersonal communication
and documentation skills.  Desired Skill-set  CCNA; Prior experience in Server Room / DR Command Centre /
Data
Centre operations is preferred.  Responsibilities  Responsible for day to day operations and administration
within a
data
centre environment; Attend to day to day operational tasks
and assists engineers on issues and investigation for root cause; Involved in equipment
relocation, replacement and removal; Perform system maintenance and do regular reporting; Required to do
administrative and documentation work; Assist in troubleshooting in Linux/Windows system; Identify areas of improvement and ensure corrective or preventive actions are put in place; Any other tasks assigned from time to time.  Should you be interested in this opportunity, please send your updated resume to apply@sciente.com at the earliest.
 Confidentiality is assured, and only shortlisted candidates will be notified.
 EA License: 07C5639"
182,Data Engineer,ZALORA SOUTH EAST ASIA PTE. LTD.,"$4,500to$6,000Monthly","Roles & ResponsibilitiesWe are looking for a
Big Data Engineer
happy to design, build, maintain and automate big data environments (datalake, etc) and the associated data to enable the teams to make use of the high volume of data available from our e-commerce activities. You should be proficient in: - Technical background:  Linux Big Data technologies (Redshift, BigQuery, Spark, Glue, Parquet) Industrialization (Ansible..), Orchestration (Kubernetes), containers in cloud (Docker, AWS) Strong experience in resilient architecture (high availability, scalability) Data management: you have experience in integrating and managing large volumes of Data while taking into account performance issues Coding skills: skills in one or more scripting languages (Perl, Ruby) as well as one or more development languages (Python, Java)  Soft skills: while being a tech automation enthusiast with a passion for building tools to make developers' lives easier, you also want and know how to share your expertise with other people to empower them. Agile and DevOps approach, with an operational experience as an Ops in a demanding environment. You know what its like to manage in production critical systems and you have experience in sharing this knowledge to the teams to enable a you build it / you run it mindset. Requirements BS in Computer Science or related technical discipline or equivalent practical experience 3-4+ years of experience with high-traffic, high volume, high scalable distributed systems and client-server architectures (clustering, partitioning, sharding, etc) Some experience working with Data Scientists and finding solutions for them to work efficiently while manipulating high volume of data and be able to work with them and the teams to bring their algorithms at scale Strong operational experience with AWS, container approaches. "
183,BE Data and Systems Engineer,Company Undisclosed,"$4,000to$8,000Monthly","Roles & ResponsibilitiesJOB DESCRIPTION: 
 As a Manufacturing Central Team (MCT) Data and Systems Engineer, you will be responsible for developing and maintaining yield systems, reporting and/or data mining tools. You will be collaborating with Data Scientists, Engineers, Technicians and Data Mining team members to design and implement systems to extract yield and manufacturing data from 
business systems, transforming it into a format that enables ease of data analysis, understanding yield performance and creating a dynamic presentation layers for use by engineers and managers throughout Backend Manufacturing for continuous improvement initiatives. You will be creating new solutions, as well as, supporting, configuring, and enhancing existing solutions.
 The success of this position translates to an ease in data mining to allow more time for data analysis. 
 
 KEY RESPONSIBILITIES AND TASK 
 Understand the Business Problem and the Data that is Relevant to the Problem Maintain an intimate understanding of company and department strategy Translate analysis requirements into data requirements Identify and understand the data sources that are relevant to the business problem Develop conceptual models that capture the relationships within the data Define the data-quality objectives for the solution Be a subject matter expert in data sources and reporting options 
 Architect Data Management Systems Leverage understanding of the business problem and the nature of the data to select appropriate data management system (Big Data, OLTP, OLAP, etc.) Design and implement optimum data structures in the appropriate data management system (Hadoop, Teradata, SQL Server, etc.) to satisfy the data requirements Plan methods for archiving/deletion of information 
 Develop, Automate, and Orchestrate an Ecosystem of Processes that is Fast and Reliable for Varying Volumes of Data Identify and select the optimum methods of access for each data source (real-time/streaming, delayed, static) Determine transformation requirements and develop processes to bring structured and unstructured data from the source to a new physical data model Develop processes to efficiently load the transform data into the data management system
 
 Prepare Data to Meet Analysis Requirements Work with the yield engineers to implement strategies for cleaning and preparing data for analysis (e.g., outliers, missing data, etc.) Develop and code data extracts Follow best practices to ensure data quality and data integrity Ensure that the data is fit to use for data science applications RequirementsEDUCATION REQUIRED  Bachelors Degree Data Science Computer Science Software Engg Related field of Study 
 EXPERIENCE REQUIRED 2+ years experience in any of the following: Proficient with one or more high-level client, object-oriented language (e.g., C#, C++, JAVA, Python, Perl, etc.). Proficient with one or more web programming language (PHP, MySQL, Python, Perl, Javascript, ASP, etc.). Significant experience with big data processing and/or developing applications and data sources via Hadoop, Yarn, Hive, Pig, Squoop, MapReduce, HBASE, Flume, etc. Additional Information: The expectation is that you will have a minimum of 2 years professional experience or equivalent combination of education and experience based on the above requirements
 
 QUALIFICATION




 Ability to work with multiple operating systems (e.g., MS Office, Unix, Linux, etc.). Experience with Microsoft and other tools (Tableau, HTML, MDX, Integration Services, Analysis Services, Reporting Services, SharePoint) Understanding of how distributed systems work Familiarity with software architecture (data structures, data schemas, etc.) Strong working knowledge of databases (Oracle, MSSQL, etc.) including SQL and NoSQL Strong analytical, problem solving, and organizational skills Excellent oral, written, and technical communication skills and a solid command of the English language Experience in group presentation and public speaking Enthusiastic and positive attitude that anything is possible Self-motivated and team oriented"
184,Data Scientist,RANDSTAD PTE. LIMITED,"$7,000to$9,000Monthly","Roles & Responsibilitiesabout the company Our client is one of the largest insurance companies leveraging and focusing on technology-driven business models and capabilities to drive business results. They are looking for a passionate Data Scientist who is able to source and develop data models to drive the analytics developed by the analysts and data engineers about the role   Work with business groups to conceptualize, drive and implement proof-of-concepts   Develop Machine Learning and AI solutions to solve business problems   Help the team deploy models to practice and make frequent model improvements as new data is available   Identify and document best practices and frameworks to streamline and standardize workflows   Advise on implementation of advanced data analytics models with actionable outcomes    
 Requirementsskills and experience required   Masters or Ph.D. in Statistics, Mathematics, Computer Science or related fields   4+ years of industry, hands-on experience in Machine Learning, Predictive Analytics, AI   Good knowledge in a wide variety of advanced data analysis and machine learning techniques, and experience in developing solutions in response to real-world business problems   Experience in working with large unstructured datasets, deep learning and applying novel machine learning techniques to generate novel insights   Strong programming skills (SQL, Python, R, Scala, Java and/or SAS)   Experience with deep learning frameworks such as TensorFlow, Keras; Caffe, Torch   Familiarity with setting up and executing machine learning tasks on Google Cloud platform and/or Amazon AWS   Exposure to Hadoop/Spark or similar big data frameworks   To apply online please use the 'apply' function, alternatively you may send your CV to sarah.yang@randstad.com.sg or contact Sarah Yang at +65 6510 3633. Referrals are greatly appreciated! (EA: 94C3609/ R1657816)"
185,Senior Data Engineer,Company Undisclosed,"$8,000to$11,000Monthly","Roles & ResponsibilitiesYou will be a key contributor to the Data Engineering team, primarily by applying and building tools to gather data from disparate sources, processing and loading the transformed data to support internal and external constituencies. You will be required to maintain and enhance our data infrastructure and analytical solutions. This role is a hands-on engineering position. Responsibilities  Design and implement scalable and robust software platform for ingesting and transforming in (near) real-time using a variety of open-source and proprietary Big Data technologies Recommend and implement ways to improve data reliability, efficiency and quality Work closely with stakeholders to ensure high standards of data governance during implementation Serve as technical subject matter expert in latest big data technologies  Requirements 7+ years of superior software development experience building commercial large-scale software systems and database systems Proven expertise in Business Intelligence, Analytics and Big Data activities; relevant experience in web, video, mobile or adtech domain is a definite plus Proficiency in SQL coding is mandatory. T-SQL is a plus. Strong scripting knowledge like Shell, Python, etc. Experience with Hadoop frameworks such as Hortonworks associated open source tools (MapReduce, Tez, Spark, HBase, NoSQL etc.) Production coding experience in Scala, Spark programming languages and development frameworks will be considered favourably Expert knowledge in data management technologies and software engineering tools to efficiently process large volume of data Experience in Web UI, middle-tier, and backend development Demonstrated clear and thorough analytical thinking A proven team player and contributor who can multi-task and deliver against timelines Minimum degree in Computer Science/Engineering, Statistics, Mathematics, or equivalent "
186,Data Analyst,MAYBANK KIM ENG SECURITIES PTE. LTD.,"$4,000to$6,000Monthly","Roles & ResponsibilitiesJob Description  Assist in regional product management projects implementation Participate in project planning sessions with users for functional requirement gathering Assist in developing and testing of new functionalities and features Support the data warehouse in identifying and revising reporting requirements Assist in designing and developing reports or templates Provide technical expertise on data storage structures, data mining and data cleansing Provide troubleshooting and functional support for the regional product management system users Provide functional system maintenance such as managing master data, including creation, updates & mapping and user administration of regional product management system System Technical documentation Ad hoc reports/projects support as assigned  
 RequirementsRequirements  Minimum of 4 years experience. Experience in developing application Front-End GUIs.
 Proficient in C# and MSSQl Exposure to ASP.NET, WPF, WCF, Javascript, Python, FIX Engine and Message Bus Services a plus. Solid knowledge of MVVM design patterns. Understanding of the brokerage business or financial instruments is a plus. Team player with positive attitude Works well in changing environments where goals and objectives are subject to evolution. "
187,APAC Data Engineer,UPS ASIA GROUP PTE. LTD.,"$4,091to$5,454Monthly","Roles & ResponsibilitiesSummary The Data Engineer will be responsible for expanding and optimizing the data and data pipeline architecture, data flow and collection for the Data Science team and creating Application Programming Interface (APIs) to integrate the models with production systems. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support the Data Analysts and Data Scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. Responsibilities:  Creates and maintains optimal data pipeline architecture. Assembles large, complex data sets from multiple data sources that meet functional / non-functional business requirements. Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Builds the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and no SQL technologies. Builds analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Works with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Develops data design based on exploratory data analysis to meet stated business need. Works with team to select and implements model development process from statistics and machine learning to answer business problems. Reviews and creates repeatable solutions through written project documentation, process flowcharts, logs, and commented clean code to produce datasets that can be used in analytics and/or predictive modeling. Synthesizes insights and documents findings through clear and concise presentations and reports to inform stakeholders. Develops procedures to monitor model and production system performance/integrity. Supports analysis and integration of tools and methods to provide desired results from models and requirements. Provides consultation to functional partners to support the design of planning systems. Creates technical documentation in compliance with internal Software Development Lifecycle to communicate and update project teams and stakeholders. Develops data features that will serve as inputs to AI/Machine Learning/OR techniques. Acts as subject matter expert with investigating and evaluating emerging technologies. Articulate potential competitive market benefits of new technologies to senior management. Maintains broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies.  RequirementsSkills and Qualifications  Advanced working Structured Query Language (SQL) knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience in building and optimizing big data data pipelines, architectures and data sets. Experience in performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Possess strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Strong project management and organizational skills. Experience in supporting and working with cross-functional teams in a dynamic environment. Possess 3 - 5 years of experience in a Data Engineer role who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Possess experiences in using following software/tools: 	 Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with AWS cloud services: EC2, EMR, RDS, Redshift Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.   "
188,"Business /  Data Analyst, Corporate Technology - Global Surveillance Technology, Associate","JPMORGAN CHASE BANK, N.A.","$6,000to$12,000Monthly","Roles & ResponsibilitiesThe Corporate Compliance Technology (CCT) organization supports the regulatory and compliance technology requirements of the Compliance line of business across JPMC.
 The CCT Global Surveillance Technology tower is experiencing significant growth to develop and expand global capabilities and the regulatory obligations according to the defined multi-year strategic roadmap.


 These roadmap and programs focus on trade (transactional) surveillance covering market manipulation, information barrier surveillance, internal and regulatory driven monitoring as listed blow, as well as electronic communications (eCommunications) surveillance against collusion, conflict management and anti-trust. 
 Within Trade (transactional) Surveillance:  Market Manipulation / Surveillance covering all the Investment Banking trading products Information Barrier Surveillance (Grey List, Restricted List and MNPI Over the Wall monitoring) Internal Surveillance and monitoring (e.g. internal consistency/behavior patterns) Regulatory driven (e.g. Unidentified Large Trader / Rule 13-H) and Client Review (Suitability): Monitoring of Private Bank accounts and Sales Managers Review Compliance  
 The successful candidate will support the enhancement and build-out of a suite of bank-wide strategic trade and market surveillance platform consisted of in-house and vendor package Surveillance Detection Engine, and in-house Surveillance and Analytics Platform providing Order/Trade/Positions Repository, Business Intelligence reporting, statistical and pattern detection analytics to monitor the JPMC Corporate and Investment Banking Markets trading businesses across Equities, Futures and Options, FX, Commodities and Fixed Income business areas.
 The candidate will be responsible for functional and data analysis and guide the AD team and vendor consultants to implement the patterns and functionalities into the surveillance platform.
 The candidate will also need to support a suite of existing BaU applications. 
 Specific responsibilities include:  Understand new regulations and changes to trading platforms in order to know the impact on security trading and firm trading activity. Work with Surveillance users to organize, analyze and document business requirements for surveillance, reports, and relevant workflows. Responsible for gathering and documenting requirements and detailed functional specifications. Evaluate surveillance models to understand the data requirements and identify internal/external data sources to map transactions/positions data, reference data and market data to business requirements. Work with the Front office / Middle office / Back office teams to define data interface specifications and integrate data in disparate trading systems, risk management systems and market data sources. Evaluate vendor and custom solutions to map business / functional requirements, identify product limitations, define product configuration, and work flows. Evaluate the trade-off between Vendor solutions and Custom solution. Conduct review sessions with users on the solution, user interface and reports. Define product enhancements, defect resolution in the product and update business users on the product upgrades and the potential impact on the alerts. Work on data mapping from source systems to product, model configuration, define alert/case management and workflows, threshold configuration. Source data mapping to UI display fields and reports. Conduct statistical analysis on trade data and trading patterns across different security types and regions to improve the quality of the alerts reported to the surveillance users. Work with the data management team on the integration of data transformation in the overall architecture. Recommend and develop new methodologies for supporting information management security and compliance requirements. Work with the technology team to ensure database designs are consistent with information architecture and information management and industry standards. Work with business partners to help identify, analyze and resolve defects raised during UAT and production support. Develop use cases and oversee creation of test scripts by the QA team. Provide reports and metrics as requested by the users to improve the effectiveness of trade surveillance. This position does not supervise employees  
 
 Requirements
Qualifications  8+ years of Business Analyst or Data Analyst experience in Compliance Surveillance, Investment Banking Front-office Trading or Pre-/Post Trade Analytics, or other complex data systems 3+ years of experience in Investment Banking Market Surveillance and Supervisory Software such as SMARTS Broker, Actimize or Mantis 5+ years of experience in analysis and design large-scale, high-volume data processing applications, using distributed Relational RDBMS or Big Data technologies Strong analytical and problem-solving skills. Able to multi-task, proactive and attention to details Ability to work under pressure and take ownership of issues. Sense of urgency to solve problems and propose solutions Ability to work with geographically distributed and culturally diverse development organization  
 Preferred Experience  GUI and Reporting design/build experiences with Front-end visualization and Business Intelligence Tools such as QlikView, Spot Fire, Business Objects, etc. FIX protocol and UNIX scripting.  
 Our Corporate Technology team relies on smart, driven people like you to develop applications and provide tech support for all our corporate functions across our network. Your efforts will touch lives all over the financial spectrum and across all our divisions: Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and within the Corporate Administrative Office. Youll be part of a team specifically built to meet and exceed our evolving technology needs, as well as our technology controls agenda. 
 When you work at JPMorgan Chase & Co., youre not just working at a global financial institution. Youre an integral part of one of the worlds biggest tech companies. In 14 technology hubs worldwide, our team of 40,000+ technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $9.5B+ annual investment in technology enables us to hire people to create innovative solutions that will not only transform the financial services industry, but also change the world.  At JPMorgan Chase & Co. we value the unique skills of every employee, and were building a technology organization that thrives on diversity. We encourage professional growth and career development, and offer competitive benefits and compensation. If youre looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world, we want to meet you. 
 We strongly encourage all applicants to apply via our careers website where you are able join our Talent Network to receive customized vacancy notifications and ensure that your details are accessible by our global recruiting team - www.jpmorganchase.com/careers. 
 A quick link to this particular job posting can be found in this URL: http://jobs.jpmorganchase.com/ListJobs/ByKeyword/180037077/  Please note that only short-listed candidates will be notified. We thank you for your interest and wish you all the best in your career.  Yours Sincerely, Human Resources JPMorgan"
189,SENIOR AI DATA SCIENTIST (MACHINE COMPREHENSION),AMARIS.AI PTE. LTD.,"$9,000to$15,000Monthly","Roles & ResponsibilitiesWe are looking for exceptional Machine Comprehension
Data Scientists to embark on our journey to deploy world class
deep learning and machine learning algorithms in the investment and portfolio management space. 
 The Senior AI Data Scientist (Machine Comprehension) should
have a PhD or Masters in Computer Science, Statistics, Deep Learning or Machine Learning and a strong background in statistical methods such as Bayesian statistics, time series, and feature engineering. 
 If you have a passion for building
state-of-the-art deep learning and machine learning models and have a
keen interest in
Natural Language Processing and semantic AI, this is your opportunity. Requirements  Implement state-of-the-art deep learning and machine learning models for feature engineering and question/answer/prediction in investment platform   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions  "
190,"Data Engineer (Hadoop ETL, Data Science Team) - perm in Banking",DAVID & GOLIATH PTE. LTD.,"$6,000to$10,000Monthly","Roles & ResponsibilitiesAre you an exceptional Data Engineer with established competencies around
Hadoop, ETL, Oracle PLSQL? Do you have an exceptional Data Engineering career and know how to create material impact in the space? If so, this could be the career opportunity for you !! 
 Data Engineer (Hadoop ETL, Data Science Team):
  
 We are looking for a dynamic, self-motivated and technically competent individual who has an interest in data and technology  data architecture, data modelling, data integration etc. Specialising in the Data domain, you will work in a high-pace data engineering team that is delivering and supporting the Investment Banks data needs. 
  Work closely with data analysts, data scientists and business end-users to implement and support data solutions using best-of-breed technology and methodology. Conduct requirement workshop with business users and analyse requirements holistically. Design robust and scalable solutions to meet business needs and takes operational considerations into account. Demonstrate technical expertise in the assigned area. Analyse, tackle and resolve day-to-day operational incidents and advisory to business users Analyse systems operations data (SLAs, customer satisfaction, delivery quality, team efficiency etc.) to identify actionable trends for continual improvements. Play an active role in the project coordinating between internal resources and third parties/vendors for project execution. Provide technical coaching and guidance to juniors  RequirementsIn return for this excellent career opportunity, we ask that you have the following:  Bachelor degree or equivalent in Computer Science, Data Science or Engineering degree Relevant working experience in Oracle PLSQL data modelling, data integration, preferably in an investment and banking environment. Experienced with the Systems Development Life Cycle implementation methodology (SDLC) and/or agile methodologies like Scrum and Kanban. Good team player, with strong analytical skills and enjoy complex problem solving with innovative ideas Strong communication/people skills required to interact with data analysts, business end-users and vendors to design and develop solutions Passion for data and technology Good at working with details and is meticulous for operations.  
 Not Required but good to have:  Experience working with enterprise databases using database technologies (PL/SQL, SQL, NoSQL) and data integration products (e.g. Informatica) Experience in programming language in Python, Java Linux family of OS CFA equivalent certifications would be an added advantage.  
 Big Data  Hadoop Technologies: HDFS, Zookeeper, Yarn, Spark, Hive, Impala, Sqoop, Solr, ELK, Flume, Kafka Hadoop Platforms: Cloudera, Databricks NoSQL Databases: Neo4J, Cloud based Big Data Services: AWS EMR, Azure HDInsight Elastic Search  
 Scripting  Shell Script Servlets, JSPs, JSTLs Apache Olingo JPA RESTful Data API  
 *Disclaimer:




 Candidates who are shortlisted will go through Video Interviews, Data Engineering, ETL Technical Tests and Face to Face interviews. 
 If this speaks to you and you are ready for a new challenge, please send your Resume in MS word format to bennie.yeo@davidgoliath.net Even if you are not interested, you can still park your CV with us for other Banking IT positions or forward this Advertisement to your counterparts with the relevant Banking IT experiences I am looking for. 
 We Seek to:  Understand your personal circumstances, needs and ideals Present your credentials to our clients only with your permission Strategize and consult with you  
 Your application will be kept with the strictest of confidence. 
 EA License Number: 18S9167 Registration ID: R1114115"
191,AI DATA SCIENTIST (GENERALIST),AMARIS.AI PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesWe are looking for exceptional Data Scientists to embark on our journey to deploy world class deep learning and machine learning algorithms.
  The Data Scientist should have a graduate degree in Computer Science, Statistics, Deep Learning or Machine Learning and a strong background in statistical methods such as Bayesian statistics, time series forecasting, and feature engineering. Candidates with an undergraduate degree and a demonstrable track record in these domains are encouraged to apply.
 If you have a passion for building state-of-the-art deep learning and machine learning models, this is your opportunity. RESPONSIBILITIES   Implement state-of-the-art deep learning and machine learning models
   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions   TECHNICAL SKILLS   Comfortable with core machine learning algorithms implementation and theory   Advanced in scripting languages (Python, R and UNIX Shell), Git project management, deep learning frameworks (PyTorch /Keras / TensorFlow..), and programming skills (Java or C++)   Can communicate clearly and cogently on concepts, processes and algorithms used   Ability to work in time-sensitive environments and to approach problems from different angles   Deep learning experience   DIFFERENTIATING FACTORS   A vibrant Github account with open-source repositories useful to the community   Experience at a corporate data science team, financial/investment analytics entity, or hedge fund
   Work with alternative data (e.g. news, social feeds, etc.)   A top ranking in online AI competition platforms such as Kaggle   Requirements  Implement state-of-the-art deep learning and machine learning models
   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions  "
192,"Senior Associate / Associate, MIS Analyst, Group Consumer Banking & Big Data Analytics Tech (180002T5)",DBS BANK LTD.,"$4,000to$8,000Monthly","Roles & Responsibilities Drive and deliver enterprise scale transformation programs and high priority strategic projects
 Responsible for project delivery on time, on budget and with the right quality Foster partnership with stakeholders from business and support units, technology counterparts and vendors to articulate project objectives, develop and execute project plans Manage effective project and program level communications across all stakeholder groups (Business, Operations and Technology), at various levels of technical detail Drive continuous improvement in the way we deliver to our Business. Ensure best practices are in place for project execution and management Effective problem solver, with excellent quantitative techniques and good communication / interpersonal skills.  Requirements Qualified professional with a University degree or equivalent Strong hold in Excel (macros/VB script), Power Point or equivalent presentation software, Visio or equivalent planning tools and preparation of MIS & management reporting Familiar with the Agile delivery methodology Very hands-on, detail-oriented in every aspect of the project, but able to handle ambiguity Excellent communication and presentation skills, both verbal and written, able to adapt to various levels of detail A natural team worker with excellent interpersonal skills, to facilitate working within the broader T&O department and with business partners and vendors Result-driven, self-starter and independent worker Effective with working in a fast-paced, often unstructured environment Energetic and energizing character, with a strong ability to manage by influence Relevant experience in analysis, preferably in banking, finance, digital and/or consulting industries Strong modeling, analytical, planning and organizing skills Ability to take initiatives and drive strategic projects; a good team player "
193,Data Scientist,KKT TECHNOLOGY PTE. LTD.,"$3,400to$6,000Monthly","Roles & Responsibilities Responsibilities  Develop predictive models on clinical and healthcare related datasets to address various business problems of healthcare and pharma clients through leveraging advanced statistical modeling, machine learning, or data mining techniques Engage in both exploratory data analysis to identify trends and predictive data analysis to solve problems Understand client needs, frame a problem in terms of application of data science and create a roadmap to execution Learn about new and varied disease conditions and ability to communicate with subject matter experts Create visualizations to effectively communicate the insights both internally and externally for both scientific and business audience  Requirements Requirements Minimum  Deep understanding of statistical modeling, machine learning, data mining concepts, optimization etc. Experience with analysis tools (Python, R, etc.) Proficient in one or more programming languages such as Python, Java, C/C++, Matlab Familiar with one or more machine learning and statistical modeling tools such as R, Python scipy, scikit-learn, TensorFlow etc. Strong analytical and quantitative problem solving ability. Excellent communication, interpersonal relationship skills and a strong team player  Preferred  PhD or MS in Computer Science, Physics, Engineering, Statistics, Applied Math, Bioengineering, Bioinformatics or related field Prior experience in using predictive modeling or data driven analysis in biological or healthcare related data Proficiency in programming languages like Python, Java etc. Experience in applying predictive modeling in consulting or industry setting Knowledge and experience of working with relational databases and SQL Experience with software development tools like linux command line utilities, version control systems (git strongly preferred) and test driven development  Perks  Ground floor opportunity with the team to shape the strategic direction of the company The rare opportunity to change the world such that everyone around you is using the product you built. We're not just another social web app, we're helping real people and reinventing healthcare globally. Sharp, motivated co-workers in a fun office environment  Bottomline  You have to be ready to hustle! We move super fast. We work at an ambitious scale. You must be ready and excited to learn on your feet and help build next generation global healthcare company. "
194,Data Analyst,SINGAPORE EXCHANGE LIMITED,"$3,500to$7,000Monthly","Roles & ResponsibilitiesShort overview on the Unit/Team Business Management team drives the business growth and development of the various asset classes and business functions within the Equities & Fixed Income (EFI) business which includes Equities and Debt Capital Market, Securities and related Products, Trading and Post Trade as well as Fixed Income Trading. The team, which acts as the business management function for EFI group, (i) drives the desired business growth from the formulated strategy and business, and (ii) develops business intelligence and insight to enhance our business value proposition. 
 Job Description  Key Responsibilities  Design and deliver projects with analytic methodologies to solve business objectives Identify critical business metrics to measure the performance of the business initiatives Build dashboards and automated reports on critical business metrics and maintain existing data dashboards that enable continuous monitoring of business performance Analyze trading behaviour of different market participants Track the performance of individual equity product to drive market liquidity  RequirementsTechnical  Degree in Quantitative field 1-3 year experience in data analytics and ability to manipulate large data-sets Experience in one of the languages is a must, R/Python/q Proficient in Excel is a must, experience in Bloomberg, Thomson Reuters Eikon Experience in data visualization is preferred  Business  Understanding of Equity Products a must and market microstructure a plus Detailed oriented with rigor analytical and problem solving skills Team oriented and collaborative Skills in translating analytics output to actionable recommendations Exhibit intellectual curiosity and strive to continually learn Develops business cases to illustrate the return of business initiatives Takes ownership of assignments and able to work independently Resourceful and willing to learn actively "
195,"AVP  /  Senior Associate, Data Scientist, Risk Management Group (180001O1)",DBS BANK LTD.,"$6,000to$11,000Monthly","Roles & Responsibilities Work with Credit and Business teams to define the problem statement and develop solutions with advanced analytical techniques to address key challenges Work with data analyst, IT and operations to identify, process and wrangle the data Design experiments to demonstrate business value of analytics solutions. Including testing the solution with real data and quantify business impact/benefit Implement successful experiment to production Create reusable assets and share learning with others  Requirements Degree in computer science, statistics, or other quantitative fields with at least 3 years of industry experience developing data science solutions, or at least 6 years strong industry experience with Degree in Quantitative field. Must have excellent problem solving skills Experience in machine learning with excellent data processing and data engineering skills. Familiar with standards for model development Have developed and implemented industry machine learning solutions Highly proficient with programming in SAS or R Good communication and presentation skill "
196,Data Scientist,SHOPEE SINGAPORE PRIVATE LIMITED,"$3,800to$7,500Monthly","Roles & ResponsibilitiesResponsibilities:   Develop and enhance data infrastructure using frameworks such as Hadoop, SPARK and Flume Design and build new data models and architects that will provide intuitive analytics Design and build reliable data pipelines that will efficiently move data to our Data Warehouse Design and develop new systems and tools that will enable teams to utilise, understand and process data at faster speeds  
   
 RequirementsRequirements:   Minimum B.S. degree in Computer Science or a related technical field Excellent communication skills with the ability to identify and communicate data driven insights 2+ years of Python development and Unix/linux system experience 2+ years of SQL (Mysql, Mssql, Hive, etc)
experience You must also possess at least 2 of the additional requirements as below 2+ years of working experience in software development/programming in one of Java, C/C++. OS environment: Linux/Unix 2+ years of working experience with distributed databases or distributed systems 2+ years of working experience with dimensional data modelling & schema design in Data Warehouses 2+ years of working experience working on BigData analytics pipelines (Hadoop, Hive, ETL, RDBMS-Hadoop data management tools like Sqoop)  
   
"
197,Scientist (Data Analytics /  Deep Learning)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a Scientist who is highly motivated with a passion for machine learning, statistical modeling, and data visualization technologies to join our research team. Successful candidate is expected to contribute positively to the growth of the data science field, work effectively in a team environment, and maintain high productivity and work quality. In this role, successful candidate will interact with a team of experts in machine learning, deep learning, database management and distributed system teams, and work on all aspects of the design, development, and delivery of machine learning solutions. This may include, but is not limited to, the following:  Developing, enhancing, automating and managing analytics model Creating visualizations to unveils insight faster and effectively Develop practical data-driven solutions Perform data cleanup, normalization and transformation and examine data from multiple diverse data sources Process optimization design based on historical data Ensure the integrity and security of institutional data  Requirements PhD in Computer Science, Mathematics and/or statistics degree, electrical engineering, physics, civil engineering, chemical, biochemical engineering, with experience in data analytics Possess minimum 1 year of relevant experience Expertise in problem formulation and solving Experience working in a field related to statistics or data mining Experience performing data manipulation and pattern analysis Experience in applying machine learning algorithms Proficient in multiple programming languages with particular emphasis on Python, R, Matlab, Java and SQL Experience in working in a cross-functional team environment with multifunctional stakeholders Excellent written and verbal communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
198,O&T - ESST Data Fabric IT Business Senior Analyst Singapore -18028449,CITIBANK N.A.,"$6,666to$11,208Monthly","Roles & ResponsibilitiesOverview of Citi: Citi, the world leading global bank, has approximately 200 million customer accounts and a presence in more than 160 countries and jurisdictions worldwide. Citi provides consumers, corporations, governments and institutions with a broad range of financial products and services, including consumer banking and credit, corporate and investment banking, securities brokerage, transaction services, and wealth management. Citi enables clients to achieve their strategic financial objectives by providing them with cutting-edge ideas, best-in-class products and solutions, and unparalleled access to capital and liquidity. Job Description Team/Function Overview  Markets Data team is building the next generation Data fabric to solve for Business, Analytics and growing regulatory needs. Vast amounts of data assets have been accumulated through the years. Data fabric built on emerging technologies will facilitate the data being inspected, cleansed, transformed for support decision-making This job involves being part of a dynamic team and contributing towards software development of core components within the next generation Big Data Platform.
 The ideal candidate will have an eye for building and optimizing data systems and will work closely with our systems architects, data scientists, and analysts to help direct the flow of data within the pipeline and ensure consistency of data delivery and utilization across multiple projects  Role / Position Overview 
 The Decision Support Framework (DSF)  Responsible for the provision of real-time and historical market and order analytics. The DSF team is primarily focused in the niche big data technology, KDB+, developing, implementing and maintaining such solutions.
 This position is for a developer within the APAC Decision Support Framework development team. The main objective of the role is development, implementation and support of a range of Trading Analytics applications including pre trade, post trade and market data analytics. Significant development in the KDB Q language is part of the role. It is also required the candidate has basic understanding the other open source languages like Java and Big data frameworks primarily running on Unix and Linux OS. The role will encompass a level of client liaison in Globally in order to define business requirements, and to ensure a consistent global approach is taken to meet long term strategic system roadmap needs in these areas. An important aspect of the role will be to participate in all the global technology projects.  Key Responsibilities: The role will include but not be limited to the following:  Work closely with the technological partners and Business to develop applications related analytics and Business data analysis Analyze and develop and Implement Technical solutions Adaptability, tailoring testing solutions to constantly evolving requirements Collaborate with Business and Support teams to clarify specs, raise issues/concerns and identify risks throughout the software development life cycle Ability to read through Business requirements and construct application in KDB/Java individually or as group Foster a spirit of innovation and collaboration in regards to development. Actively contribute to ongoing process improvement to help streamline the development life cycle Collaborate and partner closely with program managers, development leads, test leads and production support teams to ensure that software is tested to highest quality Be an active participant in engineering excellence in continuous improvement of dev ops area that will result in productivity increase for the group  Development Value: Candidate has the opportunity to be a major contributor to the Citi Markets Data Strategy and contribute towards the goal of increasing revenue using key metrics for decision making. The candidate will work with bright and innovative individuals both on the business and technology side and the successful candidate can make a significant difference to the business performance. 
 
 
 
 RequirementsKnowledge/Experience:  5-8 years of experience within the technology or banking industry Experience of developing supporting q/KDB+ solutions Extensive experience in developing automated testing solutions for both for GUI and non-GUI testing. Strong knowledge of full software development and testing lifecycle.  Skills:  q/KDB+ programming language experience Strong development lifecycle understanding and capability Skilled in the use of industry standard functional Test tools e.g. JIRA Scripting (Shell) Unix (preferably Linux)  Qualifications:  Graduate degree in Computer Science, Information Systems or equivalent quantitative field and 5-8 years of experience Exceptional candidates who do not meet these criteria may be considered for the role provided they have the necessary skills and experience.  Competencies  Strong analytical and problem solving skills Excellent verbal and written communication skills Extensive knowledge of industry standard Testing tools Goal and deadline oriented Must demonstrate initiative to react to changing priorities Self-motivated individual and creative thinker who will take ownership and accountability  What we Offer  As well as a competitive salary and consideration for a yearly discretionary bonus Citi offer 23 days paid annual leave Medical insurance with Aviva Healthcare In addition, we offer a competitive maternity, paternity and adoption leave scheme and employees also have the option (provided they have a student loan from the Student Loan Company) to divert saver and company match contributions to their student loan. We pride ourselves on our ability to offer employees a number of lifestyle benefits including; on site restaurant and coffee shops, online shopping and concierge service and subsidized clubs and societies Our select benefit package offers you the opportunity to customize your benefits according to your own lifestyle preferences and includes corporate discounts, memberships and a range of additional extras Our vast range of diversity networks and on site multi faith room demonstrates Citis commitment to growing a diverse workforce  To apply online via the careers section of Citi E career website, please click via the link below: https://citi.taleo.net/careersection/2/jobdetail.ftl?lang=en&job=18028449"
199,information technology,SGTech,$1to$1Monthly,"Roles & ResponsibilitiesTalentGuru
(www.talentguru.org) is a skills-based career development platform
powered by data science that focuses on creating a sustainable job market for Singapores Tech industry with the aim
to address the challenges of a skills gap and talent shortage in the digital sector.
 Explore skills required for each job position and map your career pathways. Internship and career opportunities are available for tech and non-tech positions eg. Business, Marketing. Some of the hiring companies include Shopee, Mining Rig Club, CrimsonLogic, Hanalytics, NTUC LearningHub and more. Many startups and SMEs in the tech industry are hiring for the below positions. TECH INTERNSHIP (Skills required)  Associate Information Security Consultant (ASP.NET, C#, VB, PHP, JAVA, SQL database etc) Full-stack Developer Intern (Javascript, HTML, CSS, React JS, Photoshop) Web Application Developer Intern (Angular JS, Java, Content Management Systems) Android Developer Intern (Java, Android Development, JavaScript) Network Engineer Intern
(VPN, server, IT) Web Development Intern (PHP, MySQL, CSS, HTML, JavaScript, Object Oriented programming) Web Developer Intern (Java, JavaScript, HTML, CSS) Junior IT Engineer (Hardware installation, troubleshooting, computer maintenance and repair) IT Generalist Intern (Basic HTML, Basic JavaScipt) Software Engineer Intern (Java, JavaScript, HTML, PHP) Robotic Process Automation Associate (C#, Basic, HTML, CSS, JavaScript) Cybersecurity Research Intern (Networking, Cyber Security) Video Content Intern (After effects, Photoshop, Adobe Illustrator)  
 FULL-TIME TECH CAREERS (Skills required)  Software Engineer (React, Nodejs, IndexedDB, Redux) Systems Engineer (AWS Cloud, Linux systems) Desktop Deployment Engineer (Microsoft Windows, IT product knowledge) IT Network Technician (PC Troubleshooting, Operating system, Network) Junior Accounts Manager [S1]
(CRM software, MS Office) Product Management Associate (UI, UX, Product design, Project Management) Data Center Site Lead/ Manager (Linux, Windows, Networking) Mobile App Designer (iOS/Andriod web designing, HTML, CSS, JavaScript) Junior Programmer/ Software Developer (C++, C, Java, Python, JavaScript, PHP) IT Executive (PHP, MySQL) VR Gameplay Programmer (C++, C#, Java, Net) Mobile App/ Web Developer (ASP.NET, HTML, HTML5, CSS, JavaScript, PHP) Data Analyst (Python, SQL) Data Scientist (Applied Mathematics, Analysis) Technical Support Engineer (Server administration, IT Support)  And more... RequirementsFor more details, visit talentguru.org or write to talent@sgtech.org.sg if you are unable to find an internship to your preference."
200,Required Data Scientist,PATH INFOTECH PTE. LTD.,"$6,500to$8,500Monthly","Roles & Responsibilities Perform the full life-cycle of data analytics activities, including conceptualization, visualization and operationalization
 Perform data capture by defining requirements or developing adaptors to pull data from various control systems Design rich Data Visualization Conduct statistical modelling and employ deep machine learning techniques to define and build models  Develop prediction systems and design effective data delivery mechanisms 
  Degree in Software Engineering or equivalent, with specialisation in Data Analytics / Machine Learning Minimum 2  3 years of relevant experience in Java software development Minimum 1  2 years of relevant experience in machine learning pipelines, data ingestion, feature engineering, and model selection, training, validation and deployment Familiarity with Agile software development methodology and coding in various languages (Java, Python, #C) Proficiency in database management (Hadoop, NoSQL ,etc)
 Ability to derive actionable insights from large data sets  Ability to communicate, present and influence internal and external stakeholders 
 Requirements Perform the full life-cycle of data analytics activities, including conceptualization, visualization and operationalization
 Perform data capture by defining requirements or developing adaptors to pull data from various control systems Design rich Data Visualization Conduct statistical modelling and employ deep machine learning techniques to define and build models  Develop prediction systems and design effective data delivery mechanisms 
  Degree in Software Engineering or equivalent, with specialisation in Data Analytics / Machine Learning Minimum 2  3 years of relevant experience in Java software development Minimum 1  2 years of relevant experience in machine learning pipelines, data ingestion, feature engineering, and model selection, training, validation and deployment Familiarity with Agile software development methodology and coding in various languages (Java, Python, #C) Proficiency in database management (Hadoop, NoSQL ,etc)
 Ability to derive actionable insights from large data sets  Ability to communicate, present and influence internal and external stakeholders 
"
201,MCT MQE Fault Detection / Data Engineer,Company Undisclosed,"$4,000to$8,000Monthly","Roles & ResponsibilitiesJob Description 
 As an FDC Engineer, you will responsible for, but not limited to, developing/improving/maintaining Fault Detection and Classification strategies at our manufacturing facilities across Backend Operation, understanding system dependencies, project planning, engaging in cost reduction efforts, and actively participating in Environmental, Health, Safety and Security procedures. You will work with Manufacturing Central Team (MCT) Engineering and Backend Site Quality teams to provide direction and assistance with FD functions.
 You will help to coordinate and implement FD control systems across multiple international facilities with the aim at reducing overall product & process variation which will result in higher process margins, increased yield and reliability with lower costs. 
 It is highly desirable if the applicant has experience in using machine learning and statistical techniques to create state-of-the-art data products (decision support and decision automation data systems), utilizing extensive and diverse Big Data sets from our manufacturing teams. 
 Responsibilities and Tasks (include, but not limited to):  Deploy standards and Business process for Fault Detection and Classification for Semiconductor Manufacturing Facilities: Identify Fault Detection and Classification Dependencies Fault Detection and Classification for specific manufacturing area Implement, comply, maintain and improve established standards Test and implement system changes and improvements Manage the implementation of controlled modifications using Change Management methodologies, from network support and direction drive perspective. Support sites on: Deployment and on-going maintenance of FDC strategies (data collection, summarized indicators, limits, OCAPS, etc.) using AMAT E3 in an effort to minimize risks of excursion and scrap Troubleshoot strategy/tool/system related issues, including proper documentation, escalation, and follow-up to completion Monitor strategy performance and effectiveness and identify opportunities for improvement Define and deploy worldwide FDC best known methods (BKM), business rules and standards, and change management procedures Align, share, and review FDC strategy best practices and excursion/scrap prevention with world-wide sites FD counterparts. Frequent interaction with customers, and general support to explore and analyze and promote the use of FDC data Understand and Maintain System Dependencies: Evaluate and monitor user lists for program access in compliance with established product integrity, security, and intellectual property rights protection standards Facilitate Fault Detection and Classification
 Coordinate Fault Detection and Classification tasks utilizing various programs, including MAM, Process Control Systems, Statistical Process Control, Advanced Process Control, Fault Detection and Classification, GEM/SECS/GOUI, Engineering Change Notice, and Global Conversion Process Project Planning Act as a liaison between information systems, production area management, and engineering management in matters concerning Fault Detection and Classification Anticipate or diagnose automation issues across multiple equipment types within a given manufacturing area Define and deploy projects that have impact on a global scale Organize and execute project plans efficiently and effectively Cost Reduction
 As a Team Member, you are responsible for reducing costs associated with your area. This responsibility may include owning and completing cost reduction projects, identifying cost effective sustaining/manufacturing improvements, minimizing regular expenditures, and helping to promote a cost-conscious culture. Ensure that effective requirements, standards and procedures exist for functional areas and sites to accomplish given manufacturing operations Provide direction on the facilitation of the practical application of FD within Backend Manufacturing environment Work with global teams such as Global Quality, Site Quality teams, Operations Central Teams, and IT to assess the compliance of functional areas and sites to global standards Ensure all business needs are properly documented, validated, and escalated as needed. Analyze findings and assess potential problems within functional areas and sites Compile and issue formal reports detailing findings and potential problems Follow up on action items to ensure solutions/corrective actions are implemented Ensure solutions/corrective actions are aligned throughout the backend manufacturing network Ensure BKM sharing and alignment spans across all functional areas and sites regardless of technology and/or site mission differences Facilitate and maintain world class data analysis skill sets and tools for engineering efficiency to support data driven decisions by engineers Provide tactical support to the MFG Sites as required for issues of yield and quality, working with other peer groups RequirementsQualifications:  A working knowledge of a wide variety of applied statistical methods, including categorical data analysis, statistical sampling methodology and applied statistics for quality and productivity improvement, such as SPC, design of experiments (DOE), multiple regression and ANOVA, nonlinear regression, logistic regression, random/mixed/fixed effects and variance components modeling, statistical reliability methods, nonparametric statistics, survey design and analysis, re-sampling methods, mathematical statistics, and others Desire to identify and/or work on data analysis projects that will improve product (NAND, DRAM, etc.) yield and quality, reduce costs and cycle time, and optimize business practices Ability to extract data from different databases via SQL and other query languages and applying data cleansing, outlier identification, and missing data techniques Ability to work with small, big, structured, semi-structured, and unstructured data Ability to teach short-courses in applied statistics to engineers and technical management Capable of visually summarizing and presenting advanced analytical results and monetary benefits to middle and executive management General understanding of the back end operations for component assembly, component test, module/SSD assembly & test, and Finished Goods Experience in the areas: statistical modeling, feature extraction and analysis, supervised/unsupervised/semi-supervised learning. Ability to extract data from different databases via SQL and other query languages and applying data cleansing, outlier identification, and missing data techniques. Strong software development skills. Well versed in Tableau and visualization software, JMP or analytical tools Strong verbal and written communication skills. A strong plus point if the desirable skillsets are available: Machine learning and other advanced analytical methods Fluency in Python and/or R Hadoop (Hive, Spark, HBase) Teradata and/or another SQL databases Tensorflow, and/or other statistical software including scripting capability for automating analyses Experience working with time series data, images, semi-supervised learning, and data with frequently changing distributions is a plus. Program Management:  Able to multitask and adapt to changing priorities Demonstrate ability to move projects effectively through project lifecycle  initiate, plan, execute, and close  while balancing time, cost, quality, scope and risk / opportunity constraints Motivate stakeholders and all project team members to take ownership of project and its success Direct and coordinate the activities of others to accomplish project tasks successfully Prioritize and manage multiple conflicting projects based on Backend and corporate objectives Lead cross-functional initiatives and enable projects that support Company, MCT and site objectives Develop metrics for benchmarking Performance.
 Identify and share BKMs across departments and sites and track compliance in aligning to BKMs 
 Communication:
  Communicate and respond to issues in a timely manner Use active listening skills to effectively communicate with other team members Express ideas and issues in an organized, effective, and respectful manner Use voice, tone, and body language to enhance communication Written communication is complete, concise, grammatically correct, and appropriate for the audience Invite feedback for clarification and self-improvement Demonstrate cultural sensitivity - Show respect for different cultures and languages; learn to pronounce names correctly; speak English slowly and clearly when interacting with non-native English speakers; invite feedback to ensure others understand Use conference call etiquette and enforce during all meetings Be an active participant in all group discussions, meetings, etc (internal and external) Flexible and accommodating but willing to voice opinions and make recommendations 
 Education Required  Minimum B.S. degree in Statistics, Mathematics, and/or Engineering with an emphasis in Applied Statistics 
 Experience Required  Minimum 3 years of experience in semiconductor industry applying a variety of statistical methods, including process control and metrology Experience with R, JMP, and/or other statistical software including scripting capability for automating analyses 
 Workplace 
 Travel Required? Yes Travel Details Periodic travel to MFG sites for cross-training, alignment activities and/or auditing purposes Travel Frequency Not Specified Travel Duration Not Specified Travel Type International"
202,Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$2,500to$5,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for highly-motivated and skilled data engineer to work on a new initiative on developing advanced automatic data pre-processing techniques for facilitating key data analytics applications in various industry domains, including advanced manufacturing and engineering, financial services, healthcare, and urban development. Successful candidate will work with a team of data scientists and data engineers to develop novel methodology for automatic data integrity check, data imputation, and segmentation for structured data and time-series data commonly generated by industry companies. Successful candidate will have the opportunity to tap into a large pool of industrial data from different disciplines and to interact with the companies to understand their real data needs. Successful candidate will also engage in project scoping with industry companies to develop solution to address the data analytics needs. 
 Requirements Minimum Bachelor degree in the field of computer science, computer engineering, mathematics and statistics, electrical engineering, or other data science intensive program. With expertise in at least one of the following areas: data mining and management, machine learning, statistical learning, time-series analytics Possess minimum 1 year of relevant work experience Ability to work independently to translate research ideas into programs with efficient coding Basic knowledge on data analytics, machine learning, data mining Proficient in Python, R, C++ or Java Prior industry experience with engineering, financial services, healthcare, or urban development is a plus Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
203,Data Analyst,FUTURE-MOVES GROUP PTE. LTD.,"$3,600to$3,800Monthly","Roles & ResponsibilitiesYour role as a Data Analyst is to:  Collaborate with the team to provide analytical expertise on consulting projects in driverse areas for clients in both public and the private sector Assist with literature review to provide background research support Undertake and perform a various range of data analysis by applying techniques such as predictive modelling and machine learning Provide accurate and quality analysis, report and dashboards according to the desired standards and project requirements Support to the development and delivery of relevant executive education programme on data skills Engage with clients to understand their needs and requirements Contribute to thought leaderships relevant to data analytics  Requirements Minimum of a Masters Degree in Econometrics / Economics / Statistics or other relevant fields from a reputable institution 2 years relevant working experience is preferred Outstanding fresh graduates will be considered Proficient in Tableau and Microsoft Office Proficiency in the use of statistical software, such as SPSS Familiarity with Agent Based Modelling and System Dynamics would be a strong advantage Familiarity with R or Python is a necessity Excellent interpersonal and written communication skills Passion of learning new skills and acknowledge A team player Familarity with Quantitative Data Analysis and System Dynamics and experience of using Adobe Illustrator would be strong advantages "
204,Data Engineer,GRASSHOPPER PTE. LTD.,"$10,000to$12,000Monthly","Roles & ResponsibilitiesWe seek a Data engineer to support our high frequency trading activities and quantitative research. At Grasshopper we recognize that effective research and trading strategies are built upon solid foundations in data collection, storage and serving. Grasshopper trades at a number of exchanges globally and we are looking for an experienced data engineer to help manage and develop our ever expanding data collection pipelines.  As a Data Engineer, you are expected to build data pipelines that efficiently and reliably move data across systems and platforms as well as the expertise to design and build the next generation of data tools that enable other units to perform research on their data. RequirementsResponsibilities  Implement and maintain data pipelines and the infrastructure required. Perform all needed data cleansing and transformation to improve quality of input for research. Work closely with traders and researchers to consume and analyze data faster and more efficiently. Deploy new data models that provide intuitive analytics across the firm. Manage the entire data processing system and advising any necessary infrastructure changes.  Qualifications:  Extensive development experience in one or more of Scala, Haskell Experience in Prolog Extensive development experience in functional programming Experience in SQL. Experience with data modelling and designing/supporting Data Warehouses. Experience in Game theory Experience working with distributed systems. Experience with machine leanring. Experience with (NoSQL) databases such as hadoop, cassandra A degree (BSc or MSc) in a related field, preferably in Computer Science or Computer Engineering. Minimum 3 years of experience "
205,Senior Data Scientist,SHOPEE SINGAPORE PRIVATE LIMITED,"$9,000to$17,600Monthly","Roles & ResponsibilitiesResponsibilities:   Develop and enhance data infrastructure using frameworks such as Hadoop, SPARK and Flume Design and build new data models and architects that will provide intuitive analytics Design and build reliable data pipelines that will efficiently move data to our Data Warehouse Design and develop new systems and tools that will enable teams to utilise, understand and process data at faster speeds  
   
 RequirementsRequirements:   Minimum B.S. degree in Computer Science or a related technical field Excellent communication skills with the ability to identify and communicate data driven insights 2+ years of Python development and Unix/linux system experience 2+ years of SQL (Mysql, Mssql, Hive, etc)
experience You must also possess at least 2 of the additional requirements as below 2+ years of working experience in software development/programming in one of Java, C/C++. OS environment: Linux/Unix 2+ years of working experience with distributed databases or distributed systems 2+ years of working experience with dimensional data modelling & schema design in Data Warehouses 2+ years of working experience working on BigData analytics pipelines (Hadoop, Hive, ETL, RDBMS-Hadoop data management tools like Sqoop)  
   
"
206,Data Analyst,THE STAKEHOLDER COMPANY PTE. LTD.,"$3,000to$4,000Monthly","Roles & ResponsibilitiesThe Data Analyst is central to the development of the volume, accuracy and quality of the companys core data sets through stakeholder and issue driven research and data collection. Your core tasks will be to: - Collect and evaluate information on stakeholders (individuals and organizations) and relationships - Identify news sources for specific projects, define filter criteria and evaluate relevant news items. Further tasks can be added according to your interests and performance. Requirements
   Excellent problem-solving capabilities and research skills;   An ability to adapt readily and multi-task;   Enthusiasm for elegant, pragmatic solutions;   Motivation, talents, and passion;   Ability to manage a small team and ensure high standards of work;   Strong plus: Technical skills (data analysis, statistics, computer science, engineering background or experience with web technologies, etc.)   Strong plus: track-record in business development or digital marketing   
"
207,Data Analytics Analyst,COMTEL SOLUTIONS PTE LTD,"$6,500to$9,750Monthly","Roles & Responsibilities Perform full life-cycle of Data Scientist / Analyst activities, including conceptualization, visualization to operationalization Primary focus will be in applying data science to solve business problems; data mining techniques, doing statistical analysis, building high-quality prediction systems, and use deep learning techniques Able to understand and solve the business problem by translating into a data model and building insights into an actionable outcome
 Collaborate with cross-functional teams to identify and prioritize actionable, high-impact insights across a variety of customer servicing areas
 Research, design, implement and validate models / algorithms to analyse diverse sources of data to achieve targeted outcomes
 Carry out customer behaviour analytics and deliver actionable insights in real time; through behaviour segmentation, predictive modelling, lifetime value modelling, churn prevention, statistical simulations and what if scenarios  Requirements Deep and practical understanding on implementing high performance, well-behaved analytics applications with a focus on data ingestion, feature engineering, model selection, training, validating and deployment A deep understanding of statistical and predictive modelling concepts, machine-learning approaches, clustering and classification techniques, and recommendation and optimization algorithms Must have excellent Python, R and software development skills Familiarity with Linux based operating system environments Experience with scripting languages (e.g. Python, R, Julia) for data manipulation and statistical computing tools i.e. Spark Streaming (extraction, cleansing, transformation, smoothing, PMML model execution) Experience in working with large datasets through OLAP tools i.e. Druid Experience manipulating structured and unstructured data sources for analysis i.e. Greenplum, SparkSQL, HBase, S3 by using Notebook technologies such as Jupyter and Zeppelin Working experience in cloud based and open source technology components  Interested applicants are invited to apply by clicking upon the link below or by email to recruit@comtel-solutions.com"
208,Data Centre Engineer,Company Undisclosed,"$3,500to$5,500Monthly","Roles & ResponsibilitiesAbout Our Client Our client is a Fortune Global 500 management consulting firm with a well-established market presence in Asia. You will be part of a dynamic and high performing team dedicated to drive innovation and to facilitate their client's digital transformation projects in Singapore. Job Description  Assist in Data Centre site planning, development and delivery of data centre environments, maintaining the highest performance standards and proposing innovative solutions to reduce budget and increase efficiency. Monitoring, escalation and reporting of all customer network, servers, and data centre facilities equipment status and problems. Assist with server rack mounting , network cable patching and patch record maintenance. Provide support for DC related project implementation (migration, decommissioning, etc.).  RequirementsThe Successful Applicant  Bachelor's degree in Computer Science (or equivalent experience). Must have experience including troubleshooting, operation and preventive maintenance of mission-critical facilities and associated MEP components. Understanding of high availability system environments. Able to work rotating 12 hour shifts with occasional overtime.  What's on Offer This organisation is a global brand name, with strong presence in Singapore as their regional headquarters. They have been constantly growing in the APAC region and are one of the most trusted companies globally. The firm is highly focused on on-boarding the right talent to support their growth and you will play a crucial role in leading the business in its next phase of growth. If you are driven, determined and want to fast - track your career, this job will be a good fit for you. You will be a part of a forward-thinking company that values innovation and a progressive mind-set. Contact:
 Rodrigo Narcizo Quote job ref:
4007958 +65 6419 9681"
209,Data Scientist  Marketing (Partner),Company Undisclosed,"$6,000to$10,000Monthly","Roles & ResponsibilitiesAPPLICANTS HAVE TO APPLY VIA OUR WEBSITE: ""http://careers.pageuppeople.com/395/ci/en/listing"" PURPOSE: Partner with the Marketing Business Unit of Anglo American to develop statistical models and machine learning algorithms to extract value from our technical and business data and optimize commercial performance. TYPICAL TASKS:  Partner with the Marketing business to understand the questions they are trying to address to unlock value, and the data they have or need to collect to address the question. (Relevant domains; Trading, Sales, Integrated Sales & Operations (ISOP) teams, finance, risk etc.) Engage on a regular basis to refine opportunities and develop a pathway for value generating data projects for Marketing Provide specialist advice and act as first point of contact for Marketing business data queries Assist Marketing in designing data capture / experimental setups for exploratory work, or changes in process / data capture in existing systems.   Perform exploratory data analysis, using R or Python, and provide rapid iterations of analysis to refine posed problems, and identify potential solutions. Develop statistical models, algorithms and/or machine learning algorithms to analyse data and address a particular business question. Assist and supervise Data Engineers / Developers in developing and deploying production workflows for taking data in real-time or periodically from sites / business functions, passing the data through the developed models and producing the relevant reporting without human intervention.   Work with and support IM on reporting from analytics tools and developed models. Work with and support IM and business functions in architecture of data warehousing and data-lake as required. Research industry trends and identify industry best practices to further progress and develop digital best practice within the Marketing BU Leverage learnings from across commodity marketing teams and functions to create and share repeatable products where appropriate.  RequirementsCAPABILITY REQUIRED TO DO THE ROLE: Formal qualifications:   Required: Bachelor Degree in Physics, Mathematics, Engineering or Computer Science. Required: MSc in relevant field - Physics, Mathematics, Engineering, Computer Science or relevant quantitative finance qualification.  Role-specific knowledge:   Must have experience / professional background working in:   Demonstrated success working with multidisciplinary technical and global teams. Demonstrated success working in a similar professional role in a global organisation Mathematical / statistical modelling Exploratory data analysis Coding (working knowledge of Python and R) Working knowledge of common machine learning algorithms used in regression, classification and time-series modelling   Preferred experience / professional background with:   Demonstrated success working in mining, commodities covering trading, operations, risk management and financial accounting. Experience in marketing / commercial analysis within a large organisation Experience working within Agile project teams / structures Maintain relationships with key internal and external partners including Marketing Digital & Innovation team, Commodity Marketing Teams and functions, Group functions and
 Marketing Information Management team    Any other requirements to perform the work effectively:  Must be fluent in English. Fluent understanding of commodity markets Strong communication skills Domestic and International travel may be required. "
210,Data Science and Analytics Consultants,MARALL SERVICES PTE. LTD.,"$6,000to$12,000Monthly","Roles & ResponsibilitiesWe are seeking experienced Data Science, Analytics, Reporting and Business Intelligence Consultants for roles in Singapore.
 Will be involved in the build out data infrastructure, making available to the business users the right data at the right time, and
supporting the business in big data analytics. Responsibilities of the Data Engineer include:  Administration and monitoring of the EIM systems to ensure EIM operations run efficiently with the desired SLA and security compliance. Monitoring performance and advising any necessary infrastructure changes to the EIM landscape. Work with the infrastructure teams to implement such changes. Design and develop architecture for data services ecosystem spanning Relational, Columnar, NoSQL, In-Memory, Data Warehouses and BI & Big Data technologies. Designing and implementing data pipelines & ETL processes. Design data models for mission critical and high volume data management, real-time and distributed data process aligning with the business requirements. Promote and develop data architecture best practices, guidelines, procedures and repeatable and scalable frameworks. Work with and help business units with tools like Tableau to visualize and create dashboards with the relevant data in EIM. Work closely with our application teams to operationalise & integrate analytics/machine learning models into our production systems.  Requirements BS in Computer Science or other related discipline is required. Advanced degree related to Analytics, Machine Learning & AI preferred. At least 3 years of relevant industry experience in following areas: 	 Knowledge and working experience with Machine Learning, AI, statistical techniques, and information retrieval as well as on data management systems, practices and standards. Knowledge and working experience with at least one visualization tools like Tableau, PowerBI, Qlik, or similar open source tools. Working experience in architecting highly performant databases using RedShift, PostgreSQL and Cassandra or NoSQL. Knowledge & working experience in Big Data technologies like In-Memory, New SQL, NoSQL, Hadoop Hive/Spark, etc. Knowledge & experience in shell scripting, R, Python, Perl, Ruby, or any other scripting language. Should be proficient in at least shell scripting and R or Python. Experience with commercial ETL platforms with in-depth knowledge and understanding of ETL methodology & design supporting data transformations layer. Working experience with Ab Initio would be a bonus.   Strong knowledge and experience with Agile/Scrum methodology and iterative practices in a service delivery lifecycle is a PLUS. Working experience in an AWS or similar public cloud environment is another PLUS. Excellent interpersonal & communication skills and proven ability as a problem-solver.
 "
211,Market Data Business Analyst  /  Project Manager,ALLEGIS GROUP SINGAPORE PRIVATE LIMITED,"$6,000to$9,000Monthly","Roles & Responsibilities Engage customers and operational staff in documenting detailed requrements as we progress through our strategic customer journey. Working with Trade Services management team, implement a PMO framework; build programme-based business plans, project budgets and resource break-down streams that allow investment decisions. Monitor progress and delivery across the portfolio of approved projects and business plans. Manage communication plans across the division and our customers. Provide structured reports to management on programme execution performance, resource management and cost management across the portfolio. Where a vendor-lead solution is appropriate, work with the market data team, engaging with our vendors and sourcing colleagues, to prepare RFIs, RFPs.  Requirements Demonstrated experience in project management and formal project management, preferably with PMP / PRINCE2 qualifications 10+ years experience working in banking environments or other highly regulated environments. 10+ years working in the market data industry, with market data product awareness and exposure to market data contracts and technologies. 10+ years working with market data delivery technologies and associated commercials. Demonstrable experience in executing RFI and RFPs as a market data subject matter expert. Experience in managing resource groups in matrix organisations and in leading teams of less than 5 people. Experience in working with the SDLC and development teams. Comfortable in communicating with SVP, ED and MD leaders.  Preferred Experience  Experience in working with financial sales and trading staff; financial business management is a plus Book keeping or financial accounting knowledge is a plus. Public cloud experience is a plus. "
212,"DATA ANALYST(Tableau, Spotfire, Kibana, Qlikview)",INFOGAIN SOLUTIONS PTE. LIMITED,"$6,200to$7,400Monthly","Roles & ResponsibilitiesJD:  At least 3 - 7 years prior data analytics/science experience, proficient in statistical tools such as Excel Macro and Data visualization tools such as Powerpoint and Sharepoint is a must.  Proven ability to deliver data transformation, visualization and analytics in technology in the banking industry  Proven ability in standardizing and automating data analytic reports, notifications and dashboards  Additional experience in data transformation and data visualization tools such as Tableau, Spotfire, Kibana, Qlikview is a strong plus.  Additional experience in application support environment and understanding of ITIL methodology is a plus  Demonstrate accountability, independent initiatives and willingness to learn, stretch and deliver while having a strong process orientated mindset  Strong team player with good communication skills. Flexible and able to manage time effectively. Able to work with sense of urgency under multiple deadlines and successfully organize and complete tasks with minimal supervision. RequirementsMin 5 years experience with data analytics, reporting related works.  Expert with Microsoft excel (ability to write excel Macros), powerpoint, sharepoint tools is a must  Experience with data visualization tools such as Tableau, Spotfire, Kibana, Qlikview is a strong plus  Personal Skill :-  Independent worker with good communication and interpersonal skills to effectively interact with colleagues and external parties of all levels  Strong team player and willingness to share knowledge  Ability to learn new skills quickly with little supervision  Ability to think out of the box  Able to efficiently and effectively manage work, time and priorities  Ability to handle high stress and pressure situations while continuously delivering  Self-motivating and delivery focused individual  Ability to understand the big picture, yet with an eye for details  can step back and understand the context of problems before applying data analytical skills to create data transformation and data visualization with spot on details."
213,Data Scientist,Company Undisclosed,"$15,000to$25,000Monthly","Roles & ResponsibilitiesWe are a family office focused on investments in the technology space within Vietnam and are looking for a highly experienced data scientist to help us build a data analytics team for our investees in Vietnam. The candidate will be expected to spend a significant amount of time with our investees in Vietnam. In this Role:  Develop strategies to enable data-driven decision-making across the enterprise Establish a center of excellence for data analytics and business intelligence (BI) Set direction for business-based data analysts to adopt data strategies, methodologies, processes, reporting tools, and visualization technologies Collaborate with IT partners to help set direction for the data warehouse team and data-related technologies Teach and enable others to promote and make data-driven decisions, backed by investigation and collaboration through data Ensure that analyses used for financial reporting and legal requirements are valid, traceable, available, secure and consistent Ensure privacy and legal requirements are met in the access and use of data by the internal analytics community Consolidate data analytics throughout the company and set standards for consistent report generation and reporting output, including dashboards Be accountable for consistent and quality data reporting, analytics, and visualization throughout the enterprise Communicate opportunities to optimize results through use of data analytics and business intelligence Demonstrate advanced understanding of the data warehouse discipline, including data lakes, data mapping, data mining, data dependencies, structured and unstructured data, SQL, and ETL Demonstrate advanced understanding of analytics, including predictive modeling, AI, and deep learning Demonstrate knowledge and suitability for an agile scrum development environment Present complicated analytical information in a concise and compelling manner to technical and non-technical audiences Manage others; recruit, develop, coach, and retain staff  
   RequirementsRequired Qualifications:  Masters or Doctorate degree in a related field 10 years of progressive experience managing data analytics and business intelligence at a corporate level 5 years of experience working with emerging data and analytics technologies (i.e. Hadoop, Spark, MongoDB, Azure Data Lake, etc.) Skilled in emerging cloud platforms and development patterns (i.e. AWS, Azure, MapReduce, etc.) Knowledge of some or all of the following disciplines: Machine Learning , Statistical Analysis, Artificial Intelligence, Predictive Analytics Basic knowledge of architecture frameworks (TOGAF, DAMA, etc.) 
 "
214,Senior Research Engineer (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$3,400to$6,800Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg The project focuses on data management systems, data engineering solutions and deep learning systems for radiology applications. Candidate should have demonstrated interests or experience in: 1. Experience in the execution of translational projects focused on development, testing and deployment
 2. Big data analytics and data engineering 3. Experience with biomedical datasets, in particular medical images 4. Business analysis skills and/or past work with/in clinical partner institutions 
The position entails working in a multi-disciplinary business analytics translation group alongside machine learning and deep learning teams that are closely collaborating with clinical and industry partners on impactful projects that will translate research to deployed technology. Requirements Minimum bachelor degree in computer science, computer engineering, mathematics and statistics, data science intensive programs, with expertise in one or more of the following areas: data mining and management, machine learning, time-series data analytics, etc. Minimum 2 years post completion of last degree Experience in clinical research environments is a plus Excellent knowledge of a programming language such as Node.js., java or C++
 Proficient in Python Good knowledge on data analytics/ machine learning/ data mining and experience in solving real-world data science problems Able to deliver under tight schedules Good team player with both research and engineering ethics Good interpersonal and communication skills Prior experience with NLP is a big plus Prior experience with medical image processing, clinical informatics systems and software platforms is a big plus  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
215,Research Data Scientist,TECH IN ASIA PTE. LTD.,"$4,000to$6,000Monthly","Roles & ResponsibilitiesTribe is a decentralized protocol developed with a mission to help leaders build and sustain great communities around the world - communities that are economically sustainable, decentralized, and autonomous. We are a looking for a research data scientist to help us experiment and implement policies to keep the community economy healthy.  To experiment math formula to compute content quality scores and rewards
 To research and apply data science methodologies on token economy To analyze data and work with our team to implement short/long term changes to increase/decrease economic factors to create a healthy economy To test and repeat To put executions into code and production whenever required
  Requirements PhD in Mathematics or Economics At least 1 year working experience in the technology/internet sector Research and data driven. Understands experimental design Ability to think critically and in a computational way. Able to code is a huge plus Understand blockchain and its impact to the world "
216,"Data Analyst, Pricing Analytics",Company Undisclosed,"$4,000to$5,000Monthly","Roles & ResponsibilitiesWe are seeking a Data Analyst with experience working on academic or industry projects running predictive, prescriptive and descriptive analytics. Your role is to provide accurate, timely, relevant and quality analysis for a dynamic business. You will be reporting to Senior Analytics Manager and offer effective reporting, insight and analysis for multiple stakeholders, internal clients, locations and priorities. You will be working hands-on and delivering flexible solutions ensuring stakeholder satisfaction  As Data Analyst, you will be responsible for:  Advanced analytics, machine learning and dashboard building Liaise both internally within the team as well as externally with business stakeholders for completion of data analytics and reporting. Support the development and testing of hypotheses across all functional data sets supplied by the business Implementing and analyzing algorithms that will substantially impact the companys understanding of its data Support the proof of concept, and development of tools and applications Work with the manager to define key questions and projects that will transform the business This is a contractor role renewable on an annual basis This position will be based in Singapore  
   Requirements
  Master or Bachelors degree in Analytics, Computing, Engineering, IT, Math, Economics, Statistics, Sciences or other technical discipline; Expert knowledge of R programming and Qlik Sense; VBA / Python / SAS EM / SAS EG experience is desirable; Ability to understand and extract data from large and complex data sets (structured & unstructured) Basic knowledge of data quality measurements, methodology and reporting tools Basic knowledge of data management Basic knowledge of statistical methods and machine learning Strong results driven personality, with a high level of enthusiasm, energy and confidence Excellent analytical, communication, organizational and presentation skills Ability to demonstrate flexibility and integrity: be able and willing to work hands on, independently or with a small team "
217,Big Data Software Engineer,ADECCO PERSONNEL PTE LTD,"$6,000to$9,000Monthly","Roles & ResponsibilitiesThe department is responsible for development and maintenance of Risk and Finance applications used by worldwide users covering Market Risk, Counterparty Risk, Finance domain. The applications are in-house developments with a mix of Microsoft and open source technologies.  The open position is to join one major investment project to tackle the regulatory requirement by redesigning information system platform to be global and adaptable enabling automated reporting and real-time processing and monitoring. The project will transform application landscape and bring it to the next level.  Main Responsibilities:  Lead technical study into a propose solution, while involving expertise from infrastructure big data expert, business analyst requirement Document proposed design and develop the solution Implicitly ensure all CI-CD artefacts are part of the solution Perform code review while fostering knowledge and coaching best practices to team members Interact and provide reporting to project managers Monitor technical risk and escalate appropriately to management  The position requires autonomy and reliability in performing duties with initiatives and leadership when it comes to all non-functional deliverables such as testing tools, mocking objects, production monitoring concerns, quality control including performance and load testing. Requirements At least 7 years in Software development At least 6 years in Java/J2EE development At least 4 years experience in streaming solution Hands on Data ingest and data processing technology like Spark streaming and Spark Hands on Messaging systems like Kafka, Flume or ActiveMQ, MQSeries or RabitMQ Hands on knowledge on Hadoop (preferably Hortonworks distribution) - HDFS, HBase, Hive, ORC/Parquet Build tool - Maven/sbt/ant, UML, Restful web services, Jenkins/Team City, Source management  SVN/GIT, TDD using Junit, Jira/QC  Good to have:  Solution design using proven patterns, awareness of anti-patterns, performance tuning, especially in streaming Knowledge of tools like Phoenix, ElasticSearch, Sqoop, StreamSets are good to have. Basic understanding of finance and investment banking  Other Professional Skills and Mind-set  Excellent written and verbal communication skills for both team mates and management Strong analytical and problem solving skills Proficient software development life cycle Appetite to follow technology trend and participate to communities  Prepare your resume in word document (please include your current salary package with full breakdown such as base, incentives, annual wage supplement etc.) and expected package with your notice period (Including leaves to offset) and email it to TechnicalStaffing@adecco.com All shortlisted candidates will be contacted. Wai Yun Wen EA License No: 91C2918 Personnel Registration Number: R1330726"
218,Data Engineer,U3 INFOTECH PTE. LTD.,"$6,000to$9,000Monthly","Roles & Responsibilities Constructing data pipelines. Building APIs for data consumption Supporting the Data Platform Continuously monitoring and testing the system to ensure optimized performance  Requirements Experience on with visualization tools (tableau) Experience with data management tools (Ab initio) is required 5+ years of associated work experience in a relevant role Excellent interpersonal communication skills to explain complex technical topics in an easily digestible manner Advanced SQL database management is a plus. Understanding of file transfer solution (CFT, sfTP, MQ, kafka) Technical expertise regarding data models, database design development, data mining and segmentation techniques. Strong knowledge and experience with reporting packages/tools (tableau etc.), databases (SQL etc.), programming (Python, R, JavaScript or ETL frameworks). Knowledge of statistics or experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.). Adept at queries, report writing and presenting findings. Working knowledge in any analytical tools like Alteryx, Dataiku.  Working knowledge of Hadoop, MapR and Machine Learning techniques are desired."
219,Data Analyst - Gaming attachment 8 Months cambodia,THE SUPREME HR ADVISORY PTE. LTD.,"$3,000to$6,000Monthly","Roles & Responsibilities Conduct in-depth product data analysis for the game  Identify problems affecting the performance of the game in a clear manner with proper documentation  Regular checks on the functionality of the game Requirements











 Comfortable with being based in Cambodia for 8 months [accommodation, meals, and living allowances will be provided on top of salary 
  1 year of experience in game planning  Experience in managing operations for at least 2 games  Strong in logical thinking, communication and coordination  Sensitive to digital changes  Strong knowledge of Microsoft Excel  High level of initiative and development potential.  Dares to take on a project head on and strong team spirit  Able to work overseas for a few months [expenses are covered, and additional allowances will be provided]."
220,Reference Data Business Analyst,BLUECHIP PLATFORMS ASIA PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesAn established firm is seeking a potential individual who has sound expertise and understanding of market data and pricing data. Offering an opportunity to play a vital role in being part of an establish team covering all aspects of reference data, business analysis, change management and fast tracked his/her career in a highly professional and leadership-oriented platform. 
 Job Responsibilities  Change management in market data cost review  Gaining buy-in from COO/Business Heads on current spend and potential areas for savings  Project managing displacement users from requirements gatherings via surveys, trials preparation, trial feedbacks and regular updates to stakeholders.  Ensuring successful trial sign off by resolving users issues or escalating it for enhancement  Workflow and product knowledge of Financial Market, Wealth Management, Operations, Compliance divisions  Re-engineered the Product and Pricing Data team processes  Created a generic feed for pricing
 that improved the process  Continuous involvement in the Equities build-out project  Built the connectivity between the main product data depository and downstream systems used for trading and settlement  Created the Target Operating Model for the Wealth systems to leverage on the data from Investment Banking strategic product database  Handled mandatory vendor change projects  	
  Requirements/Qualifications  Holds 8 years of experience in Reference Data with huge contribution to process and system enhancements.  Experience in Project Management and Business Analysis with focus on systems integration, regulatory, process re-engineering and build-out projects in Wealth management, Investment Banking and Asset Management  Knowledge in Software Development Lifecycle, Agile methodology.  Strong Equities, Funds and Equity Derivatives product knowledge  Holds problem-solving, excellent analytical skills and communication skills, strong leadership skills, attention to detail and innovative solutions.  Ability to adapt to a fast-changing environment and a multi-cultural organization.  Good interpersonal and communication skills.  Requirements**Apply here** https://www.bluechipcareers-asia.com/jobDetails/3865/reference-data-business-analyst For more Banking and Finance Jobs, visit us at https://www.bluechipcareers-asia.com/"
221,Data Scientist  /  Customer Analyst x 5,Company Undisclosed,"$5,000to$10,000Monthly","Roles & ResponsibilitiesPrimary Responsibilities  Lead the new Data Science capability to create solutions to optimise business processes and the customer experience Contribute to a data driven, test & learn and rapid iteration culture Present concise findings to senior management with actionable recommendations Innovative application of Data Science to solve real-world use cases Conduct research and integrate suitable tools for the team Prior programming and modelling experience is essential Flexible, proactive and able to work under fast paced environments. Excellent analytical skills in problem identification and resolution
 Integrate with core systems, utilise data from inside & outside of the organisation Lead and manage the relationship with 3rd party vendors, to ensure the seamless integration of their solutions into the platform Partner with Singapore based research institutions, and further education institutions to develop IP which contributes to the development of Data Science solutions. Evaluate all activity in against agreed KPIs Demonstrate long term value creation for Customers.  Requirements Masters Degree holder  Statistics/Computer Science/Mathematics.
PhD is an advantage. 8+ years experience (minimum of 5 years experience within a commercial role) Strong command of a number of big-data technologies, statistical analysis tools and methodologies Strong user of data to understand performance and to make recommendations to the business Possesses excellent communication, interpersonal, project management & leadership skills "
222,"Data Scientist, APAC (Singapore)",Company Undisclosed,"$8,000to$12,000Monthly","Roles & ResponsibilitiesWe are considering candidates for both junior and experienced positions. Who we are The Data Science team based in Singapore has the charter to understand user behavior and accelerate user growth for our platform, especially in international markets. We work on a mix of longer term analysis (such as how can we be smarter about how we send emails and notifications to our users; or how can we measure the impact of various user acquisition efforts) and shorter term tactical work (such as opportunity sizing for certain campaigns). The common thread between all the analysis we do is to seek to have a better understanding of how our users are engaging with our products. What youll do Your work with our large amounts of structured and unstructured data to understand how our users are using the product, and communicate these insights with stakeholders (product managers, executives, business decision makers etc). For more experienced hires, you will own important project areas from start to finish. That work includes defining an important roadmap of data science work and executing it. You are highly technical and hands on but you wear a product manager hat easily to make your projects successful. Who you are  You care about people: You have fundamental respect for all people You are in awe of the ability to understand and help 100s of millions of people  You are great at:  Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto Exploring and visualizing data to drive insights Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their social media posts and their interests. Designing and implementing metrics that help teams focus on what to optimize for Understanding A/B testing and are able to statistically interpret experimental results Working with Product Managers, engineers and designers to understand where data can be helpful Transforming complicated problems into simpler, tractable ones Communicating with technical and non-technical stakeholders  RequirementsRequirements:  Bachelors, Masters or PhD degree in Computer Science, Statistics, Math, Engineering, or other quantitative discipline Some experience with one or more object oriented languages like Java, Scala, C++ Some experience with scripting languages like Python or Ruby etc. Some experience with statistical programming environments like R or Matlab Bonus points: Experience with machine learning Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects "
223,Big Data Software Engineer,ADECCO PERSONNEL PTE LTD,"$6,000to$10,000Monthly","Roles & ResponsibilitiesThe department is responsible for development and maintenance of Risk and Finance applications used by worldwide users covering Market Risk, Counterparty Risk, Finance domain. The applications are in-house developments with a mix of Microsoft and open source technologies.  The open position is to join one major investment project to tackle the regulatory requirement by redesigning information system platform to be global and adaptable enabling automated reporting and real-time processing and monitoring. The project will transform application landscape and bring it to the next level.  Main Responsibilities:  Lead technical study into a propose solution, while involving expertise from infrastructure big data expert, business analyst requirement Document proposed design and develop the solution Implicitly ensure all CI-CD artefacts are part of the solution Perform code review while fostering knowledge and coaching best practices to team members Interact and provide reporting to project managers Monitor technical risk and escalate appropriately to management  The position requires autonomy and reliability in performing duties with initiatives and leadership when it comes to all non-functional deliverables such as testing tools, mocking objects, production monitoring concerns, quality control including performance and load testing. Requirements At least 7 years in Software development At least 6 years in Java/J2EE development At least 4 years experience in streaming solution Hands on Data ingest and data processing technology like Spark streaming and Spark Hands on Messaging systems like Kafka, Flume or ActiveMQ, MQSeries or RabitMQ Hands on knowledge on Hadoop (preferably Hortonworks distribution) - HDFS, HBase, Hive, ORC/Parquet Build tool - Maven/sbt/ant, UML, Restful web services, Jenkins/Team City, Source management  SVN/GIT, TDD using Junit, Jira/QC  Good to have:  Solution design using proven patterns, awareness of anti-patterns, performance tuning, especially in streaming Knowledge of tools like Phoenix, ElasticSearch, Sqoop, StreamSets are good to have. Basic understanding of finance and investment banking  Other Professional Skills and Mind-set  Excellent written and verbal communication skills for both team mates and management Strong analytical and problem solving skills Proficient software development life cycle Appetite to follow technology trend and participate to communities  Prepare your resume in word document (please include your current salary package with full breakdown such as base, incentives, annual wage supplement etc.) and expected package with your notice period (Including leaves to offset) and email it to TechnicalStaffing@adecco.com All shortlisted candidates will be contacted. 
"
224,Scientist (Data Analytics)  /  I2R (A*STAR),A*STAR RESEARCH ENTITIES,"$4,500to$9,000Monthly","Roles & ResponsibilitiesAbout the Institute for Infocomm Research (IR) The Institute for Infocomm Research (IR) is a member of the Agency for Science, Technology and Research (A*STAR) family and is Singapores largest ICT research institute. Our strategic thrusts are in the spheres of intelligence, communications and media and our research capabilities are in shared sensor networks, public-public/public-private data-sharing platform, big data analytics and visualization solutions. For more information about I2R, please visit www.i2r.a-star.edu.sg We are looking for a capable and responsible scientist to work on and make contributions in the area of big data management and analytics, spatial-temporal data analytics, predictive analytics in time series data etc. These research areas has wide applications, such as smart city, IIoT, manufacturing, healthcare. 
Successful candidate will be given opportunities to participate in projects bringing innovation to various domain, such as advanced manufacturing and engineering (AME) domains and urban solutions and sustainability (USS) domain, and economic sectors including that of the financial service industry entities. In particular, successful candidate will be involved in the execution of both industry projects and research projects. In addition, the candidate is also required to participate in the drafting of grant proposals and project scoping with industrial partners and/or public sector entities. Overall, as a member of the Data analytics department in I2R, the successful candidate will have ample opportunities doing cutting-edge research, and solve real-world problems in collaboration with universities, industry and/or public sector entities. Requirements PhD in Computer Science, Computer engineering, Mathematics and statistics, data science intensive programs with expertise in one or more of the following areas: Data mining, data management, machine learning etc Entry level candidate with relevant experience may apply Ability to work independently to innovate and develop prototypes to demonstrate the feasibility of research ideas Good knowledge on data analytics/machine learning/ data mining and experiences in solving real-world data science problems Proficient in Python, R, Matlab, C++ or Java Able to deliver under tight schedule Good team player with both research and engineering ethics Good interpersonal and communication skills Prior experience with trajectory data or time-series data is a big plus Good knowledge of big data technology, such as Hadoop, Spark, Storm, is a big plus Prior experience with AME industry is a plus  The above eligibility criteria are not exhaustive. A*STAR may include additional selection criteria based on its prevailing recruitment policies. These policies may be amended from time to time without notice. We regret that only shortlisted candidates will be notified."
225,Research Fellow,NANYANG TECHNOLOGICAL UNIVERSITY,"$4,000to$4,500Monthly","Roles & ResponsibilitiesData Scientist / Programmer for Regional ATM Modernisation Programme Under the Air Traffic Management Research Institute (ATMRI) (http://atmri.ntu.edu.sg/), Nanyang Technological University, you will be part of Regional ATM Modernisation Programme team to perform programming and data analytics for the ASEAN air routes and ATM operations in the region.
  Primary Duties or Responsibilities Specifically, you will  Undertake research and development related to Air-space management & Data Analytics. Development and verification of Concept of Operations. Perform programming for fast time and real-time simulation tools, doing analytics, and building high quality strategic planning system for future for Air Traffic Management (ATM) eco-system for the region. You will provide expertise on mathematical concepts for the broader applied analytics of flow management and inspire the adoption of advanced analytics and data science across the entire breadth of regional ATM system. Conduct stakeholder meetings to solicit input for development of systems. Interact with senior personnel such as project lead and ATC operations specialist on significant technical matters and coordinate with other specialist teams within programme.
 Represent the Institute at regional/global ATM platforms, international forum/conferences. Occasional overseas travel may be required.
  Requirements Doctorate degree in a relevant field. At least 3 years experience in any aviation-related fast-time simulation environment. Knowledge of tools like SAAM and AirTop will be an added advantage.
 Strong programming skills such as Java, C++ and Python Experience in Data Science (knowledge in Aviation / Air Traffic Management)
 Good English writing and communication skills
 Independent and team player
 "
226,Semiconductor Manufacturing Equipment Data Scientist,TOKYO ELECTRON SINGAPORE PTE. LTD.,"$4,000to$7,000Monthly","Roles & ResponsibilitiesResponsibilities To integrate TELs tool and customers quality data to provide statistical or machine learning analysis to improve TELs equipment overall efficiency  To
 partner with customers Data science group
 and TELs process engineers to define problem statements, acquire and analyse data , create visualization to explain the data and to identify sensors of interest that correlate to customer quality data (yield, defect, CD, etch rate etc.,.) Understand the data infrastructures requirements, define the best data storage solution and support TELs development team to design data analytics applications. These applications will extract data ( and images) from relational databases and big data storages, processing and analysing data, calculating summaries and indicators, detecting patterns and finding the root cause, performing commonality analysis and data mining.  
 Requirements
Requirements  BS or MS in Computer Science/Data Science/Statistics or
a related field with at least 3 years of experience Candidates with prior semiconductor manufacturing data analysis experience preferred The candidate must have a strong knowledge in one or more of the following areas: Big Data Technologies, relational databases, machine learning algorithms, data mining, yield analysis, statistical analysis, and image processing. Expertise in Web development, Hadoop, HBase, Java, Python, R and SQL is/are preferred This position requires strong written and oral communication, analytical problem solving, leadership
 and teamwork skills "
227,IT Data Analyst,AGRITRADE RESOURCES ASIA PTE. LTD.,"$3,000to$4,200Monthly","Roles & ResponsibilitiesThe Role The purpose of this position is to assist in design, implement, maintain and support our growing IT infrastructure as well as any IT transformation projects. Some of the work scopes include  Configure and install various network and voice devices and services (e.g., routers, switches, firewalls, load balancers, VPN, QoS) Monitor performance and ensure system availability, reliability and constantly find flaws or room for improvement in the current network system Monitor system resource utilization, trending, and capacity planning Select and implement security tools, policies, and procedures in conjunction with the companys security team Provide Level 1 and 2 desktop application support including office applications Liaise with vendors and other IT personnel for problem resolution Provide IT Support to users and troubleshooting to resolve issues Interpret data, analyze results using statistical techniques, and provide ongoing reports Develop and implement databases, data collection, systems, data analytics, and other strategies that optimize statistical efficiency and quality Acquire data from primary or secondary data sources and maintain databases/data systems Identify, analyze, and interpret trends or patterns in complex data sets Work with management to prioritize business and information needs Locate and execute new process improvement opportunities.  RequirementsIdeal Profile  Diploma in Computer Science or Information Technology or related qualification Minimum 3 years of relevant experience CCNP and PMI certification would be added advantage Hands-on experience with monitoring, network diagnostic and business intelligence tools Strong analytical and problem-solving skills Meticulous, detailed oriented with passion for technology Self-starter with strong communication skills "
228,Walkin interviews 29th June 11:00 AM Onwards,R SYSTEMS (SINGAPORE) PTE LIMITED,"$2,500to$8,000Monthly","Roles & ResponsibilitiesPlease find below active roles for Walk In Interview today at 4:00 PM Onwards  Testing Roles - Manual & Automation / Core Banking
 Net Developer - Jr. to Mid Level Solution Lead Manager -
 Life Insurance
 Business Anlalyst - Insurance Domain is must Report Developer - SSIS, SSRS, Hadoop Application Support - SQL Experience
 Technical Support Engineer - Hardware & Software Java Developer / Java Lead
 - Mid Level Experince with Spring
 Digital Application Manager- Insurance
 PHP Lead Mobile Developer iOS
C++ /C IT Desktop support | IT Heldesk support
 Data analyst- SQL Excel skills
 Project / Program Manager | Infrastructure | Digitalization
  
 
 RequirementsPlease bring along your Resume
"
229,Data Center Support Engineer,SERVLINK TECHNOLOGY RESOURCES PTE LTD,"$2,500to$3,200Monthly","Roles & Responsibilities Perform data daily walkthrough and update client shared database. Monitoring, update and closing of ticket via ticketing system with resolution summary. Using approved tools for incident and problem management, perform IMAC tasks when required. Support hardware replacement and Break-fix.
 Restore on-site equipment back to working status. Media Management. Escort 3rd party vendor to all local data centers (during office hour & after office hour) Perform data center power up/down (PDU), preventive maintenance work on equipment. Manage onsite equipment and update relevant inventory systems. Compile relevant data and statistics for monthly reporting Other ad hoc data center activities as and when required. Other duties and job functions as may be instructed from time to time by the Company and may be transferred from one section to another at the sole discretion of the Company  Requirements Min Diploma in IT or Computer Science or 1 - 2 years of relevant
working experience
 Required to work on permanent night shift (8pm - 8am), shift allowance will be given Working pattern (work 3 days, rest 3 days;
work 2 days, rest 2 days) "
230,Data Analyst,Company Undisclosed,"$5,000to$7,000Monthly","Roles & ResponsibilitiesA MullenLowe Group Data Analyst is responsible for the management of the application of traditional marketing analytics techniques (e.g. marketing mix modeling) to digital marketing data through 3rd party providers. They are also responsible for the management of attribution modeling projects through 3rd party providers, as well as handson development of new analytics products for our clients.  The role requires the day-to-day relationships between MullenLowe Profero and its analytics clients ensuring that all client activity is delivered on time, to budget, and to the highest possible standard of service.  The Data Analyst will also develop short and long-term analytics strategies for our clients. You are expected to bring your own ideas and impact in growing our client relationships and improving our working practices in order to allow MullenLowe Group
to deliver the best solutions to our clients businesses and marketing challenges. RequirementsSkills & Requirements The ideal candidate must have:  Good hands-on experience of performing marketing mix modeling projects for a variety of clients and industry verticals Ability to manage the delivery of analytics projects (using 3rd party analytics providers where relevant) across the full life-cycle, from inception to completion Passion for the application of traditional marketing analytics approaches to digital marketing data Knowledge of algorithmic attribution modeling, and the ability to manage client projects in this area (via 3rd party providers) Strong data management skills, comfort with relational databases, and data management applications /languages such as SQL and Access Good experience with analytical tools such as R, SPSS and SAS The ability to sell analytical and commercial ideas and concepts to non-technical audiences To interpret client business issues and understand which analytical techniques should be applied Capacity to innovate and think creatively with data Comfortable explaining analytical outputs to non-specialist audiences Be at the forefront of analytics knowledge, by keeping up to date with industry news and developments Contribute in developing new products and ways of working that improve MullenLowe Proferos analytics offering Several years experience performing marketing data analysis in a commercial environment Maintain a detailed understanding of the client business and digital marketing objectives Help direct the client to understand the value of analytics and grow the role of analytics in their marketing programs and customer relationships Understand all areas of MullenLowe Proferos expertise and ensure your clients are knowledgeable of our full range of products and services Continuously manage, monitor, and evolve service delivery and profitability, to enable us to fulfil our contracted promises to clients and ensure that we consistently deliver high quality service Be a trusted, knowledgeable source of information and developments in marketing analytics Help in preparation for and attend sales pitches as required  Leadership & Development:  Work with an entrepreneurial spirit to identify revenue opportunities and generate ideas for your clients, within and outside of briefs Inspire clients by demonstrating the capabilities of marketing analytics Be a catalyst for idea sharing and cross-department collaboration to advance the way we work and the work we deliver for our clients Work with an attitude of its up to me to make it happen  Professional Expectations:  Be on time for, and professional in, everything you do, be that meeting a client; delivering to timescales; actively participating, using the right tone; or protecting the clients information/IP or MullenLowe Proferos. Be an excellent communicator and presenter in all forms (in-person, email, over the phone) Complete Time-sheets and status documentation in a timely manner Proactively contribute to a positive team atmosphere and company culture, and generally be a role model for the junior members of the team "
231,Data Sciences & Analytics Engineer,SINGAPORE AIRLINES LIMITED,"$4,000to$8,000Monthly","Roles & ResponsibilitiesSIA has implemented the Enterprise Information Management (EIM) platform which is the single, integrated and comprehensive repository of enterprise data. Our Data Engineering Team is looking for Data Engineers to help us continue to build out our data infrastructure, making available to the business users the right data at their fingertips and supporting the business in big data analytics.   
    Responsibilities of the Data Engineer include:   
   Administration and monitoring of the EIM systems to ensure EIM operations run efficiently with the desired SLA and security compliance. Monitoring performance and advising any necessary infrastructure changes to the EIM landscape. Work with the infrastructure teams to implement such changes. Design and develop architecture for data services ecosystem spanning Relational, Columnar, NoSQL, In-Memory, Data Warehouses and BI & Big Data technologies. This include designing and implementing data pipelines & ETL processes. Design data models for mission critical and high volume data management, real-time and distributed data process aligning with the business requirements. Promote and develop data architecture best practices, guidelines, procedures and repeatable and scalable frameworks. Work with business units on their analytics initiatives, providing the data science expertise and resources besides being responsible for extracting the data from EIM as required for the project. Work with analytics vendors, providing the data sets as required and support the business users in assessments & validation of the analytics/statistical & machine learning models. Work with and help business units with tools like Tableau to visualize and create dashboards with the relevant data in EIM. Work closely with our application teams to operationalise & integrate analytics/machine learning models into our production systems.  Requirements BS in Computer Science or other related discipline is required. Advanced degree related to Analytics, Machine Learning & AI preferred. At least 3 years of relevant industry experience in following areas:     Knowledge and working experience with Machine Learning, AI, statistical techniques, and information retrieval as well as on data management systems, practices and standards. Knowledge and working experience with at least one visualization tools like Tableau, PowerBI, Qlik, or similar open source tools. Working experience in architecting highly performant databases using RedShift, PostgreSQL and Cassandra or NoSQL. Knowledge & working experience in Big Data technologies like In-Memory, New SQL, NoSQL, Hadoop Hive/Spark, etc Knowledge & experience in shell scripting, R, Python, Perl, Ruby, or any other scripting language. Should be proficient in at least shell scripting and R or Python. Experience with commercial ETL platforms with in-depth knowledge and understanding of ETL methodology & design supporting data transformations layer. Working experience with Ab Initio would be a bonus.   Strong knowledge and experience with Agile/Scrum methodology and iterative practices in a service delivery lifecycle is a PLUS. Working experience in an AWS or similar public cloud environment is another PLUS Excellent interpersonal & communication skills and proven ability as a problem-solver. Candidate to indicate in the application his/her strengths in data engineering and data science, and his/her preference. "
232,Data Engineer,YARA ASIA PTE. LTD.,"$2,500to$3,500Monthly","Roles & ResponsibilitiesThere are more than 500 million smallholder farms globally with at least 2 billion people depending on them for their livelihoods. In many of these segments, agricultural productivity is up to 10 times less than developed markets.  The smallholder focused solutions teams have the challenge to develop digital solutions with the focus on increasing productivity through optimal crop nutrition and knowledge transfer. About the Unit Digital Farming is a newly established global unit created in Yara Crop Nutrition with locations in Europe, Brazil, Singapore, and North America, building new digital business models and identifying new digital products, enhance customer interaction and achieve digitally enabled functional excellence, with the aspiration to shape Yara as the digital leader in crop nutrition.  We build solutions for farmers, construct hardware and sensors, crunch satellite data, apply artificial intelligence, and turn research results into solutions. Our team is made of designers, software engineers, hardware developers, data scientists, solution managers and product owners. Responsibilities  Study, develop and manage the data resources of the analytics and insights side of the smallholder solutions. Research new ways to interpret and utilise the data resources to provide meaningful, actionable insights. Work cross-functionally with different parts of the development centre to support the data needs of different teams. Develop, test and implement various scripts, algorithms and code when necessary.  Requirements At least three data science projects completed from start to finish. Strong personal/professional interest in the LSM segments (developing countries, low-income markets, etc) and agriculture in general. Able to code in Python and Javascript. Working knowledge of statistical packages like R Studio, SPSS, etc. Comfortable working with our tools: AWS, GitLab, Jenkins, Jira, Docker Aligned with our principles: agile, customer-centric, lean, service-oriented architecture, self-organization, transparency.  Additional information As a global organization, we actively strive to reflect the diversity in society. We, therefore, encourage all qualified applicants from all background to apply and are committed to creating a work environment that fits gender equality and allows combining career progress with the needs of a family or other personal circumstances. Why us?  Well funded, supported and staffed corporate innovation hub which offers a balance between startup culture and corporate support and benefits.
 Direct impact on products that provide real value to farmers. Work on sustainable solutions that benefit mankind and the environment, Unlimited working contract and competitive remuneration, benefits. Support for personal development, training
and continuous learning Commitment to using new technologies and frameworks, in-house hackathons, meetups, and knowledge sharing "
233,Data Scientist,CREATIVE MEDIA WORKS PTE. LTD.,"$6,000to$8,000Monthly","Roles & ResponsibilitiesREQUIREMENTS

 
 As an applied research scientist with BBM you will be part of a highly empowered team of applied researchers, data scientists, and data engineers that are creating a first class experience for one of the most popular messaging platforms in the world. Responsibilities: The successful candidate should be able to become an expert/leader in an active area of R&D such as spam detection, user preference modeling, behavior modeling, social network analysis, recommendation systems, content classification and/or business decision support. He or she will be hands-on and will create large-scale predictive models (supervised, unsupervised and/or reinforcement) from disparate data sources. He or she will implement and deploy their ideas at scale and in the cloud.  
 RequirementsRequirements: PhD, MS or equivalent experience in machine learning, computer science or related field Solid understanding of machine learning and statistics Solid reasoning and communication skills Experience with multiple statistical modeling techniques such as logistic regression, gradient boosting, random forests, SVMs, bagging, DNNs, etc. Experience in one or more of NLP, computational linguists, hierarchical and/or multi-label classification, search or information retrieval, graph analysis, optimization, social network analysis and/or recommender systems desirable Experience with cloud platforms, e.g. GCP, and related tools, e.g. DataProc, AirFlow etc., desirable Solid coding skills in at least one of Java, scala, python, C, C++ and/or perl Data wrangling skills: Spark, Hadoop, Hive, Pig etc. Familiarity with messaging apps and/or advertising models a plus"
234,Data Warehousing Consultant,NETWORK FOR ELECTRONIC TRANSFERS (SINGAPORE) PTE LTD,"$5,500to$7,000Monthly","Roles & ResponsibilitiesPosition Purpose: The ETL Developer will be responsible for development of ETL & BI solutions to complement existing or new exclusively In-house developed systems and support of front and back office systems. This individual will also apply proven communication, analytical and problem solving skills to help identify, communicate and resolve any data warehouse issues. 
 DUTIES & RESPONSIBILITIES:  The ETL developer develops and implements initiatives to meet the Information Delivery needs of the business intelligence systems The candidate will work with both functional and technical personnel, has in-depth knowledge of ETL and BI information delivery/presentation methodology and expertise in Informatica and 
SAP BO tool sets. The candidate will be responsible for BI requirements gathering, design, development and support for Business Intelligence (BI) and reporting solutions to meet the business needs Design and develop reports, dashboards, delivery (distribution), scheduling and retention policy for reports Analyze Information requirements with business and provide various alternatives taking into consideration the user requirement the delivery mechanism capability and the design of the underlying BI solution Formulate Information Delivery and delivery framework, taking into consideration policies
 and working with the other team member to ensure adherence to these on any initiatives Adhere to software development standards, procedures and techniques. Perform level 1 & 2 support to users on Business Objects (4.2 and above) & Informatica Power Center (9.5 and above) 	 Level 1 support includes but not limited to  User Administration, System Health Monitoring, Scheduled Jobs monitoring, Incidents Resolution Level 2 support includes but not limited to  Analyze issues / problems to understand the root cause, provide solution to resolve the problem.   Routine tasks : Support standard changes (Adhoc Reports, Configuration changes) Collaborate effectively with users, project managers, business analysts, testers and other team members Participate in all development Lifecycle processes Work closely with users to maintain and troubleshoot, enhance BI functionality and deliver. Must be self-directed/self-motivated and take the accountability of own progress Must be able to manage individual workload and deliver to enhancements/initiatives milestones. Must be able to work within the context of the team, giving and taking advice Incorporate Architectural Standards into application design specifications Keeping up to date with technical and industry developments. Must have reasonable competency in Linux and Windows commands and scripts  Requirements Degree in Information Technology, Computer Science or related Experience in the development of Business Information strategies using Informatica ETL and Business Objects product suite (Business Objects, Universe Designer, Web Intelligence, Desktop Intelligence, Crystal reports, Data Services and etc) Experience in information systems applications and data warehouses. n-depth experiences with Universe design, ad-hoc reports, standard reports, dashboard. Experience with Informatica and SAP BO administration, security, and backup and restore process A strong knowledge of business intelligence design concepts, with a concentration in dimensional modelling in relational database environmentsMust demonstrate experience in dimensional modelling, ETL design and development using Informatica, Business Objects Universe Experience with Informatica ETL Data Services Proven track record in dealing with medium - large data warehouses Candidate will be expected to partner and influence the Data architect/ Data warehouse modeller to ensure performance throughput and other systemic requirementsPossess the ability to balance short-term business needs and deliverables with long term design implications A strong working knowledge of SQL, and experience with Oracle 11g. Applicant should also demonstrate excellent written and verbal communication skills, and the ability to lead small to complex requirements gathering and design sessions in front of audiences Ability to work effectively as individual or with a team to understand and interpret requirements leading to technical implementation. Ability to work effectively and independently under pressure, meet deadlines, multitask and to prioritize tasks effectively Strong business, analytical skills and problem solving skills Strong Organizational and Interpersonal Skills Interaction with Business users and IT team is expected Demonstrate motivation to learn new skills and technologies Meticulous in nature, committed and see things through end to end "
235,"Lead Data Analyst, Group Data Management Office",OVERSEA-CHINESE BANKING CORPORATION LIMITED,"$7,000to$12,000Monthly","Roles & ResponsibilitiesAs a lead data analyst, successful candidate is expected to  Gather and document user requirements (UR) in an efficient manner (for data governance, data quality and reference data management) Involve in the design and development phase of the project via clarifications of UR, and where applicable, assess impact on UR resulting from workarounds due to technical constraints Prepare the data quality (DQ) rules and monitor the implementation Prepare test cases and perform user acceptance testing (UAT)
 Prepare necessary documentation following OCBCs template (e.g., for implemented DQ rules or UAT) Provide periodic updates to the supervisor about project challenges/issues/status.  RequirementsThe ideal candidate would possess:  At least 5 years of experience in the information technology domain and has bachelor degree in Information technology, Computer science or Data analytics discipline. Experience in data warehouse and ETL development, programing (Oracle PL/SQL, Teradata BTEQ etc) or BI tools (such as Qlikview, Tableau, Cognos, etc). In particular, prior experience in Qlikview reports/dashboard development will be viewed favourably Experience in the software development life cycle (SDLC) and able to work closely with IT for project delivery Good knowledge in RDBMS and able to write complex SQL for data extraction Good communication (both spoken and written) and documentation/presentation skills Good problem solving and trouble shooting skills are essential The ability to work independently with minimal supervision "
236,Data Analyst (Crypto),CAREERLIBRARY PTE. LTD.,"$3,000to$6,000Monthly","Roles & ResponsibilitiesResponsibilities  Interpret data, analyze results using statistical techniques and provide ongoing reports. Develop and
implement
databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality. Acquire
data from primary or secondary data sources and maintain databases/data systems. Identify, analyze, and interpret trends or patterns in complex data sets. Filter and clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems. Work with management to
prioritize
business and information needs Locate and define new process improvement opportunities.  JOB SKILLS  Analytical Skills: Data analysts work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyze it to find conclusions. Communication Skills: Data analysts are often called to present their findings, or translate the data into an understandable document. You will need to write and speak clearly, easily communicating complex ideas. Critical Thinking: Data analysts must look at the numbers, trends, and data and come to new conclusions based on the findings. Attention to Detail: Data is precise. Data analysts have to make sure they are vigilant in their analysis to come to correct conclusions. Math Skills: Data analysts need math skills to estimate numerical data.  
 RequirementsRequirements  Proven working experience as a data analyst or business data analyst. Technical expertise
regarding
data models, database design development, data mining and segmentation techniques. Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks), Python programming. Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc). Strong
analytical skills
with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Adept at queries, report writing and presenting findings. BS in Mathematics, Economics, Computer Science, Information Management or Statistics.  Apply:  Interested candidates are invited to submit a comprehensive resume, stating expected salary and date of availability, together with a recent photograph to mengsu.careerlibrary@gmail.com"
237,Data Scientist,OLDENDORFF CARRIERS (SINGAPORE) PTE. LTD.,"$4,000to$6,000Monthly","Roles & ResponsibilitiesOldendorff seeking data scientists at all levels to work on the next generation of cloud-based data-driven applications. These applications will use data from Oldendorffs proprietary Data repositories, and third party vendors to drive automated outcomes in a number of horizontal and vertical application segments. Your primary focus will be in applying data mining and machine learning techniques, doing statistical analysis, and building high quality prediction systems to be integrated to our data services. This is an exciting emerging venture for Oldendorff, leveraging latest technology in the mobile, big data and cloud application spaces.
 Considering that this is an emerging venture within Oldendorff, successful candidates should be able to:  Solve problems in robust and creative ways and demonstrate solid verbal, interpersonal and written communication skills Work in an environment with a significant number of unknowns  both technically and functionally. Inherent in such a new venture. Collaborate across a number of development teams as we leverage technology and solutions from them to deliver our applications Work globally in a geographically dispersed team  RequirementsTechnically we are seeking brilliant and diverse individuals with exposure (but not limited) to some of the following:  Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Experience with common data science toolkits Great communication skills Proficiency in using query languages such as SQL, Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good scripting and programming skills Data-oriented personality BS or MS degree or equivalent experience relevant to functional area.  This is a great opportunity to learn new skills and work on a new exciting venture within Oldendorff helping to take us to the next level in shipping. 
"
238,"VP  /  AVP, Data Scientist, Investment and Trading Technology, Technology and Operations  (180002YF)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & Responsibilities Selecting features, building and optimizing classifiers using machine learning techniques Data mining using state-of-the-art methods Enhancing data collection procedures to include information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Doing ad-hoc analysis and presenting results in a clear manner  Requirements Excellent understanding of machine learning techniques and algorithms; pattern recognition and predictive modeling skills to address business problems Undertaking data collection, preprocessing and analysis of structured and unstructured data Experience with common data science toolkits, such as R, Python. Experience with programming languages such as Java an asset.
 Proficiency in using query languages such as SQL, Hive, Pig. Being able to use Spark is an added advantage Experience with NoSQL databases, such as MongoDB, Cassandra, HBase
 Communicate results and ideas to key decision makers
 Experience with data visualization tools such as Qlik or any other open source visualization tools. Good to have treasury & market product knowledge as well Good applied statistics skills such as distributions, statistical testing, regression, etc. Good scripting and programming skills
 Data-oriented personality with problem-solving aptitude Masters Degree in Computer Science, Statistics, Applied Math or related field 4+ years of hands-on analytics and / or model development. "
239,System Engineer - Data Centre Automation,EIRE SYSTEMS SINGAPORE PTE. LTD.,"$4,000to$5,000Monthly","Roles & Responsibilities Implementation, monitoring, optimization and support of processes in the BI-IT-Automation computer system. Manage and coordinate critical preventive maintenance, performance monitoring initiatives, and documentation reviews/updates. Provide 2nd level support in the Center of Excellence (CoE) for Cloud Computing team
 Handle tickets and escalations from the Incident management team and provide support on technology and troubleshooting. Actively participate in global and regional IT projects and initiatives.  Requirements Knowledge of ITIL processes and methodologies Minimum of 2 years experience in IT Infrastructure Automation and support  Experience with using REST API within automation workflows, orchestration, and BPM  Strong technical proficiency with in scripting and automation technologies is a must  Experience with programming languages such as Powershell, Perl, Automic/UC4, XML, Ruby, Python, JavaScript, and/or Bash  IDE based tools such as Eclipse or virtual studio code and using of code and binary repositories (e.g. GiTHub, GiTLab and BitBucket) Hands on experience with Text-file formats for structure data (e.g. JSON and YAML) General skills with administration of server based operating systems such as Redhat Linux Server OS (6.x and 7.x), Windows Server (2012 and 2016) Experience with virtualization technologies related to VMware vSphere ESXi and vCenter  
"
240,Data Scientist,YOJEE PTE. LTD.,"$6,000to$7,500Monthly","Roles & ResponsibilitiesYojee is looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve our company and to build data products to extract valuable business insights. In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential and having a passion for machine-learning and research. Responsibilities  Prototyping faster & more scalable machine learning and heuristic optimisation algorithms using cutting edge research to solve logistics problems such as finding the best possible, or cost efficient routes, multi modal route planning, NP-hard problems, etc.  Build and maintain a scalable data pipeline to consume data from multiple sources.  Basic data cleansing and preparation  Build analysis and visualisation for business purposes and sales pitches.  Build solutions using Big Data technologies to crunch potentially enormous data and respond with meaningful results in real time. Requirements Minimum Bachelor Degree in Computer Science or Computer Engineering or its equivalent related experience.  Minimum 2 years of experience in machine learning and data analysis  Proficient in software programming and database skills; Python, Scala, Java, SQL, scikit-learn, MapReduce, Spark, Apache Hadoop.  Knowledge of Big Data Frameworks such as Spark, Hadoop, etc.  Proficient and experienced working with statistical models; Regression, Clustering, Classification, etc.  Experience working with agile software development practices  Ability to work in a globally distributed team"
241,Data Analyst - Data Scientist,TERALYTICS PTE. LTD.,"$5,000to$8,000Monthly","Roles & ResponsibilitiesWe at Teralytics are searching for an exceptionally talented & highly-motivated individual for combined role of data analyst and data scientist. In the beginning of your engagement, you will be dealing with a very high profile government agency in Singapore which is one of our primary data customers; however, you may be assigned to work with additional customers or internal projects as time allows it. Your responsibilities will include:  Working closely with our data customers to understand what their issues and needs regarding the data we provide to them Perform investigation, tuning and improvements to the data processing models and algorithms to address the issues raised by the customers Perform various analysis, both visual and programmatic, of both raw or processed data to address the needs of the customers Develop tools to automate analysis of both raw and processed data Work closely with senior data scientists to make more complex improvements to data processing models and algorithms, when necessary Support software engineers on understanding data processing models and algorithms in order to develop new software products or deploy them to different customers Produce validation and analysis reports as needed internally, by partners and customers  RequirementsYou are experienced in working with data either professionally or academically. You possess programming skills on at least basic level and is comfortable on operating datasets in a programmatic way. You are keen to learn as much as possible technical in data science, statistical learning, machine learning, and artificial intelligence, as well as becoming proficient with the programming languages and tools used in these fields. You have interest in the realms of urban planning and human mobility, and how technology can be leveraged to produce Smart Cities. You enjoy working closely with other people in a highly diverse and multicultural environment. You have excellent communication skills and are interested in being able to directly face partners and customers. Must have
  BS/MS and/or PhD in Computer Science, Statistics, Mathematics, Physics, Engineering, Business Analytics or other fields with a strong mathematics / algorithm foundation At least 1 year of experience with programming. Proficient with at least one scripting language suitable for data analysis, such as Python, R, MATLAB or SAS language At least 3+ years of experience with analysing or manipulating datasets Experience with at least two of the following topics (more than two will be an advantage):     Machine learning (e.g. regression, decision trees, neural networks) Statistical hypothesis testing (e.g. Student t-tests, Pearson correlation tests, ANOVA) Statistical learning (e.g. Markov Chain Monte Carlo, Expectation-Maximization, Particle filter) Target tracking (e.g. IMM filter, data association, multiple hypothesis tracking) Relational databases (e.g. SQL, Pandas, SparkSQL) Data visualisation using Tableau Location analytics (QGIS, geodetic coordinate conversions, location data visualisation) Other advanced mathematical / algorithmic topics such as graph theory, optimisation, NP-complete problems, infinite dimensional differential equations, computer vision, etc.    Advantageous
  Substantial experience in applying machine learning and statistics to large amounts of data in either academia or industry. A PhD in the topic is a plus Substantial experience with Python, R, and or MATLAB Experience with processing location data, such as cellular, Wi-Fi, GPS, GTFS, OpenStreetMap, Google Maps Knowledge of statistics including those in multivariate statistics, spatial-temporal statistics and time series analysis. "
242,Senior Software Engineer (Chief Data Office),STANDARD CHARTERED BANK,"$8,000to$14,000Monthly","Roles & ResponsibilitiesLeading the way in International Banking. 
We support the people and companies driving investment, trade and wealth creation across
Asia, Africa and the Middle East. And our heritage and values are expressed in our brand
promise  here for good.

See our Brand and Values Job Description Reference Management team provides data services to manage enterprise wide master data/reference data.

The objective of the RDM is to establish golden source of core reference data to drive consistency across enterprise systems, processes and core reporting activities. This will critically ensure consistency across regulatory, financial and management reporting, as well as enable end to end integration from transaction systems through to reporting applications, reducing duplicated and multiple manual processes to append and correct reference data sets across the enterprise Senior Software Engineer is a technical development role who will be
accountable
& responsible for all technical deliverables in RDM & also drive the strategic Reference data management end state objectives. Reference Data Management (RDM Data Services) RDM Solution includes sourcing of data from various data provides (external & internal), mastering them in the RDM platform & distributing the data for various consumers. RDM services are both foundational & critical for ensuring data standardization, regulatory reporting, risk management, etc.

It is progressively being adopted across the various applications across the bank and is relied upon for the bank to conduct its day-day operations. Managing as many entities that are commonly required by the bank and increasing the adoption of the reference datasets across the bank are key success measures. Senior Software Engineer -
Technical development role is an exciting opportunity to drive impactful change across the bank collaborating with team in Singapore, Malaysia and India. This role
will involve leading the technical delivery team including vendor delivery teams to deliver the reference data services as required by various projects.

In addition to end to end delivery accountability, candidate should drive agile practice in the team and ensure solutions are designed / implemented correctly and are fit for purpose. Role would also involve working with PM and ensuring that delivery is managed well in terms of costs, timelines, risks and completeness. Key Roles & Responsibilities  Be a technical expert with good understanding of various technology/toolkits used in RDM applications Propose and evaluate new technologies for use in the pipeline projects Provide the solution approach & solution direction that will deliver the functional requirements Design & develop various business requirements across various projects. This including designing data model, configuration & customization of workflow and integration to data services Deliver reference data Services for on-going projects in RDM. This includes defining/driving the overall solution, detailing the technical components required & driving the delivery of those - having an eye for detail Perform the code review of all the change and will be a Gatekeeper in all stages of project cycle Keep the big picture in focus while being able to deep dive into the unique engineering challenges Analyze, clarify, question and challenge vendor delivery and solution approach Own end to end delivery of the requirements in a timely manner without compromising on the quality Ensure each technical role / resource has clear responsibilities, reporting lines, delegated authorities and objectives  RequirementsExperience / Qualifications / Skills  Must Have - In depth knowledge of Teradata database, tools & utilities involving administration & maintenance of database, optimization, capacity, security, and configuration & scheduling. Must Have - Good Understanding of Teradata Product (MDM) & Min of 2 years of hands-on development experience using MDM product in projects in implementing MDM core feature 

Data Model Design, Creating Configuration UI, Custom Workflows, defining Approval framework and integration with various services  Email, data distribution, Rest API. Should have expertise in Teradata utilities for data management like MultiLoad, Fastload & BTEQ scripting. Ability to do work on multiple technology stack beyond Teradata tools/technology to solution and deliver the target state RDM aspirations Good understanding of UNIX script & Design & develop data processing, monitoring & profiling tools using standard UNIX scripts. Excellent analytical, problem solving skills and a motivated team player with good inter-personal skills. Self-driven and results-oriented with strong will to succeed. A naturally organised person with determination to deliver excellence. Strong problem-solving and analytical skills to view problems as challenges and turn them into viable solutions. Must have adopted and implemented Continuous Integration for large scale programs -
Build out full automation across Build/Test/Deployment. Excellent communication skills  Having clear oral and written communication with CIOs as well as technical developers At least 5+ years of relevant industry experience. Any bachelor degree in science or engineering  We are committed to building a culture that fosters a diverse and inclusive environment thats free from bias, where everyone can realise their full potential and make a positive contribution. 
This is just one of our values that is expressed in our brand promise  here for good. 
Apply Now... How to Apply Click here ( https://scb.taleo.net/careersection/jobdetail.ftl?job=1800018461&lang=en ) to apply now and take the next step in fulfilling your potential You can search and view current opportunities across our organization and apply immediately by visiting www.standardchartered.com and selecting Careers. To help speed up your application, please note the following:  You will need to log in (or register if you are visiting our careers site for the first time) before you can apply for a specific role Some roles may require you to undertake an online talent assessment in addition to completing the application form (to facilitate this process it is preferable that you provide us with an email address as part of your contact information) We will ask you about your education, career history and skills and experience, it may be helpful to have this information at hand when completing your application  It usually takes 15 - 20 minutes to complete the application form; you can save your application at any time and return to complete it at your convenience. Diversity & Inclusion Standard Chartered is committed to diversity and inclusion. We believe that a work environment which embraces diversity will enable us to get the best out of the broadest spectrum of people to sustain strong business performance and competitive advantage. By building an inclusive culture, each employee can develop a sense of belonging, and have the opportunity to maximise their personal potential."
243,"Facilities Engineer[Data Centre, M&E]",THE SUPREME HR ADVISORY PTE. LTD.,"$1,700to$3,400Monthly","Roles & Responsibilities East Attractive Salary Career Progression Opportunities  
 Interested applicants can send your resume to supreme.terryyeo1@gmail.com and allow our Consultants to match you with our Clients. No Charges will be incurred by Candidates for any service rendered. 
 *Requirements and Skills  Minimum qualification Diploma or equivalent Min experience 2 years & above Tactful, analytical skills and responsible  
 *Job Description  Daily health check non-critical/critical facilities & records Attendance/initial troubleshooting to fault/breakdown/complaint & records Attend user request for handyman works, eg. Cabinet door faulty, minor shifting etc and report to client CAS for follow up action Generating the 1st incident report & escalation Coordination/supervision of contractor's work (maintenance/rectification/fault) Maintaining records for utilities,chilled water & condenser water usage/monthly work carried out/monthly fault call-out /outstanding works Coordination/supervision of landlord on building related work (aircon,toilet, lighting,etc) Reporting of abnormality 7 days/24 hours standby for any M & E related emergency call out Monitoring of FMAS on Data Centre M & E facilities Scheduling of FCUs and AHUs for aircon extension request Obtain quotation for maintenance and improvement works from vendors/contractors Carry out duties in accordance with QEHS policy, procedures and work instructions Aware of the legal and other requirements and significant environment aspects/impacts (EAI) and occupational safety and health hazard/risks associated with their work activities  Reg No R1871723 Ea No 14c7279 Job Type: Full-time Job Type: Full-time Requirements*Requirements and Skills  Minimum qualification Diploma or equivalent Min experience 2 years & above Tactful, analytical skills and responsible "
244,Senior / Data Analyst (Data Science Team),M1 LIMITED,"$3,250to$6,500Monthly","Roles & Responsibilities Work closely with the data source owners to identify and utilize data that will help to implement use cases for new opportunities or in solving business problems Responsible for end-to-end data preparation, hands-on extraction, transformation and loading of different formats of data from various source systems Work closely with complex big data sets, perform data cleansing and filtering based on the analytics model requirements Design, develop, test and implement extraction, transformation and loading programs Responsible for the operations, maintenance and administration of Big Data Platform systems and applications Proactively discover new insights from raw datasets that are meaningful and useful to business needs  Requirements Degree in Statistics, Mathematics, Computer Science or Engineering or related field with at least 2 years experience in Data Analytics or Enterprise Data Warehouse related applications Sound technical abilities on databases, file systems, ETL processes, data manipulation Experience working with different interface protocols, e.g. ODBC/JDBC/OCI, JSON, XML, SOAP, HTTP/HTTPS, RMI, sFTP, SNMP, SysLog, Java API, Microsoft .NET API Working experience with Big Data tools and related technologies - Hadoop, HDFS, Spark, Hive, Impala, Sqoop, Kafka, etc Proficient in SQL, HP Vertica Scripts, Oracle, PostgreSQL, ETL/ELT applications and experience in performance tuning such applications Basic understanding of machine learning techniques - feature engineering, regressions, dimensionality reduction, segmentation classification, etc. with experience in R, Python, Scala, Java as an added advantage Experience in administering Big Data systems - cluster, connectivity, security, archival, backup and recovery, capacity and performance
 Telecom domain knowledge with experience in multi-tiered Customer Care, Order Management, Loyalty, Business Support and Network Provisioning systems will be highly advantageous Experience working with visualization / business intelligence tools such as Microstrategy, Tableau, Qlik, Superset, Zoomdata Comfortable working with very large volumes of data of various formats Excellent analytical and communication skills Able to perform under pressure and work effectively with end-users and vendors "
245,Data Analyst (Fintech),MATCHMOVE PAY PTE. LTD.,"$3,000to$5,000Monthly","Roles & ResponsibilitiesAre You The One? MatchMove Pay, one of the fastest, award-winning Financial Technology company, is
looking for a Data Analyst who has an eye for detail and excellent with SQL and MS Excel
as we accelerate our global expansion.  Key Responsibilities:  Provide support in the settlement and reconciliation of treasury operations Monitor daily processing of payments and settlements Analyze reporting needs and requirements, assess current reporting in the context of strategic goals and devise plans for delivering the most appropriate reporting solutions Analyze and interpret data and reports Support and assist team members in all aspects of data analyst, quality insurances and report creation Resolve problems with data analysis services and reporting services Establish and maintain policies, standard operating procedures, and associated documentation for user interaction with the database environment Work with others in the development of data warehouses and other data sources to support managerial and business intelligence reporting needs.  Requirements Bachelors Degree in Computer Science, Computer Engineering, Statistics or related fields Good understanding of relational database concepts, SQL query statements, SQL Server programmability Experience working with a variety of reporting and analytic platforms and tools Skilled at optimizing large complicated SQL statements  Culture in MatchMove  To work in a fast-moving startup, fun and yet professional environment that recognises and rewards individual contributions and also team success. To work with highly motivated people who are totally focused on winning by combining great teamwork, rapid execution and an uncompromising approach to quality and customer satisfaction. We strongly encourage Innovation, Collaboration, Creativity, and Initiative. Work in a collaborative environment where you can talk to the CEO anytime!  Personal Data Protection Act
 By submitting your application for this job, you are authorizing MatchMove to: a) collect and use your personal data, and to disclose such data to any third party with whom MatchMove or any of its related corporation has service arrangements, in each case for all purposes in connection with your job application, and employment with MatchMove; and b) retain your personal data for 1 year for consideration of future job opportunities (where applicable for relevant unsuccessful job applicants). 
"
246,Senior Data Technologist,RAKUTEN ASIA PTE. LTD.,"$8,000to$12,000Monthly","Roles & Responsibilities Communicate with stakeholders, explaining analytics plan, methodology, and expectation. Identify gaps or opportunities in AD/Marketing performance, develop potential solutions to fill these gaps Understand structured and unstructured datasets Generate insights using data science technologies Create and automate the data workflows such as extraction, transformation and load (ETL) Manage data science initiatives in a cycle of planning, modeling, test, deployment, evaluation Enhance, educate, and guide your team in the specialization of Data sciences to achieve high agility, high contribution to business, and catching up state-of-the-art technologies related to advertisement industries by bringing your knowledge/experience to team.  Requirements M.Sc., M.Eng., or PhD degree in computer science, operational research, mathematics, or other related faculties. At least 5-10 years of strong professional experience in Data sciences, General statistics and good programming skills (Python, R or Scala) At least 2 years of experience with SQL, HIVE Experience in developing and building data science solutions Experience in handling big data using technologies, like Hadoop Eco-System, Hive, Presto, Mapreduce, Spark, MongoDB etc Strong foundation in data science techniques (Recommendation Engine, Regression, Classification, Dimension Reduction) Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products Demonstrated critical thinking and translating business needs into technical requirements Experience working with marketing teams for an Internet technology company Familiarity with building data pipelines (Luigi, Airflow) at enterprise scale Demonstrates creativity and flexibility in solving challenging problems Advanced Data Science techniques (Neural Nets, Bayesian Modeling, MCMC, Boosting, Graph Theory) "
247,Data Network Analyst,JONES LANG LASALLE PROPERTY CONSULTANTS PTE LTD,"$6,000to$8,000Monthly","Roles & ResponsibilitiesWith JLLs strategic aim of becoming a technology company focused on real estate, data and technology are key to our future.
 The Analyst will partner with senior management deliver business insights from analyzing the collected data.
 In order to be successful, this individual will need to have proficiency in Excel Financial Modeling.
 Prior experiences in Salesforce, Data Management, and Interactive Data Visualization Tools is a plus.
 JLL advisors partner with investors, owners and operators around the globe to support and shape investment strategies that deliver maximum value of their commercial real estate portfolio.
No other advisory or brokerage team in the world provides as broad a spectrum of services for hotel investors.
 A partnership with JLL gives our clients a single point of contact for support in: acquisition advice, asset management, financing, investment sales, project and development services, operator selection and contract negotiation, research consultancy, strategic advisory, valuations, and value recovery.
 In response to changing client expectations and market conditions, we assemble teams of experts who deliver integrated services built on market insight and foresight, sound research and relevant market knowledge.
 We attract, develop and reward the best, and most diverse people in our industry, challenging them to develop enduring client relationships built on quality service, collaboration, and trust. 
 RESPONSIBILITIES: Financial Modeling-Excel Proficiency  Support, Excel-based valuation models Build decision-making models for senior leadership and managers Assist teams with Excel modeling and data manipulation  Salesforce and Data Management  Configure Salesforce platform (Validation Rules, Workflow, etc.) and data cleansing
 Drive Salesforce adoption by assisting in day-to-day support Train users as necessary on system functionality and new Salesforce features Maintain data quality by identifying, deleting or merging duplicate records, cleansing and updating inaccurate data Gather business requirements and translate them into Salesforce changes and enhancements Identify business problems and recommend solutions that meet organizational needs Participate in business-led change management processes  Interactive Data Visualization Tools  Conduct data analysis using Salesforce reports & dashboards to deliver insights to the business Maintain Tableau/Power Bi dashboards and make updates as necessary Build Tableau/Power Bi dashboards that use Salesforce and other data sources for internal decision-making  Requirements 2-4 years of work experience in technologyreal estate experience strongly preferred Bachelors degree required in Management Information Systems, Computer Science or Business Strong Excel proficiency including Visual Basic for Applications (VBA); Formulas: Index, Match, IRR, Present Value, Future Value, If, Sumifs, and Countifs Understanding of basic financial valuation concepts  discounted cash flows, leveraged internal rates of return, etc. Prior Salesforce experience  creating Validation Rules & Workflows is a plus Salesforce Administrator Certification is preferred but not required. Knowledge of Power Bi/Tableau dashboard tools is a plus Commercial Real Estate (CRE) experience a plus Willingness and flexibility to work in a global environment, outside of standard business hours and on weekends as needed Ability to travel domestically and internationally - less than 15% "
248,"Data, Software and Operations Engineer",APPLE SOUTH ASIA PTE. LTD.,"$4,000to$7,000Monthly","Roles & ResponsibilitiesJob Summary Do you want to work for one of the most exciting and innovative companies in the world? At , new ideas and complex challenges have a way of quickly becoming phenomenal products, services, and customer experiences, and we need your expertise! Description Apples Information Systems & Technology (IS&T) organization leads key business and technical infrastructure at  -- how online orders are placed, the customer experience with technology in our retail stores, how much network capacity we need around the world and much more. We are looking for a talented Engineer who can help build solutions. You will have the chance to work with diverse technology stacks and learn from a talented group of engineers and analysts, while being exposed to insights that help drive our business. If you have a passion for building solutions and want to make an impact on Apples future direction, wed love to hear from you. RequirementsKey Qualifications  Experience in one or more of Database (MongoDB, Cassandra, Coachbase) technologies, Operating Systems (Linux, Java) or other object-oriented programming preferred Experience with iOS is beneficial Excellent problem solving ability and understanding of development processes and agile methodologies Ability to communicate technical solutions to non-technical partners Deep understanding of data structures and algorithms Possess a very high degree of natural curiosity Organized and self-motivated Have a can-do mindset to improve development efficiency Build efficient solutions to meet business requirements Work with many teams across   is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities.  will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.  Education Bachelors degree or equivalent work experience preferred"
249,Associate  /  Senior Data Scientist,NCS PTE. LTD.,"$4,500to$8,000Monthly","Roles & Responsibilities Work with customers to identify opportunities where Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) can be applied to data to solve the customer painpoints. Individually or collaborate with other team members to develop AI/ML/AA prototypes/Proof-of-Concept/Proof-of-Value to derive actionable insights from data. Collaborate with the customers and internal stakeholders to architect the overall supporting storage and compute infrastructure to support the deployment of the AI/ML/AA models, applications, and visualisation of the results.

 Collaborate with the relevant project managers to conceptualise, develop project scope, requirements, budget, and timeline for the implementation of the identified AI/ML/AA projects. Implement the AI/ML/AA projects and to ensure that the projects AI/ML/AA objectives are met.  

 Requirements PhD/Masters/Bachelors (with good honours) in Computer Science, Statistics, Applied Mathematics, Operations Research, or related disciplines. Prefer candidates with 3 or more years of working experience, with at least 2 years of Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) experience. Domain experience in public safety, defence, transport, education, and healthcare are highly desired. AI/ML/AA experience in smart city, social media, and procurement are also highly desired.
 Good knowledge of AI/ML/AA models, software, and tools with the ability to conceptualise and architect the key components of AI/ML/AA projects; and to develop prototypes using statistical software packages such as R/SAS/SPSS. Experience working with very large data sets, including statistical analyses, data visualization, data mining, and data cleansing/transformation and machine learning. Experience in solutions using technologies such as Hadoop/Hive/Hbase/NoSQL and developer skills in Python, Perl, and Java are highly desired. "
250,Project Officer,Company Undisclosed,"$3,200to$4,000Monthly","Roles & ResponsibilitiesData Scientist / Programmer for Regional ATM Modernisation Programme Under the Air Traffic Management Research Institute (ATMRI) (http://atmri.ntu.edu.sg/), Nanyang Technological University, you will be part of Regional ATM Modernisation Programme team to perform programming and data analytics for the ASEAN air routes and ATM operations in the region. Primary Duties or Responsibilities Specifically, you will  Undertake research and development related to Air-space management & Data Analytics. Perform programming support for fast time and real-time simulation tools, doing analytics, and building high quality strategic planning system for future for Air Traffic Management (ATM) eco-system for the region. You will provide expertise on mathematical concepts for the broader applied analytics of flow management and inspire the adoption of advanced analytics and data science across the entire breadth of regional ATM system. Conduct stakeholder meetings to solicit input for development of systems. Interact with senior personnel such as project lead and ATC operations specialist on significant technical matters and coordinate with other specialist teams within programme. Represent the Institute at regional/global ATM platforms, international forum/conferences. Occasional overseas travel may be required.  Requirements Bachelors degree in a relevant field. At least 3 years experience in any aviation-related fast-time simulation environment. Knowledge of tools like SAAM and AirTop will be an added advantage. Strong programming skills. Experience in
Data Science (knowledge in Aviation / Air Traffic Management Good English writing and communication skills Independent and team player "
251,Senior  /  Consultant (Data Scientist),NCS PTE. LTD.,"$4,000to$7,000Monthly","Roles & Responsibilities Work with customers to identify opportunities where Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) can be applied to data to solve the customer painpoints. Individually or collaborate with other team members to develop AI/ML/AA prototypes/Proof-of-Concept/Proof-of-Value to derive actionable insights from data. Collaborate with the customers and internal stakeholders to architect the overall supporting storage and compute infrastructure to support the deployment of the AI/ML/AA models, applications, and visualisation of the results.

 Collaborate with the relevant project managers to conceptualise, develop project scope, requirements, budget, and timeline for the implementation of the identified AI/ML/AA projects. Implement the AI/ML/AA projects and to ensure that the projects AI/ML/AA objectives are met.  

 Requirements PhD/Masters/Bachelors (with good honours) in Computer Science, Statistics, Applied Mathematics, Operations Research, or related disciplines. Prefer candidates with 3 or more years of working experience, with at least 2 years of Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) experience. Domain experience in public safety, defence, transport, education, and healthcare are highly desired. AI/ML/AA experience in smart city, social media, and procurement are also highly desired.
 Good knowledge of AI/ML/AA models, software, and tools with the ability to conceptualise and architect the key components of AI/ML/AA projects; and to develop prototypes using statistical software packages such as R/SAS/SPSS. Experience working with very large data sets, including statistical analyses, data visualization, data mining, and data cleansing/transformation and machine learning. Experience in solutions using technologies such as Hadoop/Hive/Hbase/NoSQL and developer skills in Python, Perl, and Java are highly desired. "
252,Enterprise Data Software Engineer,TESCOM (SINGAPORE) SOFTWARE SYSTEMS TESTING PTE LTD.,"$5,000to$6,000Monthly","Roles & Responsibilities Engineering solutions for new and existing data pipelines and systems  Maintaining, and supporting existing data pipelines and systems  Working as a proactive team member in an agile environment  Consulting with stakeholders to understand, architect, and implement solutions  Testing solutions and implementations to guarantee they perform to specifications
 Requirements You have 3+ years experience in software engineering and have a desire to focus on data.  You have strong familiarity with at least one type safe language. Familiarity with multiple languages of any type, preferred  You arent dogmatic about a particular programming language. Language agnostic programmers welcome!  You have a strong sense of ownership with a bias for action and willingness to roll up your sleeves  Strong experience designing for and using relational databases  Experience with ETL (extract, transform, load).  You arent afraid to try new things, technologies or otherwise.  Bachelor's Degree (computer science or related degrees preferred) Preferred Qualifications   Primary Focus on Ruby and AWS Development  Experience engineering full stack applications  Experience in Informatica (nice to have) or eagerness to learn  Experience using AWS (S3, Lambdas, RDS) or Azure  Experience with Hadoop ecosystem (nice to have) or eagerness to learn. Spark experience big plus.  Experience with non-relational database systems like HBase, Cassandra, DynamoDB, MongoDB, etc. (nice to have)  Experience with CI/CD  Experience or familiarity with TDD/BDD  Experience or familiarity with the roles/responsibilities of Scrum and Kanban  Experience with MDM (nice to have)"
253,Data Scientist,FRIESLANDCAMPINA AMEA PTE. LTD.,"$6,000to$11,000Monthly","Roles & ResponsibilitiesFrieslandCampina is one of the worlds five largest dairy companies. FrieslandCampina supplies consumer products such as dairy-based beverages, infant & toddler nutrition, cheese and desserts in many European countries and in Asia and Africa. Products such as cream and butter are also supplied to professional customers including bakeries and food-service companies. FrieslandCampina also produces ingredients and half-finished products for manufacturers of infant & toddler nutrition, the food industry and the pharmaceutical sector around the world.  Responsibilities -Leads in harnessing the power of data and information technology through breakthrough analytics, business consulting, implementing new capabilities and processes with the business teams -Accountable for understanding the business wicked problems of the areas we work in, deliver actionable insights from mining secondary data and ensuring our projects and services add measurable business value -Lead analytical initiatives 
and be accountable for delivering intended business value.  Lead creation and execution of analytic action plans that addresses top priority business challenges and creates valuable insights. Develop in-depth business, domain, analytical and systems knowledge for building relevant solutions and services Consult and coach business teams/analysts on appropriate uses of data, analytical solutions and tools Work in multi-functional teams to evaluate business activities.



  FOCUS AREAS:  Focus on integrating different commercial (outside-in, inside-out) commercial data to bring about actionable insights Help Opco to drive data driven culture Expand to supply chain or other domains based on priority Automate the leading and lagging KPI vs today it is all manually done and deploy dashboard to the fighting units Selectively build predicative models in marketing mix impact analysis (linking leading / lagging KPI); QR code data modelling  
 RequirementsRequirements:  Have Undergraduate or Masters Degree level qualifications. Preferred (but not a requirement) disciplines include; Operations Research, Economics/Mathematics, Business Studies/MBA, Engineering, Computer Science, Physics   Strong leadership and active in extracurricular activities Excellent written and verbal communication skills to influence others to take action   Comfortable with working with ambiguous business scenarios and possesses strong thinking/problem-solving skills which can be applied to business processes with a ""can-do"" attitude Translating data driven insights into decision and action Demonstrated ability to handle multiple priorities Good FMCG Business background/interest is preferred 	 Experience in Sales/Marketing Experience in E-Commerce / Digital   Strong collaboration and influencing skills  
 
"
254,Data Center System Engineer (Top Global E-commerce Company) (JD#4337),SCIENTE INTERNATIONAL PTE. LTD.,Salary undisclosed,"Roles & ResponsibilitiesAn exciting opportunity to gain new IT operations experience as Data Centre Engineer for one of the top 10 global e-commerce company in Singapore!
  Good chance to get exposed to orther aspects within data centre operations i.e. cabling management, power management and the latest IT infrastructure technologies in the e-commerce space! RequirementsMandatory Skill-set  At least Diploma in Computer Science or IT; 
At least 1
year
of experience in Data Centre / IT Operations
and Support
; Good knowledge and experience in IP Network, switches, basic network components and networking protocols i.e. TCP/IP; Good working knowledge
in various Operating Systems (OS) i.e. Linux
and Windows;
 Conversant in basic troubleshooting in issues in Windows / Linux systems and networking; Proactive, responsible,
good work attitude and a team player; Good interpersonal communication
and documentation skills.  Desired Skill-set  CCNA; Prior experience in Server Room / DR Command Centre / Data Centre operations is preferred.  Responsibilities  Responsible for day to day operations and administration
within a
data centre environment; Attend to day to day operational tasks
and assists engineers on issues and investigation for root cause; Involved in equipment
relocation, replacement and removal; Perform system maintenance and do regular reporting; Required to do
administrative and documentation work; Assist in troubleshooting in Linux/Windows system; Identify areas of improvement and ensure corrective or preventive actions are put in place; Any other tasks assigned from time to time.  Should you be interested in this opportunity, please send your updated resume to apply@sciente.com at the earliest. Confidentiality is assured, and only shortlisted candidates will be notified. EA License: 07C5639"
255,"Data Scientist Lead, IBG Digital, Institutional Banking Group (180002JP)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & ResponsibilitiesJob Purpose
 The Lead Data Scientist manages a team of data scientists within IBG Business Analytics to drive value for the business by leveraging machine learning. He will have opportunities to work on various projects that provide data-driven insights that enable enhanced capabilities in the areas of business growth, risk management, productivity etc. Responsibilities  Lead, guide, and manage the team of data scientists Overall accountable for the teams delivery of data science projects that drive value for business Manage and guide a team of experienced data scientists to drive projects and be accountable for the output of the team Partner with business stakeholders to understand needs and identify opportunities to apply data science Frame this opportunity as a data science problem, formulating hypotheses and techniques for experimentation Oversee the process of data exploration & preparation, the conduct of experiments, review of model performance, and presentation of results to business stakeholders for their feedback Lead the presentation of key insights to management with actionable recommendations Manage the team to facilitate deployment of finalised solutions to production environment Oversee the ongoing monitoring of model performance, and the process of model retraining if necessary  Requirements For PhD holders (in computer science, machine learning, statistics, decision science, mathematics or equivalent)  at least 5 years of industry experience developing data science solutions For non PhD holders  at least 8 years of industry experience in data science PhD or advanced degree holder in computer science, machine learning, statistics, decision science, mathematics or equivalent Prior experience managing teams of PhD-level data scientists preferred Excellent advanced analytics skills, with prior industry experience developing machine learning solutions for classification, prediction, forecasting and/or anomaly detection problems Highly proficient in data manipulation Highly proficient in R, Python, Spark Strong expertise in at least one of the following areas (or equivalent): deep learning, NLP, graph mining, anomaly detection, large-scale recommender engines, large-scale optimizations, large-scale multivariate time-series forecasting, causal and statistical reasoning Ability to present analysis in a manner accessible by non-practitioners Good verbal and written communication skills and the ability to interact professionally with business executives Has a can-do attitude Prior experience in banks not required but may be considered "
256,Data Quality Officer,CAPGEMINI SINGAPORE PTE. LTD.,"$5,500to$9,000Monthly","Roles & ResponsibilitiesEstablish, monitor and adapt the rules and metrics to measure data quality Work with S2i Module owners to ensure the provided datas quality is strictly identical to the S2is one Establish a framework to automate data quality checks and optimise related costs. Requirements Engineer or University degree 5+ years of experience in of data quality and data security management 5+ years of experience with data visualization and predictive tools Good knowledge of predictive models (R or else) Experience with MS Power BI, Tableau, Qlik or Domo is a real plus Knowledge of data wrangling tools (Trifacta, alteryx, ) "
257,Data Scientist,Company Undisclosed,"$5,500to$7,500Monthly","Roles & Responsibilities The opportunity to be a data scientist in a vibrant, leading global reinsurance company with diverse data to enable innovative data analytics Coding and developing advanced analytics models (ranging from simple regression methods to machine learning to deep learning methods) in the data analytics software environments such as R, SAS, python, etc. including advanced data preparation in these environments, Microsoft SQL and other database environments. Advanced data visualizations will be important in how you communicate insights internally and to clients. Active participation in projects in the fields of statistics, machine learning and deep learning Unlimited opportunity to expand you data science practical experience through solving cutting-edge insurance problems Using advanced analytics methods, develop insurance business solutions based upon insight discovered from data Contribute to the development and implementation of solutions that enable operational units to increase quantity and quality of new business Supporting and advising the business units in applying the latest research methods and providing a central source for specialized know-how, tools and techniques for data analytics Presenting statistical, machine-learning and deep-learning solutions to internal and external stakeholders Networking with already existing data-intensive units in the area of analysis and reporting, as well as with IT to form an analytics community. Collaborate with internal partners in Life and Health and the data analytics centre in Munich to leverage capabilities in big data technology  Requirements University degree in data science / advanced data analytics, statistics, applied mathematics, information technology, or a comparable discipline 1+ years data analytics experience including advanced data preparation and manipulation (e.g. in Microsoft SQL), machine learning coding, business intelligence, predictive modelling / analytics tools in R, SAS, etc. Very good knowledge of and coding (in some or all of R, SAS, python etc.) generalized linear models and similar regressions, machine learning and deep learning methods, statistical tests, model validation and selection procedures, etc. Proven expertise and experience in the application of predictive modelling methods (regressions, machine-learning, natural language processing, deep learning, artificial intelligence, visualization or other relevant experience) in a business environment will be an advantage Must have a passion for advanced analytics methods, generating meaningful insights from complex dataset and communicating insights with powerful data visualization Very strong abilities in problem solving including managing data cleansing and preparation in Microsoft SQL or similar and linking with R, SAS etc. Proven competence in the identification and integration of external data (e.g. wearable data, bank data, telecom data, etc.) sources will be an advantage Know-how in web development, visualization and in insurance or reinsurance (life or non-life) will be an advantage Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan Capacity for innovation, forward-looking and group-wide networked thinking and action, strong service orientation, meeting realistic timelines, enjoy working in a team as well as very high level of commitment Very good command of English as well as a willingness to travel Experience of insurance/reinsurance industry would be an advantage Knowledge of a local Asian business language would be an advantage "
258,TeSA pilot programme,SGTech,"$4,000to$4,000Monthly","Roles & ResponsibilitiesIf you are a tech professional with some technical skills and looking for career opportunities, this could be the programme for you! This opportunity will give successful candidates 3-6 month attachments in high-growth tech companies that would allow them to experience working in a
dynamic
and
fast-paced
environment. Its an excellent experiential learning opportunity that could lead to full-time employment after the programme. Read more
here! Some available positions include:  Product Manager Project Manager Developer Business Development Regional Operations Regional Business Development Data Engineer Intern Senior Web Developer Software Release Engineer Network Engineer
 System Engineer
 And many more!  
 Requirements Only open to Singapore Citizens / Permanent Residents, aged 40 and above . Some IT technical skills are required Willingness to learn and adapt Positive attitude  Note: This is a 3-6 month job attachment opportunity. Submit your application here (http://bit.ly/TeSApilotimmersive) and name your resume in this format - Last name, first name.
"
259,BI Developer,TECHCOM SOLUTIONS (SINGAPORE) PTE. LTD.,"$4,500to$7,500Monthly","Roles & ResponsibilitiesYou will be responsible for working and delivering within DWH/BI team regionally and aligning globally. 
Become an integral part of a thriving global team of Architects, ETL, BI Developers, Project Managers and Analysts YOUR RESPONSIBILITIES WILL INCLUDE: 






 Support day- to- day operations for DWH/BI (as a first contact point) with ETL and Cognos changes at the highest level of quality, ensuring that business users have a Tier-1 IT support experience. 






 Ensures production application systems are stable, highly available and performs consistently. 






 Ensures rapid restoration of service follows up on the permanent removal of defects and ensures quality service is provided in an efficient, effective, and proactive manner. 






 Works with DBAs and other IT teams to align with ETL and Cognos development quality. 






 Collaborates with IT business analysts to overcome issues impacting service delivery. 






 Participates in both systems and software upgrades for the region. 






 Acts as a team role model and change-agent. 






 Engage with offshore ETL and Cognos developers and partner together to achieve delivery. 






 Promotes and follows the guidelines of the Corporations Code of Business Ethics and Values. 






 Performs all other related duties as assigned. 






 Executes ETL and Cognos enhancements. 






 Travels up to 5%. 
 Requirements






 Bachelors degree preferably in Computer Science, Engineering or related discipline.
 






 6-8 years relevant experience in IT or equivalent with preferably in a manufacturing environment. 






 This role requires strong technical skills specific to ETL ((Informatica or Oracle ODI),Cognos BI and production support. 






 Hands-on experience with reporting and BI tools, especially the Cognos Suite v10 & 11 ( with Reporting MDX) 






 Strong technical and functional knowledge of Data Warehouse and related software including design, development. 






 Expert level proficiency in developing Data Integration and EDW solutions based on:- Data Integration: Informatica PowerCenter and ODI (good to have) Database: Oracle, Progress or equivalent with hands-on experience of PL/SQL 






 Strong communication and interpersonal skills required. 






 Experience working with matrixed and geographically distributed teams, and an offshore/onshore collaborative environment. 
 BENEFITS 






 Medical Consultation coverage for self, spouse and children. 






 Medical Consultation Dental coverage for self, spouse and children."
260,Data Engineer,MOZAT PTE. LTD.,"$3,500to$5,500Monthly","Roles & Responsibilities1. Participate in R&D and performance optimization of big data platforms; 2. Responsible for the construction and maintenance of big data platforms, including but not limited to BI systems, scheduling systems, metadata systems, development platforms, data analysis/mining platforms, etc.; Requirements1. Bachelor degree or above, computer related major 2. Familiar with data warehouse theory, with ability to comb with complex business requirements 3. Proficient in SQL development, proficient in one or more of relational databases such as Mysql 4. Proficient in Hadoop and MapReduce application development, proficient in one or more of big data development tools such as HBase, Hive, Storm, Impala, Kylin, spark, etc. 5. Be familiar with Linux system, have shell, python and other script development capabilities are preferred 6. Strong in learning ability, likes to study open source new technologies, has a team concept, and has the ability to solve problems independently."
261,Data Scientist,RIDIK PTE. LTD.,"$7,500to$10,000Monthly","Roles & ResponsibilitiesExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets o Experience working with and creating data architectures o Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks o Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications o Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting o Knowledge and experience in Decision Trees, Text mining, social network analysis, etc. o Experience querying databases and using statistical computer languages: R, Python, SLQ, etc. o Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc. 
o Clear understanding of concepts and principles in Visualization and Dash-boarding o Good understanding of Semantic Models in QLIKVIEW, TABLEAU and best practices of Visualization design General skills o Should have 8  12 years of experience manipulating data sets and building statistical models 
o Should have a Masters or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools: 
o Experience creating and using advanced machine learning algorithms and statistics: regression 
o Experience creating user stories or defining business use cases for applying data science o Should have excellent communicational skills, both written and verbal and capable of smoothly interfacing with the customers Requirementso Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets o Experience working with and creating data architectures o Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks"
262,Data Engineer,Company Undisclosed,Salary undisclosed,"Roles & Responsibilities Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Big Data technologies Assemble large, complex data sets that meet business requirements Create and maintain optimal data pipeline architecture, and pull information together from different sources Structuring data for use in the analytics application; ensure optimal data delivery architecture is consistent throughout Identify, design, and implement internal process improvements  automating manual processes, optimizing data delivery, designing infrastructure for greater scalability Work with stakeholders to assist with data-related technical issues, support data infrastructure needs and drives innovation. Build processes supporting data transformation, data structures, dependency Manage projects scope, goal and deliverables and track timeless of implementation to meet expectation Manage system health to ensure high system availability and perform review for capacity expansion  Requirements Degree in the field of computer science, information systems, computer engineering or equivalent At least 3 years of SQL & Python programming skills Industry experience in a report development, data science, business analytics, business intelligence or comparable data engineering role, including data warehousing and business intelligence tools, techniques and technology will be preferred Broad knowledge of various aspects of Big Data with good understanding and hands-on experience with good business analytical skills Experience with Tableau to create impactful reports, visualizations, and interactive dashboards. Experience with reporting, descriptive statistics, probability, and cleaning of big datasets. Familiar with compiling, deploying and configuring open source data science tools including Python, R, Spark, etc. Able to work in a multi-cultural with distributed teams globally. Effective bilingual, to be able to liaise with China counterparts "
263,Data Scientist,Company Undisclosed,"$3,200to$5,500Monthly","Roles & ResponsibilitiesResponsibilities: Align to, Understand, and Prioritize Analytic Goals to Address Business Opportunities and Value 
 
 Maintain an intimate understanding of company and department strategy 
 
 Understand the business objectives in order to develop or establish success criteria metrics 
 
 Translate business problems into one or more data science projects/solutions 

 Lead Efforts to Identify Signals in Data that Address Use Cases 
 
 Understand business processes (data sources and meaning) 
 
 Manage and optimize data discovery and cleansing 
 
 Understand and collect relevant data 
 
 Identify new data sources in the network that will create new insights to business needs 
 
 Explore relevant data through visualization and statistical methods 

 Collect, Organize, and Prepare Data for Analysis 
 
 Work with various volumes of data from multiple disparate sources and perform data analysis and mining to generate solutions to business problems 
 
 Ensure processes taken to maintain data integrity 
 
 Understand available data and what data is relevant 
 
 Collaborate with data architects (IS engineers, BI engineers, DBAs, etc.) to ensure that data needed is available 
 
 Develop and automate ETL jobs for various volumes of data 

 Uncover Patterns in Data, Develop Models, and Evaluate Validity of Solutions 
 
 Develop expertise in data mining and analytic methods 
 
 Determine statistical validity and significance (pick out signals from noise) 
 
 Identify and apply appropriate analytical models 
 
 Evaluate results using statistical methods and improve the model where appropriate 
 
 Develop predictive models 

 Deploy Data Science Models into Business Processes 
 
 Present findings and deliver recommendations using effective presentation and data visualization techniques 
 
 Collaborate with software engineers to deploy data science solutions into production applications 
 
 Ensure that the models are easy to support and maintain 
 
 Regularly review deployed models and monitor for continual improvement 
 
 Validate that the business value has been met RequirementsRequirements: Doctorate Degree or equivalent experience in Statistics/Physics/Computer Science/Engineering/Operations Research/Applied Maths Good knowledge in programming and statistics. Excellent code writing abilities. Experience in Data-mining and yield analysis. Experience in developing application and data-source in Hadoop big data platform will be advantageous."
264,"Senior Associate - Data and Analytics, Advisory",ERNST & YOUNG ADVISORY PTE. LTD.,"$4,100to$8,200Monthly","Roles & ResponsibilitiesPowered by big data and advanced technologies, insights from analytics are disrupting everything from how companies create competitive advantage to day-to-day business processes. But companies dont have analytics problems; they have business problems that analytics can address.  Our view is that the human element is just as critical as technology and data to realizing true value from analytics. 
This involves individual and organizational considerations that become the bridge from data to insights to action. 
 

 The opportunity  As a Senior Consultant, you will deliver value-added services to our clients and you are required to be a specialist in managing both structured and unstructured enterprise data and deliver analytics-related solutions to Ernst & Young clients across Asean. 
In addition, you are required to communicate effectively with the project manager & team members in the region regarding the progress of the project and be a role model to the team members in exhibiting the Ernst & Young best practices.  At Ernst & Young, the true value lies in embedding analytics deeply into business processes at the point of where decisions are made  by human beings. 
 Your key responsibility:
  This is a role where no two days are the same  so youll find yourself taking on plenty of new responsibilities as you go. Youll work alongside clients and colleagues, balancing your time between developing security strategies, advising stakeholders, providing workshops and supporting business development. If youre flexible and ready to adapt to a constantly changing environment, theres no better place to develop your skills. Since youll be working directly with clients, some travel will be required.  Skills and attributes for success  Analytical and problem-solving skills combined with experience in leveraging data analytics to drive insights and business decisions.  Analyze clients business and supply chain requirements Develop supply chain optimization models and statistical analysis using packaged as well as custom optimization software tools (e.g. LLamasoft Supply Chain Guru, LLamasoft Transportation Guru, SAS, R, Python, GAMS)
 Analyze and interpret optimization results and derive insights
 Communicate technical insight from analytics and modeling to senior executives in a business-oriented and pragmatic way  Provide critical thinking and subject-matter expertise to quantitative and qualitative aspects of client engagements Strong attention to details and ability to multi-task. A strong work ethic. A willingness to travel to meet client needs; travel is estimated at 20%.  RequirementsTo qualify for the role you must have  BS in Engineering or Computer Sciences 3-
7
years of working experience in consulting, analytics software-as-a-service or technology industry. Strong experience in solving supply chain planning and design problems using quantitative approaches Working knowledge of commercial network design tools such LLamasoft SCG, IBM LNP or similar
 Advanced data analysis and processing skills in MS Access, Excel, and SQL Familiarity with custom optimization engines such as GAMS, LINDO, CPLEX Working knowledge on a statistical package such as SAS, SPSS, R or Python
 Working knowledge of visualization tools like Tableau, QlikView or any other BI solution. Strong understanding of supply chain design levers and metrics Understanding of supply chain planning at strategic, tactical and operational level
 Fundamental understanding of science behind optimization Articulate, with excellent oral and written communication skills. Adaptable, able to interact and build strong relationships with people from a diverse range of backgrounds. Intellectually rigorous, with strong analytical skills and a passion for data. Sound logical reasoning and deep thinking ability. Ability to work accurately to a high level of detail.  Ideally, youll also have  MS in Operations Research, Industrial Engineering, Decision Sciences, Engineering or Computer Sciences (preferred) Supply Chain certifications such as CSCP / CPIM are a plus  We offer a competitive compensation package where youll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package includes medical and dental coverage, and a range of programs and benefits designed to support your physical, financial and social wellbeing. Plus, we offer:  
 What working at EY offers Were interested in flexible professionals with excellent problem-solving skills and the ability to prioritise shifting workloads in a rapidly changing industry. Youll also need the confidence to give professional advice and guidance to colleagues and clients from a diverse range of cultures, often with limited information  both verbally and in writing. If youre a fast learner, with strong influencing skills and a genuine passion for information system security, this role is for you.   What we look for  Support and coaching from some of the most engaging colleagues around. Opportunities to develop new skills and progress your career. The freedom and flexibility to handle your role in a way thats right for you.
   About us 
 EY is a global professional services organisation providing advisory, assurance, tax and transaction services. We are committed to doing our part in building a better working world for our people, our clients and our communities. And we are united by our shared values and a dedication to delivering exceptional client service. 
 Want to get to know us better?  Visit www.ey.com/SG/careers
 Become a fan on Facebook: http://www.facebook.com/EYSGcareers
 Connect with us on Linked In: http://bit.ly/EYLinked_Careers
 Watch us on YouTube: http://www.youtube.com/ernstandyoungglobal
 
 We regret that only shortlisted candidates will be notified.   2017 Ernst & Young Advisory Pte. Ltd. All Rights Reserved."
265,Datawarehouse Consultant,Company Undisclosed,"$4,500to$6,500Monthly","Roles & ResponsibilitiesThe Power BI developer is to develop reports, dashboards and visualization using Microsoft products (e.g. Excel, Power BI, SRSS, SISS), QlikView or Spotfire as well as managing and administer the data warehouse system (MSSQL) database with data source from local and overseas systems for the operation finance team. Requirements 3+ years experience developing and implementing enterprise-scale reports and dashboards, including: 	 Working with users in a requirements analysis role Experience with Datawarehousing application implementations Create model from database (modelling experience) Understanding of data integration issues (validation and cleaning), familiarity with complex data and structures   Programming / scripting experience in: 	 Microsoft Power BI MICROSOFT SQL SERVER (SRSS, SASS, SISS) EXCEL MACRO C#,
ASP.NET Power Shell Scripting   Some hands-on experience with MSSQL administration and technical support.
 Some
working experience on
providing system administration and technical support to Reporting tool such as Excel. Some experience in Performance tuning related to reporting queries Experience in Windows Environment "
266,Data Analyst,WOODPECKER ASIA TECH PTE. LTD.,"$3,500to$6,000Monthly","Roles & ResponsibilitiesThe Job:  Our Data Analyst is the person responsible for enhancing our analytics and performance management framework. The Data Analyst will be responsible for carrying out reporting and analysis on datasets and provide insights to help improve the GoBear business model. The ideal candidate should be an eager learner, have prior experience in Quantitative domains such as analytics and should be keen to work in a dynamic start-up. Responsibilities: Implement statistical and machine learning techniques and create insights from data.  Use Google Big Query, Compute Engines, Dataproc and other Google Cloud Platform features to automate various analytics processes.  Use data visualization tools such as Tableau, Data Studio, Klipfolio etc to provide actionable insights to both internal teams and external partners.  Collaborate with business owners to understand business problems.  Complete ad-hoc projects and tasks as required.  Work hands-on and share knowledge between team members.   Requirements Bachelors or Masters in quantitative disciplines such as mathematics, engineering, computer science, statistics or economics, with 3-6 years relevant experience. Proficient in machine learning and statistical techniques. Proficient in R, Python and SQL.  Experience with Google Cloud Platform features will be an advantage.  Proficient in oral and written communication in English, as well as effective interpersonal and communication skills.  Good time management and prioritization skills. "
267,Associate  /  Senior Data Scientist,NCS PTE. LTD.,"$4,500to$8,500Monthly","Roles & Responsibilities Work with customers to identify opportunities where Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) can be applied to data to solve the customer painpoints. Individually or collaborate with other team members to develop AI/ML/AA prototypes/Proof-of-Concept/Proof-of-Value to derive actionable insights from data. Collaborate with the customers and internal stakeholders to architect the overall supporting storage and compute infrastructure to support the deployment of the AI/ML/AA models, applications, and visualisation of the results.

 Collaborate with the relevant project managers to conceptualise, develop project scope, requirements, budget, and timeline for the implementation of the identified AI/ML/AA projects. Implement the AI/ML/AA projects and to ensure that the projects AI/ML/AA objectives are met.  

 Requirements PhD/Masters/Bachelors (with good honours) in Computer Science, Statistics, Applied Mathematics, Operations Research, or related disciplines. Prefer candidates with 3 or more years of working experience, with at least 2 years of Artificial Intelligence (AI), Machine Learning (ML), and Advanced Analytics (AA) experience. Domain experience in public safety, defence, transport, education, and healthcare are highly desired. AI/ML/AA experience in smart city, social media, and procurement are also highly desired.
 Good knowledge of AI/ML/AA models, software, and tools with the ability to conceptualise and architect the key components of AI/ML/AA projects; and to develop prototypes using statistical software packages such as R/SAS/SPSS. Experience working with very large data sets, including statistical analyses, data visualization, data mining, and data cleansing/transformation and machine learning. Experience in solutions using technologies such as Hadoop/Hive/Hbase/NoSQL and developer skills in Python, Perl, and Java are highly desired. "
268,ETL Developer,COMTEL SOLUTIONS PTE LTD,"$4,500to$6,750Monthly","Roles & Responsibilities ETL techniques, including the development of staging areas, recoveries, data cleansing, fact and dimension tables, slowly changing dimensions, conformations, and the use of surrogate vs. natural keys. Develop robust and precise ETL routines to load the Data Warehouse from various sources. Works with the Business Intelligence Analyst to identify and understand source systems to meet business requirements. Maps source system data to data warehouse models. Develops and tests for extraction, transformation, and load ETL processes. Defines and captures metadata and rules associated with ETL processes. Adapts ETL processes to accommodate changes in source systems and new business user requirements  Requirements Minimum 2 years working experience in Informatica (versions 8.6, 8.6.1 and 9.1) ETL coding ,design and implementing ETL process layer Experience with Oracle and PL/SQL Good understanding of ETL and Data Warehouse concepts and technologies "
269,"VP, Senior Visualisation Engineer, Group Consumer Banking and Big Data Analytics Tech (180001R9)",DBS BANK LTD.,"$9,500to$18,000Monthly","Roles & ResponsibilitiesSparkola is a new team that is highly cross-functional and has an ambitious vision. In this role, youll have the opportunity to define how DBS visualizes data and enable teams and users to make data-informed decisions. Data Visualization Engineers will help build custom visualizations, data-rich user interfaces, and shared visualization components to help our clients see and reason about data. Youll have the opportunity to leverage our massive datasets, work with the latest web technologies including d3 and React, and influence all our data products. You will have the opportunity to lead other engineers as we grow our team.   Responsibilities  Build visual interfaces and shared visualization components under supervision of senior engineers Collaborate with Data Engineers to iterate on the design and implementation of data visualization products Participate in design and code reviews 	
  Requirements A passion for UI and data visualization and a keen design sense.
 UI and UX skills, with experience building web and/or mobile interfaces Experience with cutting-edge JavaScript libraries and frameworks including d3, React, and redux Commanding grasp of HTML, CSS, and related web technologies Entrepreneurial spirit and out-of-the-box thinking "
270,Data Analyst,HP SINGAPORE (PRIVATE) LIMITED,"$3,600to$6,000Monthly","Roles & ResponsibilitiesHP is the worlds leading personal systems and printing company, we create technology that makes life better for everyone, everywhere. Our innovation springs from a team of individuals, each collaborating and contributing their own perspectives, knowledge, and experience to advance the way the world works and lives. We are looking for visionaries, like you, who are ready to make a purposeful impact on the way the world works.  At HP, the future is yours to create! If you are our Data Analyst in Singapore, you will have a chance to   Improve the efficiency of the operations by generate business intelligence (BI) reports using various platforms to visualize data insights Build data models and algorithms to predict process quality Build, communicate and maintain strong working relationship with local and Israel teams  Requirements
 Are you a high-performer?
We are looking for an individual with:  Bachelor's degree At least 2 years as Data Analyst or similar function Knowledgeable in SQL, and experienced design and build BI reports using Qlikview, Tableau or Power BI Good grasp of data analytics tools such as R, Python, or any scripting language Good analytical skill; good sense on numbers Excellent interpersonal and communication skills Ability to work independently and under tight deadlines Ability to work independently; proactive Good project management and multitasking skill Willingness to learn  HP is a Human Capital Partner  we commit to human capital development and adopting progressive workplace practices in Singapore."
271,Data Analyst,ROBERT WALTERS (SINGAPORE) PTE LTD,"$5,000to$6,000Monthly","Roles & ResponsibilitiesThe Client is a global recruitment consultancy specialising in permanent, contract and temporary recruitment across all industry sectors and at all levels of seniority, offering a comprehensive service in each, managing the careers of the highest calibre candidates. 
The firms client base ranges across leading investment banks, multi-national corporations, smaller enterprises and business start-ups, covering all market sectors.
  About the Data Analyst Role: Working within the Systems Department, the holder of this position will be providing data support for the firms staff in the region in which they are based (e.g. EMEA or APAC) and also provide data support for other regions when required.  Key Responsibilities:  Providing data support for the companys main recruitment databases (Profile) e.g.
 Client Organisation Structure including addition of new records as requested by the business,
 Client Contact and Candidate records Structure, including merging of duplicates,
 Undertaking work to support Master Data Management and Data Quality Management initiatives as well as sustaining and improving data quality through ongoing tasks such as housekeeping of redundant data. Knowledge of business workflows in Profile across the region to support Admin staff with creation of contracts and letters. Manage the Code change management process: handle requests for code additions and changes; update code tick-sheets; communicate changes to the business; audit code usage and report to management. First-line support for BI applications (reports, dashboards etc..) developed by the BI Developers and Data Architects Monitoring and managing team job queue in incident-management system (currently Cherwell), logging additional requests received (by email or telephone), resolving within agreed timescales and keeping the client updated. Proactively identify opportunities to improve processes  RequirementsKey Requirements:  Bachelors degree specializing in Mathematics, Engineering, Computers or Economics. At least four (4) years of in-depth work experience with in an analytical/ reporting environment(e.g., gathering requirements, developing, compiling and preparing dashboards, reports, ad-hoc 
applications, etc.) At least 3+ years of experience with tools like Micro Strategy/ Tableau/ Qlikview etc.
 Knowledge of Profile is a plus Good analytical and problem solving skills Has strong presentation and collaboration skills and can communicate all aspects of the job requirements Strong problem solving, time management and organizational skills  This is a great role to be a part of a team which is working on bringing new technology and way of work to the daily operations of employees.  With offices spanning five continents, the firm is able to offer a truly global recruitment service to both clients and candidates alike.  If you have the passion for data and want to work on a regional level role, this is for you. Apply today to discuss this opportunity.
 
"
272,QE Fault Detection / Data Engineer,Company Undisclosed,"$4,000to$8,000Monthly","Roles & ResponsibilitiesJob Description As an FDC Engineer, you will responsible for, but not limited to, developing/improving/maintaining Fault Detection and Classification strategies at our manufacturing facilities across Backend Operation, understanding system dependencies, project planning, engaging in cost reduction efforts, and actively participating in Environmental, Health, Safety and Security procedures. You will work with Manufacturing Central Team (MCT) Engineering and Backend Site Quality teams to provide direction and assistance with FD functions.
 You will help to coordinate and implement FD control systems across multiple international facilities with the aim at reducing overall product & process variation which will result in higher process margins, increased yield and reliability with lower costs. It is highly desirable if the applicant has experience in using machine learning and statistical techniques to create state-of-the-art data products (decision support and decision automation data systems), utilizing extensive and diverse Big Data sets from our manufacturing teams . 
 Responsibilities and Tasks (include, but not limited to): Deploy standards and Business process for Fault Detection and Classification for Semiconductor Manufacturing Facilities: Identify Fault Detection and Classification Dependencies Fault Detection and Classification for specific manufacturing area Implement, comply, maintain and improve established standards Test and implement system changes and improvements Manage the implementation of controlled modifications using Change Management methodologies, from network support and direction drive perspective. Support sites on: Deployment and on-going maintenance of FDC strategies (data collection, summarized indicators, limits, OCAPS, etc.) using AMAT E3 in an effort to minimize risks of excursion and scrap Troubleshoot strategy/tool/system related issues, including proper documentation, escalation, and follow-up to completion Monitor strategy performance and effectiveness and identify opportunities for improvement Define and deploy worldwide FDC best known methods (BKM), business rules and standards, and change management procedures Align, share, and review FDC strategy best practices and excursion/scrap prevention with world-wide sites FD counterparts. Frequent interaction with customers, and general support to explore and analyze and promote the use of FDC data Understand and Maintain System Dependencies: Evaluate and monitor user lists for program access in compliance with established product integrity, security, and intellectual property rights protection standards Facilitate Fault Detection and Classification
 Coordinate Fault Detection and Classification tasks utilizing various programs, including MAM, Process Control Systems, Statistical Process Control, Advanced Process Control, Fault Detection and Classification, GEM/SECS/GOUI, Engineering Change Notice, and Global Conversion Process Project Planning Act as a liaison between information systems, production area management, and engineering management in matters concerning Fault Detection and Classification Anticipate or diagnose automation issues across multiple equipment types within a given manufacturing area Define and deploy projects that have impact on a global scale Organize and execute project plans efficiently and effectively Cost Reduction
 As a Team Member you are responsible for reducing costs associated with your area. This responsibility may include owning and completing cost reduction projects, identifying cost effective sustaining/manufacturing improvements, minimizing regular expenditures, and helping to promote a cost-conscious culture. Ensure that effective requirements, standards and procedures exist for functional areas and sites to accomplish given manufacturing operations Provide direction on the facilitation of the practical application of FD within Backend Manufacturing environment Work with global teams such as Global Quality, Site Quality teams, Operations Central Teams, and IT to assess the compliance of functional areas and sites to global standards Ensure all business needs are properly documented, validated, and escalated as needed. Analyze findings and assess potential problems within functional areas and sites Compile and issue formal reports detailing findings and potential problems Follow up on action items to ensure solutions/corrective actions are implemented Ensure solutions/corrective actions are aligned throughout the backend manufacturing network Ensure BKM sharing and alignment spans across all functional areas and sites regardless of technology and/or site mission differences Facilitate and maintain world class data analysis skill sets and tools for engineering efficiency to support data driven decisions by engineers Provide tactical support to the MFG Sites as required for issues of yield and quality, working with other peer groups RequirementsQualifications: A working knowledge of a wide variety of applied statistical methods, including categorical data analysis, statistical sampling methodology and applied statistics for quality and productivity improvement, such as SPC, design of experiments (DOE), multiple regression and ANOVA, nonlinear regression, logistic regression, random/mixed/fixed effects and variance components modeling, statistical reliability methods, nonparametric statistics, survey design and analysis, re-sampling methods, mathematical statistics, and others Desire to identify and/or work on data analysis projects that will improve product (NAND, DRAM, etc.) yield and quality, reduce costs and cycle time, and optimize business practices Ability to extract data from different databases via SQL and other query languages and applying data cleansing, outlier identification, and missing data techniques Ability to work with small, big, structured, semi-structured, and unstructured data Ability to teach short-courses in applied statistics to engineers and technical management Capable of visually summarizing and presenting advanced analytical results and monetary benefits to middle and executive management General understanding of the back end operations for component assembly, component test, module/SSD assembly & test, and Finished Goods Experience in the areas: statistical modeling, feature extraction and analysis, supervised/unsupervised/semi-supervised learning. Ability to extract data from different databases via SQL and other query languages and applying data cleansing, outlier identification, and missing data techniques. Strong software development skills. Well versed in Tableau and visualization software, JMP or analytical tools Strong verbal and written communication skills. A strong plus point if the desirable skillsets are available: Machine learning and other advanced analytical methods Fluency in Python and/or R Hadoop (Hive, Spark, HBase) Teradata and/or another SQL databases Tensorflow, and/or other statistical software including scripting capability for automating analyses Experience working with time series data, images, semi-supervised learning, and data with frequently changing distributions is a plus. 
 
 Program Management: Able to multitask and adapt to changing priorities Demonstrate ability to move projects effectively through project lifecycle  initiate, plan, execute, and close  while balancing time, cost, quality, scope and risk / opportunity constraints Motivate stakeholders and all project team members to take ownership of project and its success Direct and coordinate the activities of others to accomplish project tasks successfully Prioritize and manage multiple conflicting projects based on Backend and corporate objectives Lead cross-functional initiatives and enable projects that support Company, MCT and site objectives Develop metrics for benchmarking Performance.
 Identify and share BKMs across departments and sites and track compliance in aligning to BKMs 
 
 Communication:
 Communicate and respond to issues in a timely manner Use active listening skills to effectively communicate with other team members Express ideas and issues in an organized, effective, and respectful manner Use voice, tone, and body language to enhance communication Written communication is complete, concise, grammatically correct, and appropriate for the audience Invite feedback for clarification and self-improvement Demonstrate cultural sensitivity - Show respect for different cultures and languages; learn to pronounce names correctly; speak English slowly and clearly when interacting with non-native English speakers; invite feedback to ensure others understand Use conference call etiquette and enforce during all meetings Be an active participant in all group discussions, meetings, etc (internal and external) Flexible and accommodating but willing to voice opinions and make recommendations 
 
 Education Required Minimum B.S. degree in Statistics, Mathematics, and/or Engineering with an emphasis in Applied Statistics 
 
 Experience Required Minimum 3 years of experience in semiconductor industry applying a variety of statistical methods, including process control and metrology Experience with R, JMP, and/or other statistical software including scripting capability for automating analyses 
 
 Workplace Travel Required? Yes Travel Details Periodic travel to MFG sites for cross-training, alignment activities and/or auditing purposes"
273,"Data Scientist, APAC (Singapore)",Company Undisclosed,"$4,000to$8,000Monthly","Roles & ResponsibilitiesWe are considering candidates for both junior and experienced positions. Who we are The Data Science team based in Singapore has the charter to understand user behavior and accelerate user growth for our platform, especially in international markets. We work on a mix of longer term analysis (such as how can we be smarter about how we send emails and notifications to our users; or how can we measure the impact of various user acquisition efforts) and shorter term tactical work (such as opportunity sizing for certain campaigns). The common thread between all the analysis we do is to seek to have a better understanding of how our users are engaging with our products. What youll do Your work with our large amounts of structured and unstructured data to understand how our users are using the product, and communicate these insights with stakeholders (product managers, executives, business decision makers etc). For more experienced hires, you will own important project areas from start to finish. That work includes defining an important roadmap of data science work and executing it. You are highly technical and hands on but you wear a product manager hat easily to make your projects successful. Who you are  You care about people: You have fundamental respect for all people You are in awe of the ability to understand and help 100s of millions of people  You are great at:  Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto Exploring and visualizing data to drive insights Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their social media posts and their interests. Designing and implementing metrics that help teams focus on what to optimize for Understanding A/B testing and are able to statistically interpret experimental results Working with Product Managers, engineers and designers to understand where data can be helpful Transforming complicated problems into simpler, tractable ones Communicating with technical and non-technical stakeholders  RequirementsRequirements:  Bachelors, Masters or PhD degree in Computer Science, Statistics, Math, Engineering, or other quantitative discipline Some experience with one or more object oriented languages like Java, Scala, C++ Some experience with scripting languages like Python or Ruby etc. Some experience with statistical programming environments like R or Matlab Bonus points: Experience with machine learning Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects "
274,Senior / Data Science Engineer,Company Undisclosed,"$4,000to$8,000Monthly","Roles & ResponsibilitiesJob Description As a Data Science Engineer, your main responsibility will be working with enormous data and conduct analytics on complex datasets to assist the factory to better understand manufacturing operation and provide solution to pressing manufacturing process issues to drive down manufacturing cost and cycle time and improve product yield and quality. You will identify, collect and manipulate new semi structured or unstructured datasets from disparate sources to make them available in Big Data Platform for user query and analysis, and provide data visualization to create new insights to business needs. You will also build and implement frontiers predictive analytics model, strategy and operation to identify untapped opportunities and expose hidden risks buried inside vast amounts of data. 
 Responsibilities and Tasks - Work with large volume of data on the Big Data platform, perform data analysis and mining to generate solutions to cycle time/cost/yield/quality problems. - Develop ETL jobs for large volume of data that is fast and reliable in Big Data platform. - Develop Big Data analytic solution to analyze and link multiple data sources in Big Data platform. - Create new visualization software that leverage machine learning and predictive analytic to bring new insights and solution to the business. - Build forecasting and optimization models using advanced procedures like statistical modeling. 
 RequirementsEducation Bachelors or Masters Degree in Electrical, Electronics, Microelectronics Engineering, Semiconductor, IC Design or Computer Science or equivalent experience. 
 Qualifications - Good experience with Hadoop Ecosystem and Components specific to Big Data: Apache Pig/ Hive/ Spark/ HBASE/ MapReduce/ Sqoop and etc. - Good knowledge of Machine Learning Algorithms. - Fluent with SQL and R or any other statistical analysis tool. - Strong interpersonal skills with the ability to work effectively with a variety of people. - Proven ability to work with minimal supervision, multi-task, prioritize and manage projects. - Excellent organizational skills with a strong attention to detail. - Excellent code writing abilities in Java or Python programming language. - Good foundation in statistics, modeling, analytics and math. - Demonstrated ability to be dynamic and proactive. - Experience in Semiconductor Industry is an added advantage."
275,Data Analyst,INTERNATIONAL APPLICATION SOLUTIONS PTE LTD,"$8,000to$10,000Monthly","Roles & ResponsibilitiesHiring for Data Analyst positions for a leading banking project.  Interact with the business to identify, capture and analyze business requirements. Improves business processes as intermediary between Business and IT. Perform data analysis including data mapping, report analysis, interface definitions. Supporting project management  RequirementsDeep analytical skills 





 Business intelligence understanding. 





 Data Visualization tools (tableau). 





 Enjoying discovering and solving problems Excellent communication skills 





 Conscious listening and storytelling. 





 Strong interpersonal, oral and written communication and presentation skills. 





 Ability to communicate complex findings and ideas in plain language. 





 Written and verbal communication, preferably with technical writing skills. 





 Being able to work in teams towards a shared goal; Project and resource management skills 





 Resilient project juggler 





 Strong experience in user testing and project management Specific Qualifications Required  Experience on with visualization tools (tableau) Experience with data management tools (Ab initio) is required  3+ years of associated work experience in a relevant role Excellent interpersonal communication skills to explain complex technical topics in an easily digestible manner Willingness to work independently and as part of a team Knowledge of banking application. Technical expertise regarding data models, database design development, data mining and segmentation techniques. Strong knowledge and experience with reporting packages/tools (tableau etc.), databases (SQL etc.), Knowledge of statistics or experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.). Adept at queries, report writing and presenting findings. Working knowledge in any analytical tools like Alteryx, Dataiku.  
 
 
 
"
276,Senior Bioinformatics Specialist,ENGINE BIOSCIENCES PTE. LTD.,"$90,000to$140,000Annually","Roles & ResponsibilitiesEngine Biosciences is a venture-backed biotechnology company discovering and developing novel therapeutics and precision medicines, utilizing a proprietary platform that integrates massively parallel biological experimentation with data science, machine learning and AI.
 Led by scientific experts from MIT, Harvard, Mayo Clinic and UCSD, and successful drug developers, informaticians, and company builders, Engine is working on multiple programs and therapeutic areas and growing rapidly across US and Asia. The Sr. Bioinformatics & Data Scientist will analyze multi-dimensional biological and genomics data, enhance algorithms and develop novel methods for the utilization in Engines analytics platform that combines advanced system biology analytics with genomics data science and machine learning for accelerated drug discovery and biomarker identification. 
The successful candidate will bring extensive hands-on industry experience in bioinformatics, algorithm development, in-silico drug discovery, data science, machine learning and cloud compute. 

As a Sr. Bioinformatics and Data Scientist, you will collaborate globally with Engines teams and external partners in Asia, US and EU. 

  Extensive hands-on industry experience in Next Generation Sequencing (NGS) and multi-dimensional omics data analysis, algorithm development and machine learning in application for drug discovery and biomarker identification. Real time analytics, predictive models, classification, in-silico validation, queries and visualization of high throughput biological data. Strong peer reviewed publication record in bioinformatics, data science and machine learning. Experience in biological interpretation, pathway analysis and disease biology. Amazon Web Services (AWS) experience including DevOps, Security, VPC, EC2, EMR, Docker, SPARK, ElasticSearch, Lambda, Redshift, and Amazon Machine Learning (TensorFlow, MXNet). Experience working across multiple time zones with executive leadership, scientists and engineers.  Requirements Ph.D. in Bioinformatics / Statistical Genetics / Machine Learning / AI, or related field. 3 years of industry experience in bioinformatics, genomics data analysis, algorithm development and machine learning. 3 years of industry experience in cloud based (e.g. AWS) data science. Programming skills in Python, AngularJS, Node.js., Java. R., Matlab, SQL and NoSQL dbs. Agile development methodologies such as SCRUM and Kanban. Strong communication and global collaboration skills. "
277,Sr Report Developer,ECNET LIMITED,"$5,500to$6,500Monthly","Roles & Responsibilities Designed the ETL framework and developed SSIS, SSAS, SSRS packages Stored procedure development for the SSRS reports Designing the tactical and strategic data marts for the operational and strategic reporting Data marts with the data items required by Actimize RequirementsMSBI  SSIS, SSRS, SSAS"
278,Data Scientist,Company Undisclosed,"$3,000to$5,500Monthly","Roles & Responsibilities Serve as primary source of data insights supporting internal and external constituencies Analyse and translate data findings into meaningful, actionable insights  including synthesizing relevant insights from different customer touch points and data sources Lead, design and implement quantitative analytical frameworks, including scalable predictive models, customer segmentation and marketing mix optimization that improve business performance and customer engagement Institute and adopt best practices in data science, platforms and approaches. Establish internal organisational standards and benchmarks Work with other teams in Mediacorp to understand business needs, document data and data integration requirements, and resolve conflicting business/data architecture rules. Ensure compliance with internal customer contact governance policies and drive closed-loop measurement through smart data capture. Become an internal authority on Mediacorps data tools and resources. Function as a power user of data analytics to guide other business users. Support ad-hoc business intelligence and other strategic initiatives  Requirements PhD or MS degree in Statistics, Mathematics, Machine Learning, Operations Research, CS, Econometrics or related field. Minimum 5 years hands-on experience in data science. Demonstrated expertise in developing and implementing a full range of analytical techniques to address commercial challenges. Proficiency in at least one statistical analysis tool such as R or Weka. Demonstrated experience with distributed databases and query languages. Proficiency in at least one programming language (preferably Java, C++, Python, or Perl). Must possess exceptional business judgment to identify core business objectives; synthesize and interpret disparate quantitative information, develop meaningful insights and clearly disseminate to key stakeholders Strong project management and time management skills. Able to lead data initiative independently with minimal supervision. Relevant experience in web, video, mobile or adtech domain is a plus. "
279,Data Analyst,ASIA FUSION TECHNOLOGY PTE. LTD.,"$3,000to$6,000Monthly","Roles & ResponsibilitiesJob Description  Design and implementation of machine learning & analytics, Python based. Development of SSRS reports to support team decisions Usage of machine learning algorithms to predict player behaviour, enhance the player experience and improve business KPIs Build effective working relationships with engineer to come up with solutions that allow stake holders to easily visualize data Build a strong understanding to uncover insights  This role reports to the Team Lead.
 RequirementsJob Requirements   You should have at least 4 years of experience in data analytics, or data science related projects Bachelor Degree Holder in Computer Science, Mathematics, Engineering, Business Analytics, Economics Comfortable with writing code (Python or C# would be advantageous) Passionate about analytics & statistics You should be culturally flexible and enjoy working with teams from across different countries. Strong communication skills are a must Decent command of English and ability to speak Mandarin a plus You should have hand-on experience on the whole life cycle of building data product "
280,Data Scientist - Grab Financial,GP NETWORK ASIA PTE. LTD.,"$10,000to$15,000Monthly","Roles & ResponsibilitiesGet to know the Role:  Develop a deep behavioral understanding and intuition of our
passengers and drivers,
especially in the space of how they would violate our policies and game our systems Manage
and
own the
entire
end-to-end
lifecycle of
designing
models, working with
Engineering for implementation, to maintenance and
enforcement Generate multivariate statistical
models to identify
latent factors, preventive and
preemptive
capabilities that the trust framework requires Interface with
business & operation teams to formulate solutions & product changes informed by your findings Work independently or in a team to solve complex problem statements   The day-to-day activities:  Translate these intuitions into actionable,
creative
insights that produces heuristic or classification
models to identify
and take down those who violate our Terms of Services Test and validate these insights via rapid experimentation and deployment  RequirementsThe must haves:  Proficient in RDBMS such as PostgresQL or MySQL; and statistical programming in languages like R, Python, Java, C++ or SAS Experience in ETL, feature selections, modeling, model validation and conducting data analyses using R, SQL, Python or any JVM languages Deep understanding
and implementation experience of predictive modeling algorithms such as logistic regression, neural networks, forward propagation, decision trees and heuristic models, with familiarity dealing with trade offs between model performance and business needs Experience in
interfacing
with
other
teams and departments to deliver impact solutions for organisation Self-motivated, independent learner, and enjoy sharing knowledge with team members Detail-oriented
and efficient time manager in a
dynamic
and
fast-paced
working environment  
 Really nice to haves:  Deep understanding
of the fraud space with hands-on knowledge of fraud, payments and risk, especially on tech products Experience in geospatial databases or graph databases Recent programming experience in a production environment Experience in Scala or PySpark on distributed systems Interest in working with MapReduce technologies (such as Hadoop / Spark) Familiarity with Python Scikit Learn, Panda or Spark ML/Mllib is a plus "
281,Data Analyst,CLARIANT (SINGAPORE) PTE. LTD.,"$3,300to$5,500Monthly","Roles & ResponsibilitiesResponsibilities: 
 Data Management  Understand, standardised and optimised process data with hands-on projects Interpret data, analyse results using statistical techniques and provide sets of data on existing data ecosystem to identify useful data required for digitalization and machine learning Identify, analyse, and interpret trends or patterns in complex data sets Work with the Digital Project team on data trends and analysis Work with project team to ensure collection and logging of data needed to provide insights of the operations Support and develop Digital Twin and simulation programmes Design smart, adaptive and flexible digital systems & process Carry out systems modelling, controller design and analysis  
 Data Interpretation and Optimization  Apply statistical techniques to understand operations and optimization Ensure highest industrial standards in data based optimization and simulation Develop algorithms for automated data base access, analytics and control  
 Competency Centre Management  Propose and develop new approaches in the field of digitization, implement new technologies Utilize information of product and production processes data to value-add to the process streams Ensure and lead cyber security and make sure data are well protected from external threats



















 






















  Knowledge Management






































































  Ensure responsible management of IP Develop Work Instructions, SOPs








 Regular review on latest technologies to enhance the performance of Clariant Digital Platforms














 






















  Training



























































  Train & exchange other sites of know-how in the field of data mining, cleaning, analysing and data interpretation Train people within Clariant to apply Data analytical tools (e.g. CLNX, Maintenance, Operations, Supply Chain)  RequirementsRequirements: 
  Diploma in Statistics, Computer Science, IT, Mechatronics or Electrical Engineering or Electronics Engineering or related








 Have knowledge/experience in Data Analyst or Data mining






 Have knowledge/experience in Basic and detailed engineering design Have knowledge/experience in SQL or other programming languages Have knowledge/experience in Operations and passion for driving digital transformation projects  






















 


















































































 


































"
282,"Data Scientist, APAC (Singapore)",Company Undisclosed,"$4,000to$8,000Monthly","Roles & ResponsibilitiesWe are considering candidates for both junior and experienced positions. Who we are The Data Science team based in Singapore has the charter to understand user behavior and accelerate user growth for our platform, especially in international markets. We work on a mix of longer term analysis (such as how can we be smarter about how we send emails and notifications to our users; or how can we measure the impact of various user acquisition efforts) and shorter term tactical work (such as opportunity sizing for certain campaigns). The common thread between all the analysis we do is to seek to have a better understanding of how our users are engaging with our products. What youll do Your work with our large amounts of structured and unstructured data to understand how our users are using the product, and communicate these insights with stakeholders (product managers, executives, business decision makers etc). For more experienced hires, you will own important project areas from start to finish. That work includes defining an important roadmap of data science work and executing it. You are highly technical and hands on but you wear a product manager hat easily to make your projects successful. Who you are  You care about people: You have fundamental respect for all people You are in awe of the ability to understand and help 100s of millions of people  You are great at:  Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto Exploring and visualizing data to drive insights Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their social media posts and their interests. Designing and implementing metrics that help teams focus on what to optimize for Understanding A/B testing and are able to statistically interpret experimental results Working with Product Managers, engineers and designers to understand where data can be helpful Transforming complicated problems into simpler, tractable ones Communicating with technical and non-technical stakeholders  RequirementsRequirements:  Bachelors, Masters or PhD degree in Computer Science, Statistics, Math, Engineering, or other quantitative discipline Some experience with one or more object oriented languages like Java, Scala, C++ Some experience with scripting languages like Python or Ruby etc. Some experience with statistical programming environments like R or Matlab Bonus points: Experience with machine learning Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects "
283,"VP  /  AVP, Data Scientist - Analytic Centre of Excellence, Data Management, T&O (170003CZ)",DBS BANK LTD.,"$6,500to$13,000Monthly","Roles & Responsibilities Work with business to define the problem and solution Design the experiment and measurement to test the solution Work with data analyst and engineer to identify, process and wrangle the data
 Develop the solution with advanced analytic techniques Validate and test the solution with historical data Implement the solution to production
 Test the solution with real live data Create reusable assets and share learning with others  Requirements PhD in computer science, statistics, decision science or other highly quantitative fields with at least 3 years of industry experience developing data science solutions. Or none PhD with at least 6 years industry experience Must have excellent problem solving and advanced analytic skills Expert in machine learning and data mining with excellent data processing, wrangling and feature engineering skills. Familiar with industry paradigm and standard for model development, validation and testing Strong understanding on the mathematics under the hook of machine learning algorithms Have developed and implemented industry machine learning solution for classification, prediction, forecasting and anomality detection problems Highly proficient with programming in Spark, Python or R Expert in at least one of the following areas or equivalent in depth: deep learning, NLP, graph analytics, anomality detection, advanced large-scale recommendation, large scale optimization (OR), large scale multivariate time series forecasting, statistical experiment design, statistical causality reasoning Good communication and presentation skill "
284,"Data Scientist, APAC (Singapore)",Company Undisclosed,"$8,000to$12,000Monthly","Roles & ResponsibilitiesWe are considering candidates for both junior and experienced positions. Who we are The Data Science team based in Singapore has the charter to understand user behavior and accelerate user growth for our platform, especially in international markets. We work on a mix of longer term analysis (such as how can we be smarter about how we send emails and notifications to our users; or how can we measure the impact of various user acquisition efforts) and shorter term tactical work (such as opportunity sizing for certain campaigns). The common thread between all the analysis we do is to seek to have a better understanding of how our users are engaging with our products. What youll do Your work with our large amounts of structured and unstructured data to understand how our users are using the product, and communicate these insights with stakeholders (product managers, executives, business decision makers etc). For more experienced hires, you will own important project areas from start to finish. That work includes defining an important roadmap of data science work and executing it. You are highly technical and hands on but you wear a product manager hat easily to make your projects successful. Who you are  You care about people: You have fundamental respect for all people You are in awe of the ability to understand and help 100s of millions of people  You are great at:  Extracting and transforming data from systems like Hadoop and SQL, using tools such as Pig, Scalding, Hive, Presto Exploring and visualizing data to drive insights Applying machine learning techniques for a variety of modeling and relevance problems involving users, their relationships, their social media posts and their interests. Designing and implementing metrics that help teams focus on what to optimize for Understanding A/B testing and are able to statistically interpret experimental results Working with Product Managers, engineers and designers to understand where data can be helpful Transforming complicated problems into simpler, tractable ones Communicating with technical and non-technical stakeholders  RequirementsRequirements:  Bachelors, Masters or PhD degree in Computer Science, Statistics, Math, Engineering, or other quantitative discipline Some experience with one or more object oriented languages like Java, Scala, C++ Some experience with scripting languages like Python or Ruby etc. Some experience with statistical programming environments like R or Matlab Bonus points: Experience with machine learning Experience with large datasets and Map Reduce architectures like Hadoop and open source data mining and machine learning projects "
285,Iron Ore Data Scientist,VALE INTERNATIONAL SA SINGAPORE BRANCH,"$4,500to$6,000Monthly","Roles & ResponsibilitiesThe position requires an expert on data science to work on Vale Iron Ore analytics projects, including designing and implementing models using machine learning and/or data mining techniques to generate business insights. The person will be part of multi-disciplinary teams and will help to develop custom analytics workflows by integrating relevant data sources and developing analytic/derived data sets to address specific business problems,
including analysis to determine data quality. The person will also apply data science tools on existing work flows which helps to lower the existing effort required for execution of existing analytics projects thereby improving productivity and efficiency of the Marketing team. RequirementsKey Accountabilities  The person will be extensively involved in data science related projects turning significant amounts of data into informative and insightful actions through various statistical techniques that turn into meaningful business results. Working across multi-disciplinary teams designing and implementing models using machine learning and/or data mining techniques to generate business insights. Person will develop custom analytics workflows by integrating relevant data sources and developing analytic/derived data sets to address specific business problems,
including analysis to determine data quality.  Main Challenges  Turning significant amounts of data into informative and insightful actions through various statistical techniques that turn into meaningful business results. Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner with excellent interpersonal, written, and verbal communication skills. Expertise in designing and implementing applied statistical and machine learning solutions on complex data sets using relevant languages & tools (e.g. R / Python / SAS / Matlab). Experience in developing scalable analytics solutions for small and large data sets by using big data and analytics services. Ability to use data visualization tools (e.g. Tableau/PowerBI, etc.). "
286,Enterprise Data Software Engineer,PEOPLEBANK SINGAPORE PTE. LTD.,"$7,000to$9,000Monthly","Roles & Responsibilities Engineering solutions for new and existing data pipelines and systems Maintaining, and supporting existing data pipelines and systems Working as a proactive team member in an agile environment Consulting with stakeholders to understand, architect, and implement solutions Testing solutions and implementations to guarantee they perform to specifications  Requirements Experience engineering full stack applications Experience in Informatica (nice to have) or eagerness to learn Experience using AWS (S3, Lambdas, RDS) or Azure Experience with Hadoop ecosystem (nice to have) or eagerness to learn. Spark experience big plus. Experience with non-relational database systems like HBase, Cassandra, DynamoDB, MongoDB, etc. (nice to have) Experience with CI/CD Experience or familiarity with TDD/BDD Experience or familiarity with the roles/responsibilities of Scrum and Kanban Experience with MDM (nice to have) Excellent analytical and problem solving, and thinking outside the box.  Interested candidate please send your updated resume to George.guo@peoplebank.asia"
287,Senior AI Data Engineer,AMARIS.AI PTE. LTD.,"$9,000to$15,000Monthly","Roles & ResponsibilitiesWe are looking for an AI
Data Engineer to implement
and maintain
the information architecture for the big data business based on the end-to-end vision of the data architect. The AI Data Engineer should be experienced in full stack web development. The Senior AI
Data Engineer will execute
master data management policies developed by the data architect and perform
the data quality evaluations.
 He/She is required to work
closely with business representatives to improve
the
quality of data to the required levels. Requirements  Responsible for the integration of large, structured and unstructured data volumes into the cloud platforms   Development of scalable end-to-end data pipelines for batch and stream processing   Execution of the datalake integration workflow and activities for populating the data lake and integrating diverse data sources   Execution an further development of the physical implementation of the logical data model into a physical implementation in the data lake   Implementation of solutions for reference data and master data management within the context of the mobility data business   Execution of data quality measurements and implementation of data quality improvement activities to the required levels of data quality   Support of build-up and maintenance of a data directory for all data relevant to the mobility data business   Representation of the Data Architecture team in selected data architecture, data modeling, and metadata management work teams inside Mobility  "
288,Data Scientist,SINGAPORE TECHNOLOGIES ENGINEERING LTD,Salary undisclosed,"Roles & ResponsibilitiesJob Description: - Work in Strategic Technology Centre to deliver data analytic solution to customers/users (solutions range from Descriptive, Diagnostic. Predictive, Prescriptive to Machine Learning and AI in developing data models with algorithms for big data analytics. 
 - Develop hardcore data science techniques into algorithms for DA with ML/AI capabilities.
  
 
 
 RequirementsRequirements: -



 Prefer a Master's Degree or PHD in Science/Engineering/Mathematics with at least 2-3 years of working experience in data analytics.  -



 In-depth technical knowledge in either: (1) Operational Research, (2) Computer Network (3) Computer Vision (4) Fluid Dynamics (5) Engineering Mechanics (6) Video/Image Processing (7) AI and Neural Network (7) Geometry and Topology (8) Social & Cognitive Computing is a plus. -



 Good experience with end-to-end data profiling, mathematical modeling, testing, validation, algorithm, visualization / ideation and solutioning. -



 Experienced in MySQL, Python, Matlab, Java or C. -




Knowledge of Hadoop and Spark highly essential in the age of Big Data.
 "
289,Data Scientist  /  Analyst ( UP $7K /  JURONG /  PhD /  Masters),SEARCH INDEX PTE. LTD.,"$5,000to$7,000Monthly","Roles & Responsibilities UP $7K / MNC
 Jurong Area
 AWS + BONUS
 PHD / Masters in Physics, Maths, Chemistry and Computer Sciences
 Exp in Data Mining / Analysis Exp in Production Industry an added advantage
  
 Responsibilities:
  Perform Data Analysis / Mining Transform Logic, Data into Algorithms
 Transfer findings and knowledge to Production / Product Development
 Ensure cost control in Projects
 Support DOE during Production process  RequirementsRequirement:
  PhD, Masters in Chemistry, Mathematics, Physics, Computer Sciences
  
 To apply, please email your detailed CV in MS Word format to
Search14@searchindex.com.sg
with the following details inside your CV for faster processing:  Reasons for leaving each past
 & current employment  Salary drawn for each past & current employment  Expected Salary  Earliest availability date We regret that only short-listed candidates will be contacted shortly. EA Licence No. | 14C7092 EA Registration No. | R1110636 EA Personnel | Pang Dan Pei (Danna)"
290,Data Engineer,PERX TECHNOLOGIES PTE. LTD.,"$5,000to$8,000Monthly","Roles & ResponsibilitiesWhat Youll Do: 
 As a Data Engineer on the Analytics team, you will be the source of truth for Perxs most fundamental data - such as end-customer engagement and client usage data - along with core metrics such as daily (DAU) and monthly active users (MAU). Alongside designing & implementing the plumbing & infrastructure that will power the Analytics frameworks, you will also help lead the companys decision to use bleeding-edge data technologies and features, working directly with our infrastructure team to integrate them into the services you design at scale. In doing so, you will help empower the Engineering department, tens of co-workers, thousands of marketing analysts and millions of end customers to dream of new insights and new possibilities. 
 Who You Are: You are a go-getter & dreamer, wanting to join a community of extremely talented, forward-thinking & diverse engineers in the industry & region. You gain happiness in building & scaling resilient, robust, well performing, and end-to-end tested distributed systems that can power the most business-critical applications. You want to learn, work with, and leverage on cutting-edge open-source technologies. The ideal candidate has experience with and/or history of contributions to Python, Hadoop, Spark, Redshift, Cassandra, PostGREs, Ruby (on Rails) or similar technologies. You have experience in distributed systems, database internals, or performance analysis. RequirementsMS in computer science or a related field OR BS in computer science and 3 years of experience in software engineering. Backend development experience with a solid foundation in data pipelines, distributed systems, large-scale data processing. Experience with DBs like AWS Redshift, PostGREs, MySQL. Experience with ETL and query language. Proficiency with Python, Scala or Java. Experience with Ruby is a plus. Experience with Linux/Unix systems and AWS / cloud environments. Working knowledge of MapReduce, Hadoop, HDFS. Experience with Spark is a big plus! 
"
291,"VP, Data Scientist, Business Analytics, Consumer Banking Group (1800016V)",DBS BANK LTD.,"$10,400to$18,700Monthly","Roles & Responsibilities Work with product and business teams to define the problem statement and develop solution with advanced analytic techniques to address key business challenges Work with data analyst and engineer to identify, process and wrangle the data
 Design experiments to demonstrate business value of analytics solutions. Including testing the solution with real live data and quantify business impact/benefit Implement successful experiment to production Create reusable assets and share learning with others  Requirements PhD in computer science, statistics, or other quantitative fields with at least 3 years of industry experience developing data science solutions, or at least 6 years strong industry experience with Degree in Quantative field. Must have excellent problem solving and advanced analytic skills Expert in machine learning and data mining with excellent data processing, wrangling and feature engineering skills. Familiar with industry paradigm and standard for model development Have developed and implemented industry machine learning solution for classification, prediction, forecasting and anomality detection problems Highly proficient with programming in Spark, Python or R Expert in at least one of the following areas or equivalent in depth: deep learning, NLP, graph analytics, anomality detection, advanced large-scale recommendation, large scale optimization, large scale multivariate time series forecasting, statistical experiment design Good communication and presentation skill 
 "
